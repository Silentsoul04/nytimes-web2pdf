<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Technology](https://www.nytimes.com/section/technology)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Technology](/section/technology)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">Internet
Companies Prepare to Fight the ‘Deepfake’ Future</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2OeECau</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

<div>

<div id="styln-elections-notifications-menu" class="section interactive-content interactive-size-medium css-1edisqu">

<div class="css-17ih8de interactive-body">

<div class="nytslm_innerContainer" data-aria-live="polite">

<div class="nytslm_title">

</div>

  - 
    
    <div id="default_container" class="nytslm_li_loud">
    
    <div id="default" class="nytslm_li_default_loud">
    
    </div>
    
    [Election
    Updates](https://www.nytimes.com/2020/08/07/us/elections/biden-vs-trump.html?action=click&pgtype=Article&state=default&region=TOP_BANNER&context=storylines_menu)
    
    </div>

  - 
    
    <div id="default_container" class="nytslm_li_loud">
    
    <div id="default" class="nytslm_li_default_loud">
    
    </div>
    
    [Hawaii
    Results](https://www.nytimes.com/interactive/2020/08/08/us/elections/results-hawaii-primary-elections.html?action=click&pgtype=Article&state=default&region=TOP_BANNER&context=storylines_menu)
    
    </div>

  - 
    
    <div id="default_container" class="nytslm_li_loud">
    
    <div id="default" class="nytslm_li_default_loud">
    
    </div>
    
    [Biden’s V.P.
    Search](https://www.nytimes.com/article/biden-vice-president-2020.html?action=click&pgtype=Article&state=default&region=TOP_BANNER&context=storylines_menu)
    
    </div>

  - 
    
    <div id="default_container" class="nytslm_li_loud">
    
    <div id="default" class="nytslm_li_default_loud">
    
    </div>
    
    [The
    Candidates](https://www.nytimes.com/interactive/2019/us/politics/2020-presidential-candidates.html?action=click&pgtype=Article&state=default&region=TOP_BANNER&context=storylines_menu)
    
    </div>

  - 
    
    <div id="default_container" class="nytslm_li_loud">
    
    <div id="default" class="nytslm_li_default_loud">
    
    </div>
    
    [Politics
    Newsletter](https://www.nytimes.com/newsletters/politics?action=click&pgtype=Article&state=default&region=TOP_BANNER&context=storylines_menu)
    
    </div>

</div>

</div>

</div>

</div>

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# Internet Companies Prepare to Fight the ‘Deepfake’ Future

</div>

Researchers are creating tools to find A.I.-generated fake videos before
they become impossible to detect. Some experts fear it is a losing
battle.

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Actors
were filmed in a variety of scenes. The top picture is their actual
image, with a deepfake altered image below
it. </span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Google</span></span></span>](https://static01.nyt.com/images/2019/11/24/business/24DEEPFAKES-01/24DEEPFAKES-01-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-hus3qt ey68jwv0" data-aria-hidden="true">

[![Cade
Metz](https://static01.nyt.com/images/2018/11/26/multimedia/author-cade-metz/author-cade-metz-thumbLarge.png
"Cade Metz")](https://www.nytimes.com/by/cade-metz)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Cade
Metz</span>](https://www.nytimes.com/by/cade-metz)

</div>

</div>

  - 
    
    <div class="css-ld3wwf e16638kd2">
    
    Nov. 24, 2019
    
    </div>

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

SAN FRANCISCO — Several months ago, Google hired dozens of actors to sit
at a table, stand in a hallway and walk down a street while talking into
a video camera.

Then the company’s researchers, using a new kind of artificial
intelligence software, [swapped the faces of the
actors](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html).
People who had been walking were suddenly at a table. The actors who had
been in a hallway looked like they were on a street. Men’s faces were
put on women’s bodies. Women’s faces were put on men’s bodies. In time,
the researchers had created hundreds of so-called deepfake videos.

By creating these digitally manipulated videos, Google’s scientists
believe they are learning how to spot deepfakes, which researchers and
lawmakers worry could become a new, insidious method for spreading
disinformation in the lead-up to the 2020 presidential election.

For internet companies like Google, finding the tools to spot deepfakes
has gained urgency. If someone wants to spread a fake video far and
wide, Google’s YouTube or Facebook’s social media platforms would be
great places to do it.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Imagine a fake Senator Elizabeth Warren, virtually indistinguishable
from the real thing, getting into a fistfight in a doctored video. Or a
fake President Trump doing the same. The technology capable of that
trickery is edging closer to reality.

“Even with current technology, it is hard for some people to tell what
is real and what is not,” said Subbarao Kambhampati, a professor of
computer science at Arizona State University.

### On ‘The Weekly,’ A.I. Engineers Create a Deepfake Video

\[*Sunday at 10 p.m. on FX and Streaming Monday on Hulu.*\]

</div>

</div>

<div class="css-bsn42l">

<span class="css-1dv1kvn">Video</span>

<div>

<div class="css-n27z15" style="padding-bottom:56.25%">

<div class="css-mm3pwi">

<div class="css-1g7y0i5 e1drnplw0">

<div class="css-1ceswkc e1drnplw1">

</div>

<div class="css-f2fzwx e1drnplw2">

<div data-aria-labelledby="modal-title" role="region">

<div id="modal-title" class="css-mln36k">

transcript

</div>

<div class="css-pbq7ev">

</div>

<span>Back</span>

<div class="css-f6lhej">

<div class="css-1ialerq">

<div class="css-1701swk">

bars

</div>

<div>

<div class="css-1t7yl1y">

0:00/2:01

</div>

<div class="css-og85jy">

\-0:00

</div>

</div>

</div>

</div>

<div class="css-15fbio0">

<div class="css-1p4nyns">

transcript

</div>

  -   
    \[HIGH-PITCHED NOTE\] “You know when a person is working on
    something and it’s good, but it’s not perfect? And he just tries for
    perfection? That’s me in a nutshell.” \[MUFFLED SPEECH\] “I just
    want to recreate humans.” “O.K. But why?” “I don’t know. I mean,
    it’s that feeling you get when you achieve something big.
    (ECHOING) “It’s really interesting. You hear these words coming out
    in your voice, but you never said them.” “Let’s try again.” “We’ve
    been working to make a convincing total deepfake. The bar we’re
    setting is very high.” “So you can see, it’s not perfect.” “We’re
    trying to make it so the population would totally believe this
    video.” “Give this guy an Oscar.” \[LAUGHTER\] “There are definitely
    people doing it at Google, Samsung, Microsoft. The technology moves
    super fast.” “Somebody else will beat you to it if you wait a year.”
    “Someone else will. And that will hurt.” “O.K., let’s try again.”
    “Just make it natural, right?” “It’s hard to be natural.” “It’s
    hard to be natural when you’re faking it.” “O.K.” “What are you up
    to these days?” “Today, I’m announcing my candidacy for the
    presidency of the United States.” \[LAUGHTER\] “And I would like to
    announce my very special running mate, the most famous chimp in the
    world, Bubbles Jackson. Are we good?” “People do not realize how
    close this is to happen. Fingers crossed. It’s going to happen,
    like, in the upcoming months. Yeah, the world is going to change.”
    “I squint my eyes.” “Yeah.” “Look, this is how we got into the
    mess we’re in today with technology, right? A bunch of idealistic
    young people thinking, we’re going to change the world.” “It’s weird
    to see his face on it.” \[LAUGHTER\] “I wondered what you would say
    to these engineers.” “I would say, I hope you’re putting as much
    thought into how we deal with the consequences of this as you are
    into the realization of it. This is a Pandora’s box you’re opening.”
    \[THEME MUSIC\]

</div>

</div>

</div>

</div>

</div>

<div class="css-1cueeje" style="padding-bottom:56.25%;transition:opacity 300ms ease-in-out">

<div class="css-1ihorw">

</div>

<div class="css-1ruigs3">

<div class="css-v15h5m">

<div>

</div>

<div>

</div>

</div>

</div>

</div>

</div>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Deepfakes — a term that generally describes videos doctored with
cutting-edge artificial intelligence — have already challenged our
assumptions about what is real and what is not.

In recent months, video evidence was at the center of prominent
incidents in Brazil, Gabon in Central Africa and China. Each was colored
by the same question: Is the video real? The Gabonese president, for
example, was out of the country for medical care and his government
released a so-called proof-of-life video. Opponents claimed it had been
faked. Experts call that confusion “the liar’s dividend.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“You can already see a material effect that deepfakes have had,” said
Nick Dufour, one of the Google engineers overseeing the company’s
deepfake research. “They have allowed people to claim that video
evidence that would otherwise be very convincing is a fake.”

<div id="NYT_MAIN_CONTENT_1_REGION" class="css-9tf9ac">

<div>

<div id="styln-nfldraft-updates-block" class="section interactive-content interactive-size-medium css-1ftcdic">

<div class="css-17ih8de interactive-body">

</div>

</div>

</div>

</div>

For decades, computer software has allowed people to manipulate photos
and videos or create fake images from scratch. But it has been a slow,
painstaking process usually reserved for experts trained in the vagaries
of software like Adobe Photoshop or After Effects.

Now, artificial intelligence technologies are streamlining the process,
reducing the cost, time and skill needed to doctor digital images. These
A.I. systems learn on their own how to build fake images by analyzing
thousands of real images. That means they can handle a portion of the
workload that once fell to trained technicians. And that means people
can create far more fake stuff than they used to.

The technologies used to create deepfakes is still fairly new and the
results are often easy to notice. But the technology is evolving. While
the tools used to detect these bogus videos are also evolving, some
researchers worry that they won’t be able to keep pace.

Google recently
[said](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html)
that any academic or corporate researcher could download its collection
of synthetic videos and use them to build tools for identifying
deepfakes. The video collection is essentially a syllabus of digital
trickery for computers. By analyzing all of those images, A.I. systems
learn how to watch for fakes. Facebook recently [did something
similar](https://ai.facebook.com/blog/deepfake-detection-challenge/),
using actors to build fake videos and then releasing them to outside
researchers.

Engineers at a Canadian company called Dessa, which specializes in
artificial intelligence, recently tested a deepfake detector that was
built using Google’s synthetic videos. It could identify the Google
videos with almost perfect accuracy. But when they tested their detector
on deepfake videos plucked from across the internet, it failed more than
40 percent of the time.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">The change
from the actual image can be subtle or drastic, depending on the other
actor used to create
it.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Google</span></span>](https://static01.nyt.com/images/2019/11/24/business/24DEEPFAKES-02/24DEEPFAKES-02-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

They eventually fixed the problem, but only after rebuilding their
detector with help from videos found “in the wild,” not created with
paid actors — proving that a detector is only as good as the data used
to train it.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Their tests showed that the fight against deepfakes and other forms of
online disinformation will require nearly constant reinvention. Several
hundred synthetic videos are not enough to solve the problem, because
they don’t necessarily share the characteristics of fake videos being
distributed today, much less in the years to come.

“Unlike other problems, this one is constantly changing,” said Ragavan
Thurairatnam, Dessa’s founder and head of machine learning.

In December 2017, someone calling themselves “deepfakes” started using
A.I. technologies to graft [the heads of celebrities onto nude bodies in
pornographic
videos](https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html).
As the practice spread across services like Twitter, Reddit and PornHub,
the term deepfake entered the popular lexicon. Soon, it was synonymous
with any fake video posted to the internet.

The technology has improved at a rate that surprises A.I. experts, and
there is little reason to believe it will slow. Deepfakes should benefit
from one of the few tech industry axioms that have held up over the
years: Computers always get more powerful and there is always more data.
That makes the so-called machine-learning software that helps create
deepfakes more effective.

“It is getting easier, and it will continue to get easier. There is no
doubt about it,” said Matthias Niessner, a professor of computer science
at the Technical University of Munich who is working with Google on its
deepfake research. “That trend will continue for years.”

The question is: Which side will improve more quickly?

Researchers like Dr. Niessner are working to build systems that can
automatically identify and remove deepfakes. This is the other side of
the same coin. Like deepfake creators, deepfake detectors learn their
skills by analyzing images.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Detectors can also improve by leaps and bounds. But that requires a
constant stream of new data representing the latest deepfake techniques
used around the internet, Dr. Niessner and other researchers said.
Collecting and sharing the right data can be difficult. Relevant
examples are scarce, and for privacy and copyright reasons, companies
cannot always share data with outside researchers.

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Though activists and artists occasionally release deepfakes as a way of
showing [how these videos could shift the political discourse
online,](https://www.nytimes.com/2019/06/11/technology/fake-zuckerberg-video-facebook.html)
these techniques are not widely used to spread disinformation. They are
mostly used to spread humor or fake pornography, according to Facebook,
Google and others who track the progress of deepfakes.

Right now, deepfake videos have subtle imperfections that can be readily
detected by automated systems, if not by the naked eye. But some
researchers argue that the improved technology will be powerful enough
to create fake images without these tiny defects. Companies like Google
and Facebook hope they will have reliable detectors in place before that
happens.

“In the short term, detection will be reasonably effective,” said Mr.
Kambhampati, the Arizona State professor. “In the longer term, I think
it will be impossible to distinguish between the real pictures and the
fake pictures.”

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div id="NYT_BELOW_MAIN_CONTENT_REGION">

<div>

<div id="STLYN_guide_v1_STYLN_guide_a" class="section css-l08pwh interactive-content interactive-size-medium">

<div class="css-17ih8de interactive-body">

<div class="g-story g-freebird g-max-limit" data-preview-slug="styln-scroll-guide">

</div>

<div id="g-electionguide-id" class="g-electionguide">

<div class="g-electionguide-container">

<div class="g-electionguide-wrapper">

<div class="g-electionguide-logo">

</div>

# Our 2020 Election Guide

Updated Aug. 8, 2020

  - 
    
    -----
    
    ## The Latest
    
      - With 160 lawsuits filed over voting rules and President Trump's
        baseless claims of fraud, Election Day in America [could become
        Election
        Month](https://www.nytimes.com/2020/08/08/us/politics/voting-nov-3-election.html?action=click&pgtype=Article&state=default&region=BELOW_MAIN_CONTENT&context=storylines_guide).

  - 
    
    -----
    
    ## Biden’s V.P. Search
    
      - [Here are 13
        women](https://www.nytimes.com/article/biden-vice-president-2020.html?action=click&pgtype=Article&state=default&region=BELOW_MAIN_CONTENT&context=storylines_guide)
        who have been under consideration to be Joe Biden’s running
        mate, and why each might be chosen — and might not be.

  - 
    
    -----
    
    ## Keep Up With Our Coverage
    
      - Get an
        [email](https://www.nytimes.com/newsletters/politics?action=click&pgtype=Article&state=default&region=BELOW_MAIN_CONTENT&context=storylines_guide)
        recapping the day’s news
    
    <!-- end list -->
    
      - Download our mobile app on
        [iOS](https://apps.apple.com/us/app/nytimes/id284862083?ls=1&mat_click_id=5c79ae7455014fd1bd66b5610c05b8f2-20191112-16948&referrer=mat_click_id%3D5c79ae7455014fd1bd66b5610c05b8f2-20191112-16948%26link_click_id%3D722930677036718082)
        and
        [Android](http://a.localytics.com/android?id=com.nytimes.android&referrer=utm_source%3Dother_nyt_mobile_web%26utm_medium%3DWeb%2520page%26utm_term%3DGeneral%2520Mobile%2520Page%26utm_campaign%3DNYT%2520Mobile%2520General%2520Page)
        and turn on Breaking News and Politics alerts

</div>

</div>

</div>

</div>

</div>

</div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
