Sections

SEARCH

\protect\hyperlink{site-content}{Skip to
content}\protect\hyperlink{site-index}{Skip to site index}

\href{https://www.nytimes.com/section/business}{Business}

\href{https://myaccount.nytimes.com/auth/login?response_type=cookie\&client_id=vi}{}

\href{https://www.nytimes.com/section/todayspaper}{Today's Paper}

\href{/section/business}{Business}\textbar{}Clearview's Facial
Recognition App Is Identifying Child Victims of Abuse

\url{https://nyti.ms/2OAw6Cq}

\begin{itemize}
\item
\item
\item
\item
\item
\end{itemize}

Advertisement

\protect\hyperlink{after-top}{Continue reading the main story}

Supported by

\protect\hyperlink{after-sponsor}{Continue reading the main story}

\hypertarget{clearviews-facial-recognition-app-is-identifying-child-victims-of-abuse}{%
\section{Clearview's Facial Recognition App Is Identifying Child Victims
of
Abuse}\label{clearviews-facial-recognition-app-is-identifying-child-victims-of-abuse}}

Though a breakthrough for law enforcement, the technique could allow the
little-known start-up to collect an extraordinarily sensitive set of
data and images.

\includegraphics{https://static01.nyt.com/images/2020/02/07/business/07CLEARVIEW-01/merlin_167287035_0c3ff0e2-b4b7-4c2b-a1a7-e5054b500409-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

By \href{https://www.nytimes.com/by/kashmir-hill}{Kashmir Hill} and
\href{https://www.nytimes.com/by/gabriel-dance}{Gabriel J.X. Dance}

\begin{itemize}
\item
  Published Feb. 7, 2020Updated Feb. 10, 2020
\item
  \begin{itemize}
  \item
  \item
  \item
  \item
  \item
  \end{itemize}
\end{itemize}

Law enforcement agencies across the United States and Canada are using
\href{https://www.nytimes.com/2020/02/10/podcasts/the-daily/facial-recognition-surveillance.html}{Clearview
AI} --- a secretive facial recognition start-up with a database of three
billion images --- to identify children who are victims of sexual abuse.
It's a powerful use case for the company's technology, but raises new
questions about the tool's accuracy and how the company handles data.

Investigators say Clearview's tools allow them to learn the names or
locations of minors in exploitative videos and photos who otherwise
might not have been identified. In one case in Indiana, detectives ran
images of 21 victims of the same offender through Clearview's app and
received 14 IDs, according to Charles Cohen, a retired chief of the
state police. The youngest was 13.

``These were kids or young women, and we wanted to be able to find them
to tell them we had arrested this guy and see if they wanted to make
victim statements,'' Mr. Cohen said.

Another official, a victim identification officer in Canada, who was not
authorized to discuss investigations publicly, described Clearview's
technology as ``the biggest breakthrough in the last decade'' in the
field of child sexual abuse crimes.

But privacy advocates say the company's database is untested and
unregulated, and could cause new kinds of harm. Clearview stores
pictures uploaded by investigators ---~known as probe images --- on its
servers, meaning it could amass an extraordinarily sensitive data set of
child victims of sexual abuse and exploitation.

``We understand the extreme sensitivity involved with identifying
children,'' Clearview's founder, Hoan Ton-That, wrote in an email. ``Our
mission is to protect children.''

According to a
\href{https://int.nyt.com/data/documenthelper/6690-clearview-faq/c8b081a0bcca12e7903a/optimized/full.pdf\#page=1}{company
document} distributed to clients, ``searches are retained forever'' by
default, but administrators can change their settings so search images
are purged after 30 days.

Clearview operated largely in the shadows until
\href{https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html}{a
New York Times report} last month revealed its use by local and federal
law enforcement agencies across the country. The company has harvested
billions of photos of individuals from the public internet, including
sites such as Facebook, Twitter, Venmo and YouTube. When a user uploads
a person's photo to Clearview, the app returns other images of the
person and the web addresses where they appeared.

In numerous publicity documents, Clearview promotes the use of its
technology by law enforcement to solve child sexual abuse cases. But
until recently, the company focused on its role in **** identifying
perpetrators, not victims.

Critics of Clearview said the benefits of such a database did not
outweigh its harms.

``It's tough. Everybody wants safety and to save kids,'' said Liz
O'Sullivan, technology director at the Surveillance Technology Oversight
Project. ``There is always some way to normalize surveillance, but it
would be dangerous for us to focus on the potential upsides. Facial
recognition makes a lot of mistakes.''

Ms. O'Sullivan said she was concerned that Clearview's software had not
been tested for accuracy by an independent agency. Facial recognition
algorithms can work poorly on young people, partly because their faces
change as they age, and partly because children are often not included
in the data sets used to train the algorithms.

Ms. O'Sullivan noted that if the tool made an incorrect match, there
could be devastating effects for wrongly identified children and their
families.

``The exchange of freedom and privacy for some early anecdotal evidence
that it might help some people is wholly insufficient to trade away our
civil liberties,'' she said.

Law enforcement is required to verify each identity when it uses the
Clearview app, Mr. Ton-That said in his email. But he could not say how
many children were in its database.

``We do not track the age, gender or racial breakdown of our image
database,'' he said. ``We are a search engine for public images, not a
surveillance system.''

The app is being used by task forces in Florida, Indiana and South
Dakota dedicated to investigating child abuse, as well as by the
Department of Homeland Security and law enforcement in Canada.

Like several officers who spoke with The Times, the Canadian
investigator was reluctant to discuss Clearview, fearing offenders would
shift their tactics.

``Our concern is that when bad guys hear this is available, they will
cover up the victims' faces more,'' the officer said. ``We don't want
bad guys to know this is possible.''

\includegraphics{https://static01.nyt.com/images/2017/01/29/podcasts/the-daily-album-art/the-daily-album-art-articleInline-v2.jpg?quality=75\&auto=webp\&disable=upscale}

\hypertarget{listen-to-the-daily-the-end-of-privacy-as-we-know-it}{%
\subsubsection{Listen to `The Daily': The End of Privacy as We Know
It?}\label{listen-to-the-daily-the-end-of-privacy-as-we-know-it}}

An unregulated facial recognition app can probably tell the police your
name, and help them find out where you live and who your friends are.

transcript

Back to The Daily

bars

0:00/31:46

-31:46

transcript

\hypertarget{listen-to-the-daily-the-end-of-privacy-as-we-know-it-1}{%
\subsection{Listen to `The Daily': The End of Privacy as We Know
It?}\label{listen-to-the-daily-the-end-of-privacy-as-we-know-it-1}}

\hypertarget{hosted-by-michael-barbaro-produced-by-annie-brown-and-daniel-guillemette-with-help-from-michael-simon-johnson-and-edited-by-paige-cowett-and-larissa-anderson}{%
\subsubsection{Hosted by Michael Barbaro; produced by Annie Brown and
Daniel Guillemette; with help from Michael Simon Johnson; and edited by
Paige Cowett and Larissa
Anderson}\label{hosted-by-michael-barbaro-produced-by-annie-brown-and-daniel-guillemette-with-help-from-michael-simon-johnson-and-edited-by-paige-cowett-and-larissa-anderson}}

\hypertarget{an-unregulated-facial-recognition-app-can-probably-tell-the-police-your-name-and-help-them-find-out-where-you-live-and-who-your-friends-are}{%
\paragraph{An unregulated facial recognition app can probably tell the
police your name, and help them find out where you live and who your
friends
are.}\label{an-unregulated-facial-recognition-app-can-probably-tell-the-police-your-name-and-help-them-find-out-where-you-live-and-who-your-friends-are}}

\begin{itemize}
\item
  {[}music{]}
\item
  michael barbaro\\
  From The New York Times, I'm Michael Barbaro. This is ``The Daily.''

  Today: A secretive company promising the next generation of facial
  recognition software has compiled a database of images far bigger than
  anything ever constructed by the U.S. government. The Daily's Annie
  Brown speaks to reporter Kashmir Hill about whether the technology is
  a breakthrough for law enforcement or the end of privacy as we know
  it.

  It's Monday, February 10.
\item
  annie brown\\
  Kashmir, how did this story come to you?
\item
  kashmir hill\\
  So I got an email. It was a Wednesday morning. I was checking my
  phone. And it was from a tipster who had gotten a bunch of documents
  from police departments. And one of the police departments had sent
  along this memo about a private company that was offering a radical
  new tool to solve crimes using facial recognition.
\item
  annie brown\\
  And what would make a facial recognition tool radical?
\item
  kashmir hill\\
  So law enforcement has for years had access to facial recognition
  tools. But what this company was offering was unlike any other facial
  recognition tools that police have been using, because they had
  scraped the open web of public photos --- from Facebook, from Venmo,
  from Twitter, from education sites, employment sites --- and had a
  massive database of billions of photos. So the pitch is that you can
  take a picture of a criminal suspect, put their face into this app and
  identify them in seconds.
\item
  annie brown\\
  And when you read this memo, what do you make of what this company is
  offering?
\item
  kashmir hill\\
  So I've been covering privacy for 10 years, and I know that a
  technology like this in public hands is the nightmare scenario.
\item
  {[}music{]}\\
  This has been a tool that was too taboo for Silicon Valley giants who
  were capable of building it. Google in 2011 said that they could
  release a tool like this, but it was the one technology they were
  holding back because it could be used in a very bad way.
\item
  annie brown\\
  And why exactly is this kind of technology this line in the sand that
  no one will cross? What makes it so dangerous?
\item
  kashmir hill\\
  So imagine this technology in public hands. It would mean that if you
  were at a bar and someone saw you and was interested in you, they
  could take your photo, run your face through the app, and then it
  pulls up all these photos of you from the internet. It probably takes
  them back to your Facebook page. So now they know your name, they know
  who you're friends with, they can Google your name, they can see where
  you live, where you work, maybe how much money you make. Let's say
  you're a parent and you're walking down the street with your
  three-year-old. Somebody can take a photo of you and know where the
  two of you live. Imagine you're a protester in the U.S. or in a more
  authoritarian regime. All of a sudden they know everything about you,
  and you can face repercussions for just trying to exercise your
  political opinions. If this app were made publicly available, it would
  be the end of being anonymous in public. You would have to assume
  anyone can know who you are any time they're able to take a photo of
  your face.
\item
  annie brown\\
  And so that technology is what this company is pitching these police
  departments?
\item
  kashmir hill\\
  Exactly.
\item
  annie brown\\
  And what do you know about this company at this point?
\item
  kashmir hill\\
  So at this point, all I really know is that the company is called
  Clearview AI. And so the first thing I do is Google it. And I find
  their website, which is clearview.ai. And the website is pretty bare,
  but there's also an office address listed there, 145 West 41st Street,
  which happens to be just a couple of blocks from The New York Times
  office.
\item
  annie brown\\
  Right.
\item
  kashmir hill\\
  So I decided to walk over there, and there just is no 145 West 41st
  Street. So that was weird. So now I have this company that's offering
  this radical new tool ---
\item
  annie brown\\
  It's got a fake address.
\item
  kashmir hill\\
  It's got a fake address, which is a huge red flag.
\item
  annie brown\\
  So what you do next?
\item
  kashmir hill\\
  I found the company on LinkedIn. It only had one employee listed, a
  sales manager named John Good, which ---
\item
  annie brown\\
  John Good.
\item
  kashmir hill\\
  John Good. It seemed like it could also be fake. And I sent that
  person a LinkedIn message and never heard back. So one of the things I
  find online is a website called PitchBook that lists investments in
  start-ups. And so it says that this Clearview AI has received \$7
  million from a venture capital firm and from Peter Thiel --- you know,
  a big name in Silicon Valley, invested in Facebook and Palantir. So I
  reach out to his spokesperson, and he says I'll get back to you. I
  never hear from him again. And then one day, I open up Facebook, and I
  have a message from a friend whose name I don't recognize. And he
  says, hey, I hear you're looking into Clearview AI. I know them.
  They're a great company. How can I help?
\item
  annie brown\\
  And you don't know who this guy is?
\item
  kashmir hill\\
  I don't. I mean, it's a guy I met once 10 years ago. And somehow he
  knows that I'm looking into this company. But I'll take it. You know,
  finally ---
\item
  annie brown\\
  Right!
\item
  kashmir hill\\
  --- somebody wants to talk to me about Clearview AI. And so I say,
  hey, can I give you a call? And then he doesn't respond, which I'm
  getting used to.
\item
  annie brown\\
  You just can't catch a break.
\item
  kashmir hill\\
  I know. I'm like, I cannot believe this is another dead end.

  So phone and email are not working for me. So I just need to figure
  out another door to knock on to try to talk to a real human being. And
  one of the investors in the company is this venture capital firm that
  has an office in Bronxville, New York. So on a cold, rainy Tuesday, I
  got on the train and headed to Bronxville. I get to the company's
  address. It's just like in a retail space. And go inside. There's this
  long, quiet hallway of office suites, and this venture capital firm is
  at the very end. And I knock on the door, and there's no one there. So
  I start trying to talk to their neighbors, and a woman who works next
  door says, oh yeah, they're never here. So I'm walking down the stairs
  to go back out of the building, and two guys walk through the door.
  They're both in dark suits with lavender and pink shirts underneath,
  and they just kind of look like V.C.s to me. So I say, hey, are you
  with this venture capital firm? And they say, we are. Who are you? And
  I was like, I'm the New York Times reporter who's been trying to get
  in touch with you. And they said, the company has told us not to talk
  to you. And I said, well I've come all the way out to Bronxville. Can
  we just chat for a little bit? And they say, O.K. If probably helps
  that I'm very pregnant, and they offered me water. And they just start
  telling me everything.
\item
  {[}music{]}
\item
  annie brown\\
  And what do they tell you?
\item
  kashmir hill\\
  They confirm that they've invested in Clearview AI and that Peter
  Thiel has also invested. They identified the genius coder behind the
  company, this guy named Hoan Ton-That. And they say he's Vietnamese
  royalty but he's from Australia. And they also tell me that Hoan is
  the one that was using the fake name John Good on LinkedIn.
\item
  annie brown\\
  He's John Good.
\item
  kashmir hill\\
  He's John Good.

  And they confirm that law enforcement is already using the app. And
  that law enforcement loves it and that it's spreading like wildfire.
\item
  annie brown\\
  Wow.
\item
  kashmir hill\\
  So I've learned some stuff from these two investors, but no one from
  the company is talking to me still. So in the meantime, I am also
  reaching out to law enforcement, because I want to know if this app
  really works as well as the company claims. By this point, I had
  learned that over 600 law enforcement agencies had tried the app,
  including the Department of Homeland Security and the F.B.I.
\item
  annie brown\\
  Wow. It's not just local police departments. This is being used by the
  federal government already.
\item
  kashmir hill\\
  Yeah, I mean, I was just shocked to discover how easily government
  agencies can just try a new technology without apparently knowing much
  about the company that provides it. So I talked to a retired police
  chief from Indiana, who was actually one of the first departments to
  use the app. And they solved a case within 20 seconds, he said.
\item
  annie brown\\
  A case they hadn't been able to solve?
\item
  kashmir hill\\
  That they hadn't been able to solve. One of the officers told me that
  he went back through like 30 dead-end cases that hadn't had any hits
  on the government database, and he got a bunch of hits using the app.
  So they were really excited about it.
\item
  annie brown\\
  This is way more effective than what they were using before.
\item
  kashmir hill\\
  Exactly. With the government databases they were previously using,
  they had to have a photo that was just a direct full-face photo of a
  suspect --- like mug shots and driver's license photos. But with
  Clearview, it could be a person wearing glasses, or a hat, or part of
  their face was covered, or they were in profile, and officers were
  still getting results on these photos.
\item
  annie brown\\
  Wow.
\item
  kashmir hill\\
  But the most astounding story I was told was that investigators had
  this child exploitation video, and there was an adult who was visible
  in the video just for a few seconds in the background. So they had
  this person's face. They had run it through their usual databases and
  not gotten anything back. But then they ran his face through
  Clearview's app, and he turned up in the background of someone else's
  gym selfie. You could see his face in the mirror. And so they figured
  out what gym this photo was taken out. They went to the gym. They
  asked the employees, do you know who this is? And the employee said,
  we can't tell you. We have to protect our members' privacy. But then
  later, the detectives got a text from somebody who worked there
  identifying the person. And that --- I mean, that's just something
  that would not have been possible without Clearview's app.

  So because officers were telling me the tool works so well, I wanted
  to see it for myself, on myself. And I asked them if they would run my
  photo through the app. But every time I did this, things would get
  weird. The officers would tell me that they ran my photo and there
  were no results.
\item
  annie brown\\
  No pictures of you?
\item
  kashmir hill\\
  There were no pictures of me, which was really weird, because I have a
  lot of photos of myself online. And then officers would just stop
  responding to me or talking to me. And I had no idea what was going on
  until one officer was kind enough to explain to me.
\item
  {[}phone ringing{]}
\item
  officer\\
  Hello, how are you.
\item
  kashmir hill\\
  Hey. It's Kashmir.
\item
  officer\\
  Yes, hi. Mm-hmm.
\end{itemize}

kashmir hill

I'm keeping this officer anonymous because he could get in serious
trouble for talking to me so openly about Clearview.

\begin{itemize}
\item
  kashmir hill\\
  If you could just describe yourself, to the extent that you can
  describe yourself.
\item
  officer\\
  I'm a police officer at a large metropolitan police department.
\end{itemize}

kashmir hill

So he's a cop who was doing a 30-day free trial of the app. And he was
really impressed with it. So I asked him if he wouldn't mind running my
photo.

annie brown

And what did he tell you happened when he sent your picture through?

\begin{itemize}
\item
  officer\\
  Yeah, nothing. I didn't get a response at all.
\item
  kashmir hill\\
  No results?
\item
  officer\\
  No results. And within a couple of minutes of me putting your photo up
  there --- maybe five, less than 10 --- I got a phone call from the
  Clearview company. They wanted to know why I was uploading a New York
  Times reporter's photo.
\item
  kashmir hill\\
  That is so wild. I don't know. {[}LAUGHS{]} It creeps me out as a
  reporter. I mean yeah, it just ---
\item
  officer\\
  It kind of creeped me out as a user.
\end{itemize}

kashmir hill

So this implied that Clearview flagged my face in their system such that
they got an alert when a police officer ran my face. Which I found ---

annie brown

Wow.

kashmir hill

--- very alarming, because this is telling me for the first time that
this company is able to monitor who law enforcement is looking for, and
not just know who they're looking for, but manipulate the results. And
so then that made me go back to the earlier officers who had run my
photo. And they all confirmed, yes, I got a call from the company, and
they said, we're not supposed to be talking to the media.

{[}music{]}

\begin{itemize}
\item
  kashmir hill\\
  So were you able to keep using the app after that?
\item
  officer\\
  My account was deactivated.
\item
  kashmir hill\\
  Did you ever get access back?
\item
  officer\\
  I never did. But I have colleagues that have access. So if I were to
  need a picture searched, I could just email it to them and they can
  email me the results.
\item
  kashmir hill\\
  And you think the trade-offs are worth it, in terms of what the
  company has access to?
\item
  officer\\
  Do I think it's worth it? So from a law enforcement perspective, it's
  worth it. We get a lot of cases, and we don't usually have a lot of
  leads. And so anything that can --- honestly, anything that can help
  us solve a crime is a win for us. From a privacy perspective, it's
  rather frightening the amount of information that they were able to
  get and provide. As long as they're doing it for the right reasons,
  then everything will work out. Let's put it that way.
\end{itemize}

{[}music{]}

kashmir hill

But the problem is we don't know anything about the company at this
point. We don't know if there's any kind of oversight. We don't know who
the people are that are operating this and what their intentions are
with their product. The person in charge of the company won't talk to
me. But then, it's the end of December when I get a call from the
company's spokeswoman. And she says that the founder, Hoan Ton-That, is
ready to talk.

michael barbaro

We'll be right back.

\begin{itemize}
\item
  kashmir hill\\
  Do you have a hard stop?
\item
  hoan ton-that\\
  No I don't actually. 12:30.
\item
  lisa linden\\
  12:00 noon.
\item
  hoan ton-that\\
  Oh, 12:00 noon.
\item
  kashmir hill\\
  I have no hard stop.
\item
  lisa linden\\
  Oh.
\item
  kashmir hill\\
  And I have lots of questions, so I'll take as much time as you can
  give me.
\end{itemize}

annie brown

So Kashmir, you finally got an interview with the founder of Clearview,
this man named Hoan Ton-That. Where do you meet him?

kashmir hill

So we met in a WeWork in Chelsea. He came down to the lobby.

\begin{itemize}
\item
  kashmir hill\\
  You like New York, you're going to stay here?
\item
  hoan ton-that\\
  Oh, yeah.
\end{itemize}

kashmir hill

And his appearance surprised me, because I had Googled him online and
there are a lot of photos of him. And he's usually pretty eccentric ---
like a lot of paisley shirts, he's at Burning Man.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  Let's go to the back room.
\end{itemize}

kashmir hill

But in person he was very conservative. He was in this dark blue navy
suit with a white button-up and leather shoes. So he looked very much
like the security start-up entrepreneur.

annie brown

He was looking the part.

kashmir hill

He was looking the part.

\begin{itemize}
\item
  kashmir hill\\
  When were you born? How old are you?
\item
  hoan ton-that\\
  `88, so I'm 31.
\item
  kashmir hill\\
  O.K.
\end{itemize}

annie brown

And what do you learn about him?

kashmir hill

So he is 31. He grew up in Australia, but you can't hear that in his
voice.

\begin{itemize}
\item
  hoan ton-that\\
  I love computers, obviously.
\item
  kashmir hill\\
  Yeah, so how did you get interested in technology?
\item
  hoan ton-that\\
  We had a computer, of course, when I was four or five years old.
\end{itemize}

kashmir hill

So his family got a computer when he was three or four, and he was
always tinkering with computers growing up.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  We got the internet when I was 10, I think. And then you could
  discover all these things online. But Linux, I was like I have to get
  this thing. It's the nerdiest thing ever. I convinced my dad. We
  installed it, and I would spend the whole summer reinstalling and
  learning Linux stuff, staying home from high school and learning
  programming for fun. So that's --- I just really liked it.
\end{itemize}

kashmir hill

He enrolled in college, decided to drop out like many technologists do,
and moved to San Francisco when he was 19.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  --- 2007, before it was a big thing, right? It was kind of getting
  there, but it wasn't huge.
\end{itemize}

kashmir hill

This is 2007, and this is kind of a boom time. The iPhone has just come
out.

\begin{itemize}
\item
  hoan ton-that\\
  That's the Facebook app era. Remember that?
\item
  kashmir hill\\
  Yeah.
\end{itemize}

kashmir hill

People are becoming millionaires by making Facebook games. And he wants
to be the next big app guy.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  Being there is a lot different from reading about it online. You
  absorb a lot more of how people get things done. And you learn a lot
  more secrets.
\end{itemize}

annie brown

What did he built?

kashmir hill

So the Facebook apps were like ``would you rather'' apps and kind of
like romantic GIFs.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  Did Some of the first iPhone games as well.
\end{itemize}

kashmir hill

One of his most recent apps was called Trump Hair, and it was an app for
adding Trump's hair to your photos.

annie brown

That's it?

kashmir hill

That's it. The tagline was, ``It's gonna be yuge!''

annie brown

O.K. {[}LAUGHS{]} So how do you move from a Donald Trump hair app to
something that seems like it could revolutionize police work?

kashmir hill

Well, he moved to New York. And that seemed to be a big change for him.
And he started meeting very different people. And one of the most
important people he met was Richard Schwartz.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  I ended up meeting Richard at a party.
\end{itemize}

kashmir hill

This 61-year-old guy who worked for Mayor Rudy Giuliani in the 1990s. He
was just very politically connected.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  I really loved that. He had a lot of stories. And then we talked for
  an hour about different ideas. Because I was like, this is what I do
  --- technology. I can make anything. And it went from there.
\end{itemize}

kashmir hill

And the two of them decided, with Hoan Ton-That's tech know-how and
Richard's Rolodex, that they want to try to start a facial recognition
company together.

annie brown

And why facial recognition? Why did the two of them choose that?

kashmir hill

I think it was because Hoan had started reading a lot of papers about
facial recognition and machine learning.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  I had never really studied AI stuff before, but I could pick up a lot
  of it.
\end{itemize}

kashmir hill

And I think they realized they could make money doing it.

\begin{itemize}
\item
  kashmir hill\\
  What would you say, in terms of the range of ideas at first, what were
  you thinking?
\item
  hoan ton-that\\
  A lot. I could go on, really crazy, but ---
\end{itemize}

kashmir hill

There's a lot of face recognition algorithms out there, and a lot that
work pretty well. What was different about what Hoan Ton-That and
Richard Schwartz were doing is they had been willing to scrape all of
these photos from the internet. So they just had a huge database of
photos.

annie brown

Right, the billions of photos.

kashmir hill

Exactly.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  And then we had this point where we got to 99 percent accuracy. I
  remember that, it was just in the office. And he was like, wow, it
  works. Try that one again. Try that one again. And just every time, it
  would pick the right person out. And that's when we knew, this is
  crazy. This actually works.
\end{itemize}

annie brown

Is that legal? Can you just take photographs from anywhere on the
internet and use them for this kind of thing?

kashmir hill

There was a ruling in a federal court this fall that said, yeah, this
kind of public scraping seems to be legal.

annie brown

And what are they hoping to do with this software at this point?

kashmir hill

I mean, they're just trying to figure out how they can make money off of
the app. And so they eventually end up settling on law enforcement.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  And they start solving cases from grainy A.T.M. photos, cases they
  would've never solved. So this spread to different departments, and
  then from one agency to other agencies.
\end{itemize}

annie brown

And do you ask him about that thing that happened with the officer who
couldn't find your photos?

kashmir hill

Yeah, so that was one of my questions, and I wasn't entirely satisfied
by his answer.

\begin{itemize}
\item
  hoan ton-that\\
  So ---
\item
  kashmir hill\\
  One thing that surprised me --- some of the officers I talked to tried
  to run my photo through it, and they got no hits. And I tons of photos
  online.
\item
  hoan ton-that\\
  {[}LAUGHS{]} It must have been a bug.
\item
  kashmir hill\\
  Did you guys block me from like getting results?
\item
  hoan ton-that\\
  I don't know about that.
\item
  kashmir hill\\
  Because I was like, this doesn't make any sense.
\end{itemize}

kashmir hill

He said, oh yeah, that was a software bug. But he laughed.

\begin{itemize}
\item
  kashmir hill\\
  I was like, I have 1,000 photos online. This can't work as well as
  they say it works.
\item
  hoan ton-that\\
  Yeah, well, it must have been a bug in the software or something.
\item
  kashmir hill\\
  {[}LAUGHS{]} Why did you do that? It totally made me think that ---
\item
  hoan ton-that\\
  Hey, maybe it doesn't work. You never know, right? This could be the
  long con.
\item
  kashmir hill\\
  Ah, O.K.
\item
  hoan ton-that\\
  I'm kidding, I'm kidding. It works.
\end{itemize}

annie brown

What do you think that was about?

kashmir hill

{[}LAUGHS{]} I don't think it was a software bug.

\begin{itemize}
\item
  hoan ton-that\\
  It's a bug. I don't know. I ---
\item
  kashmir hill\\
  You have no idea, huh?
\end{itemize}

annie brown

Huh.

kashmir hill

Yeah. So he said the software bug is now fixed.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  Oh yes, so I'll show you. This is the iPhone version.
\end{itemize}

kashmir hill

And he took a photo of me.

\begin{itemize}
\item
  hoan ton-that\\
  Oh, it does work.
\item
  kashmir hill\\
  Oh, that's so surprising.
\item
  hoan ton-that\\
  I know.
\end{itemize}

kashmir hill

And there, the results included a bunch of photos of me online.

\begin{itemize}
\item
  kashmir hill\\
  Oh my god, I totally forgot.
\item
  hoan ton-that\\
  Well, we can take ---
\item
  kashmir hill\\
  That's 10 years ago.
\end{itemize}

kashmir hill

Including some I had never seen before.

\begin{itemize}
\tightlist
\item
  kashmir hill\\
  Some of these photos I didn't know were online.
\end{itemize}

annie brown

So he's just brushing off this weird thing that happened to you. But do
you get the sense that he's thinking at all about privacy?

kashmir hill

So I asked him, you know, this is a very powerful app. And I asked him
what restrictions is he thinking about for it. And he said, one, that
they were only selling it to law enforcement right now, though it does
turn out that they're also selling it to a few private companies for
security purposes. But he said they wouldn't sell it to bad actors or
bad governments.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  --- and our philosophy is basically, if it's a U.S. based --- or like
  a democracy or an ally of the U.S. --- we will consider it. But like,
  no China, no Russia or anything that wouldn't be good. So if it's a
  country where it's just governed terribly or whatever, I don't know if
  we'd feel comfortable selling to certain countries.
\end{itemize}

annie brown

So it doesn't sound like he has much of a rubric for deciding who to
sell to. And it sounds like there's no one really overseeing how he's
making these decisions.

kashmir hill

At this point, it's just up to Clearview to decide who they want to sell
the app to.

\begin{itemize}
\tightlist
\item
  hoan ton-that\\
  No pressure, but when we talk to some venture capitalists, they're
  like, ``Why don't you make this consumer? Law enforcement is such a
  small market. You won't make that much money.'' And we've considered
  it, and we're just like, what's the use case here? And right now, we
  catch, help catch pedophiles. What if a pedophile got access to this,
  goes around the street, runs ---
\end{itemize}

kashmir hill

But when I was talking to one of their investors, he says, we want to
dominate the law enforcement market, and then we want to move into other
markets like hospitality, like real estate. And he predicted that one
day, all consumers will have access to this app.

\begin{itemize}
\item
  hoan ton-that\\
  Um, and ---
\item
  kashmir hill\\
  I can tell you that one of your investors hopes that you guys are
  going to go into the consumer market.
\item
  hoan ton-that\\
  Well, yeah. He talks too much. But like, we're not --- we're not going
  to do that. I just don't ---
\end{itemize}

annie brown

Hoan seems to be saying, yeah, there's pressure on us to sell to private
consumers, but we're not going to do that. And how reasonable is it to
think that he has control or the company has control at this point over
where this technology goes?

kashmir hill

I mean, one point that I made when I was talking to him is that
oftentimes, the tools that law enforcement use end up in the hands of
the public.

\begin{itemize}
\item
  kashmir hill\\
  I just --- I personally feel like you guys have opened the door to now
  this becoming more normalized, just because a lot of tools that law
  enforcement have eventually make their way into public hands.
\item
  hoan ton-that\\
  Not always. Not everyone has a gun. {[}LAUGHS{]} Right? That would be
  ---
\item
  kashmir hill\\
  Anyone who wants one can get one in the U.S. basically, but ---
\end{itemize}

kashmir hill

His response was strange. He said, well, look at guns. Law enforcement
has guns, but not everybody has a gun. And I don't know if that's
because he's from Australia?

annie brown

Yeah, he's proving your point, in a way.

kashmir hill

{[}LAUGHS{]} It did seem like he was proving my point, rather than
rebutting it.

{[}music{]}

We've been building the technology to make this possible for years now.
Facebook building this huge database of our photos with our names
attached to it, advances in image recognition and search technologies,
it all led us here. But there's been no accompanying regulation or rules
around how the technology should be used. There's no real law or
regulation that makes this illegal. The scraping seems to be O.K. We
don't have a big ban on facial recognition. We don't need to give
consent for people to process our faces. And so in terms of holding this
tool back, we're just relying on the moral compasses of the companies
that are making this technology and on the thoughtfulness of people like
Hoan Tan-That.

\begin{itemize}
\item
  kashmir hill\\
  But yeah, what do you think about that? Do you think that this is too
  dangerous a tool for everybody to have?
\item
  hoan ton-that\\
  I have to think about that and really get back to you on an answer,
  because it's a good question.
\item
  kashmir hill\\
  Yeah.
\item
  hoan ton-that\\
  I've thought about it a little bit.
\item
  kashmir hill\\
  You haven't thought about it? You have?
\item
  hoan ton-that\\
  I have, I have. But I need to really come up with a good answer for
  that. Honestly like, yeah.
\end{itemize}

{[}music{]}

annie brown

Thanks, Kashmir.

kashmir hill

Thank you.

michael barbaro

Since Kashmir began reporting on Clearview AI, several major social
media companies including Facebook, Twitter and Venmo have demanded that
the company stop using photos scraped from their websites. But it's
unclear what, if any, power those social media companies have to force
Clearview to comply. A few weeks ago, the state of New Jersey barred law
enforcement from using Clearview's technology, but police remain free to
do so in 49 other states.

We'll be right back.

Here's what else you need to know today. President Trump has begun a
campaign of retribution against witnesses in the impeachment inquiry,
firing Gordon Sondland, his ambassador to the European Union, who called
the president's actions toward Ukraine a quid pro quo. And Lieutenant
Colonel Alexander Vindman, a member of the National Security Council,
who expressed alarm over the president's phone call with the leader of
Ukraine. The Times reports that several Republican senators urged Trump
not to fire the witnesses, fearing it would send a dangerous message,
but that the president ignored their advice. And the global death toll
from the coronavirus has reached more than 800, surpassing that of the
SARS epidemic, which killed 774 in 2003. The number of confirmed
infections from the coronavirus now stands at more than 37,000. Finally,
new polling in New Hampshire, which will hold its primary tomorrow,
shows Mayor Pete Buttigieg neck-and-neck with Senator Bernie Sanders and
former Vice President Joe Biden slipping into fourth place.

\begin{itemize}
\tightlist
\item
  archived recording (george stephanopoulos)\\
  Vice President Biden, the first question is for you. In the last few
  days, you've been saying that Democrats will be taking too big a risk
  if they nominate Senator Sanders or Mayor Buttigieg, but they came out
  on top in Iowa. What risks did the Iowa Democrats miss?
\end{itemize}

michael barbaro

The poll, conducted by The Boston Globe, WBZ and Suffolk University
suggest Buttigieg is benefiting from a strong performance in the Iowa
caucuses and that Biden may perform poorly for the second time in a row,
a prediction Biden confirmed during Friday night's debate on ABC.

\begin{itemize}
\tightlist
\item
  archived recording (joe biden)\\
  Oh, they didn't miss anything. This is a long race. I took a hit in
  Iowa, and I'll probably take it here.
\end{itemize}

michael barbaro

That's it for ``The Daily.'' I'm Michael Barbaro. See you tomorrow.

There are legal risks associated with handling this type of imagery. It
would be against the law for the company to receive images of abuse
without immediately informing the authorities and deleting the material
from its servers. Mr. Ton-That said Clearview's app transmitted only
faces, not entire images.

The Times verified this behavior by analyzing a version of Clearview's
Android app, but was not able to examine the company's iOS offering or a
web-based version.

None of the law enforcement agencies The Times spoke with would say
whether they had performed a technical audit of Clearview before using
the software. Nor would any respond to questions regarding the specific
use of the application, saying they did not comment on investigative
techniques.

Britney Walker, a spokeswoman for the Department of Homeland Security's
Child Exploitation Investigations Unit, said that it collaborated with
external agencies to assist in investigations, but that the unit's
``victim-centered'' approach forbade any sharing of illegal imagery.

``Under no circumstances would the agency share child sexual abuse
materials to private companies,'' Ms. Walker said.

Other companies already work closely with law enforcement officials
investigating child sexual abuse. Johann Hofmann, the chief executive of
Griffeye, said the company's imagery analysis software was installed
inside law enforcement networks and was designed to avoid sending images
to third parties, including Griffeye itself.

Another company providing analysis tools to investigators of child
sexual abuse, CameraForensics, also said its systems were designed to
never receive any imagery, including faces, from law enforcement. The
company's founder, Matt Burns, said his company had considered
incorporating facial recognition technology into its software, but had
decided not to for ``ethical reasons.''

``We thought it was too controversial of a feature because it was too
easy to use that functionality for abuse,'' he said. ``And also it's
just a legal nightmare.''

Still, Mr. Burns said, he understood why investigators would want to use
facial recognition software. ``They are faced with a very grim task, and
if there's a tool that gives them an opportunity to safeguard victims, I
don't blame them for trying to grab it with both hands,'' he said.

Since Clearview's practices have come to light, Facebook, LinkedIn,
Twitter, Venmo and YouTube have
\href{https://www.nytimes.com/2020/01/22/technology/clearview-ai-twitter-letter.html}{sent}
the company cease-and-desist letters, asking it to stop scraping photos
from their sites and delete existing images in its database. The
attorney general of New Jersey
\href{https://www.nytimes.com/2020/01/24/technology/clearview-ai-new-jersey.html}{banned
the use of Clearview} by officers in the state and called for an
investigation into how it and similar technologies were being used by
law enforcement. A lawsuit seeking class-action certification was filed
in Illinois, where a strong biometric privacy law prohibits the use of
residents' faceprints without their consent, and another was filed in
Virginia on Monday.

Bills that would ban the use of facial recognition by the police have
recently been introduced in New York and Washington. And Clearview
received a letter from Senator Edward Markey, Democrat of Massachusetts,
asking for a list of law enforcement agencies that have used the app and
whether biometric information has been collected for children under 13
years old.

``While this type of technology has existed for quite some time, we
believe we have created something that enables law enforcement to solve
previously unsolvable crimes and, most importantly, protect vulnerable
children,'' Mr. Ton-That said in his email. ``At the same time, we are
responding to requests for information from government and other
interested parties as appropriate, and look forward to engaging in
constructive discussions with them as we work to make our communities
safer.''

In October, law enforcement groups
\href{https://www.ascia.org/pdf/news/le_group_letter_to_congress__facial_recogniton_technology__october_2019.pdf}{sent
a letter} to members of Congress, urging them to not ban the use of
facial recognition for their investigations. ``We understand the
public's concern about protection of their privacy and civil rights,''
they wrote. ``With clear, publicly available policies we believe those
concerns can be addressed.''

Many agencies had already been using Clearview for months, but the
letter made no mention of that.

Michael H. Keller and Aaron Krolik contributed reporting.

Advertisement

\protect\hyperlink{after-bottom}{Continue reading the main story}

\hypertarget{site-index}{%
\subsection{Site Index}\label{site-index}}

\hypertarget{site-information-navigation}{%
\subsection{Site Information
Navigation}\label{site-information-navigation}}

\begin{itemize}
\tightlist
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice}{©~2020~The
  New York Times Company}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \href{https://www.nytco.com/}{NYTCo}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us}{Contact
  Us}
\item
  \href{https://www.nytco.com/careers/}{Work with us}
\item
  \href{https://nytmediakit.com/}{Advertise}
\item
  \href{http://www.tbrandstudio.com/}{T Brand Studio}
\item
  \href{https://www.nytimes.com/privacy/cookie-policy\#how-do-i-manage-trackers}{Your
  Ad Choices}
\item
  \href{https://www.nytimes.com/privacy}{Privacy}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service}{Terms
  of Service}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale}{Terms
  of Sale}
\item
  \href{https://spiderbites.nytimes.com}{Site Map}
\item
  \href{https://help.nytimes.com/hc/en-us}{Help}
\item
  \href{https://www.nytimes.com/subscription?campaignId=37WXW}{Subscriptions}
\end{itemize}
