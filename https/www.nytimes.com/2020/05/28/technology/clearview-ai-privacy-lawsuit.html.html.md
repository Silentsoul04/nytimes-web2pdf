<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Technology](https://www.nytimes.com/section/technology)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Technology](/section/technology)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">A.C.L.U.
Accuses Clearview AI of Privacy ‘Nightmare
Scenario’</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2TNET6P</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# A.C.L.U. Accuses Clearview AI of Privacy ‘Nightmare Scenario’

</div>

The facial recognition start-up violated the privacy of Illinois
residents by collecting their images without their consent, the civil
liberties group says in a new lawsuit.

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Hoan
Ton-That, founder of Clearview AI, tests the smart phone
application.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Amr
Alfiky for The New York
Times</span></span></span>](https://static01.nyt.com/images/2020/05/29/business/28clearview-print/28clearview-articleLarge-v2.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Davey
Alba</span>](https://www.nytimes.com/by/davey-alba)

</div>

</div>

  - 
    
    <div class="css-ld3wwf e16638kd2">
    
    Published May 28, 2020Updated June 3,
    2020
    
    </div>

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-pvvomx" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The American Civil Liberties Union on Thursday sued the facial
recognition start-up Clearview AI, which claims to have helped hundreds
of law enforcement agencies use online photos to solve crimes, accusing
the company of “unlawful, privacy-destroying surveillance activities.”

In a suit filed in Illinois, the
[A.C.L.U.](https://www.nytimes.com/2020/06/03/business/aclu-sues-police-minneapolis.html)
said that Clearview violated a state law that forbids companies from
using a resident’s fingerprints or face scans without consent. Under the
law, residents have the right to sue companies for up to $5,000 per
privacy violation.

“The bottom line is that, if left unchecked, Clearview’s product is
going to end privacy as we know it,” said Nathan Freed Wessler, a lawyer
at the
[A.C.L.U.](https://www.nytimes.com/2020/06/03/business/aclu-sues-police-minneapolis.html),
“and we’re taking the company to court to prevent that from happening.”

The suit, filed in the Circuit Court of Cook County, adds to the growing
backlash against Clearview since January, when [The New York Times
reported](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html)
that the company had amassed a database of more than three billion
photos across the internet, including from Facebook, YouTube, Twitter
and Venmo. This trove of photos enables anyone with the Clearview app to
match a person to their online photos and find links back to the sites
where the images originated.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

People in New York and Vermont have also filed suits in against the
company in recent months, and the state attorneys general of Vermont and
New Jersey have ordered Clearview to stop collecting residents’ photos.

According to the A.C.L.U.
[suit](https://www.aclu.org/legal-document/aclu-v-clearview-ai-complaint),
“Clearview has set out to do what many companies have intentionally
avoided out of ethical concerns: create a mass database of billions of
face prints of people, including millions of Illinoisans, entirely
unbeknownst to those people, and offer paid access to that database to
private and governmental actors worldwide.”

The company’s business model, the complaint said, “appears to embody the
nightmare scenario” of a “private company capturing untold quantities of
biometric data for purposes of surveillance and tracking without notice
to the individuals affected, much less their consent.”

“Clearview AI is a search engine that uses only publicly available
images accessible on the internet,” Tor Ekeland, a lawyer for Clearview,
said in a statement. “It is absurd that the A.C.L.U. wants to censor
which search engines people can use to access public information on the
internet. The First Amendment forbids this.”

Mr. Wessler of the A.C.L.U. said the First Amendment “does not shield
Clearview’s unlawful conducts.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Our lawsuit does not challenge Clearview’s scraping of images off of
social media platforms,” he said. “It challenges the secret,
nonconsensual and unlawful capture of individuals’ biometric identifiers
from those images. Capturing a face print is conduct, not speech.”

The Illinois suit was prepared by the A.C.L.U., the A.C.L.U. of Illinois
and the law firm Edelson PC, which has specialized in class action suits
against technology companies for privacy violations. The firm was
involved in a suit that ended in a [$550 million settlement with
Facebook for the tech giant’s use of facial recognition technology in
Illinois](https://www.nytimes.com/2020/01/29/technology/facebook-privacy-lawsuit-earnings.html).

Other organizations that have signed on to the legal action include the
Chicago Alliance Against Sexual Exploitation, the Sex Workers Outreach
Project and the Illinois State Public Interest Research Group.

The A.C.L.U. said the lawsuit would compel a facial recognition company
to answer to groups representing sexual assault survivors, undocumented
immigrants and other vulnerable communities uniquely harmed by
surveillance.

There is a growing understanding among researchers that facial
recognition systems are worse at accurately identifying the faces of
people of color. Last December, the federal government released a study,
one of the largest of its kind, that found that most commercial facial
recognition systems exhibited bias, [falsely identifying
African-American and Asian
faces](https://www.nytimes.com/2019/07/08/us/detroit-facial-recognition-cameras.htmlhttps://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html)
10 to 100 times more than Caucasian faces.

Mallory Littlejohn from the Chicago Alliance Against Sexual
Exploitation, a Chicago-based nonprofit, said, “We can change our names
and addresses to shield our whereabouts and identities from stalkers and
abusive partners, but we can’t change our faces.”

Clearview, she said, “put survivors in constant fear of being tracked by
those who seek to harm them, and are a threat to our security, safety
and well-being.”

</div>

</div>

<div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
