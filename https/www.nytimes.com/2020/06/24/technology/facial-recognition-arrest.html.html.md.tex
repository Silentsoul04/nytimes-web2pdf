\href{/section/technology}{Technology}\textbar{}Wrongfully Accused by an
Algorithm

\url{https://nyti.ms/3dAQA89}

\begin{itemize}
\item
\item
\item
\item
\item
\item
\end{itemize}

\includegraphics{https://static01.nyt.com/images/2020/06/24/business/24michigan-arrest1/24michigan-arrest1-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

Sections

\protect\hyperlink{site-content}{Skip to
content}\protect\hyperlink{site-index}{Skip to site index}

The Great Read

\hypertarget{wrongfully-accused-by-an-algorithm}{%
\section{Wrongfully Accused by an
Algorithm}\label{wrongfully-accused-by-an-algorithm}}

In what may be the first known case of its kind, a faulty facial
recognition match led to a Michigan man's arrest for a crime he did not
commit.

``This is not me,'' Robert Julian-Borchak Williams told investigators.
``You think all Black men look alike?''Credit...Sylvia Jarrus for The
New York Times

Supported by

\protect\hyperlink{after-sponsor}{Continue reading the main story}

\href{https://www.nytimes.com/by/kashmir-hill}{\includegraphics{https://static01.nyt.com/images/2020/07/24/business/author-hill-kashmir/author-hill-kashmir-thumbLarge-v2.png}}

By \href{https://www.nytimes.com/by/kashmir-hill}{Kashmir Hill}

\begin{itemize}
\item
  Published June 24, 2020Updated Aug. 3, 2020
\item
  \begin{itemize}
  \item
  \item
  \item
  \item
  \item
  \item
  \end{itemize}
\end{itemize}

\emph{Note: In response to this article, the Wayne County prosecutor's
office said that Robert Julian-Borchak Williams could have the case and
his fingerprint data expunged. ``We apologize,'' the prosecutor, Kym L.
Worthy, said in a}
\href{https://int.nyt.com/data/documenthelper/7046-facial-recognition-arrest/5a6d6d0047295fad363b/optimized/full.pdf\#page=1}{\emph{statement}}\emph{,
adding, ``This does not in any way make up for the hours that Mr.
Williams spent in jail.''}

\hypertarget{listen-to-this-article}{%
\subsubsection{Listen to This Article}\label{listen-to-this-article}}

Audio Recording by Audm

\emph{To hear more audio stories from publishers like The New York
Times,
download}\href{https://www.audm.com/?utm_source=nytmag\&utm_medium=embed\&utm_campaign=left_behind_draper}{**}\href{https://www.audm.com/?utm_source=nyt\&utm_medium=embed\&utm_campaign=wrongfully_accused_algorithm}{\emph{Audm
for iPhone or Android}}\emph{.}

On a Thursday afternoon in January, Robert Julian-Borchak Williams was
in his office at an automotive supply company when he got a call from
the Detroit Police Department telling him to come to the station to be
arrested. He thought at first that it was a prank.

An hour later, when he pulled into his driveway in a quiet subdivision
in Farmington Hills, Mich., a police car pulled up behind, blocking him
in. Two officers got out and handcuffed Mr. Williams on his front lawn,
in front of his wife and two young daughters, who were distraught. The
police wouldn't say why he was being arrested, only showing him a piece
of paper with his photo and the words ``felony warrant'' and
``larceny.''

His wife, Melissa, asked where he was being taken. ``Google it,'' she
recalls an officer replying.

The police drove Mr. Williams to a detention center. He had his mug
shot, fingerprints and DNA taken, and was held overnight. Around noon on
Friday, two detectives took him to an interrogation room and placed
three pieces of paper on the table, face down.

``When's the last time you went to a Shinola store?'' one of the
detectives asked, in Mr. Williams's recollection. Shinola is an upscale
boutique that sells watches, bicycles and leather goods in the trendy
Midtown neighborhood of Detroit. Mr. Williams said he and his wife had
checked it out when the store first opened in 2014.

The detective turned over the first piece of paper. It was a still image
from a surveillance video, showing a heavyset man, dressed in black and
wearing a red St. Louis Cardinals cap, standing in front of a watch
display. Five timepieces, worth \$3,800, were shoplifted.

``Is this you?'' asked the detective.

The second piece of paper was a close-up. The photo was blurry, but it
was clearly not Mr. Williams. He picked up the image and held it next to
his face.

``No, this is not me,'' Mr. Williams said. ``You think all black men
look alike?''

Mr. Williams knew that he had not committed the crime in question. What
he could not have known, as he sat in the interrogation room, is that
his case may be the first known account of an American being wrongfully
arrested based on a flawed match from a facial recognition algorithm,
according to experts on technology and the law.

\hypertarget{a-faulty-system}{%
\subsection{A faulty system}\label{a-faulty-system}}

A nationwide debate is raging about
\href{https://www.nytimes.com/news-event/george-floyd-protests-minneapolis-new-york-los-angeles}{racism
in law enforcement}. Across the country, millions are protesting not
just the actions of individual officers, but bias in the systems used to
surveil communities and identify people for prosecution.

Facial recognition systems have been used by police forces for
\href{https://www.nytimes.com/2020/01/12/technology/facial-recognition-police.html}{more
than two decades}. Recent studies by
\href{https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html}{M.I.T.}
and the
\href{https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html}{National
Institute of Standards and Technology}, or NIST, have found that while
the technology works relatively well on white men, the results are less
accurate for other demographics, in part because of a lack of diversity
in the images used to develop the underlying databases.

Last year, during a public hearing about the use of
\href{https://www.nytimes.com/2019/07/08/us/detroit-facial-recognition-cameras.html}{facial
recognition in Detroit}, an assistant police chief was among those who
raised concerns. ``On the question of false positives --- that is
absolutely factual, and it's well-documented,'' James White said. ``So
that concerns me as an African-American male.''

This month,
\href{https://www.nytimes.com/2020/06/10/technology/amazon-facial-recognition-backlash.html}{Amazon},
\href{https://www.cnn.com/2020/06/18/tech/brad-smith-microsoft-facial-recognition/index.html}{Microsoft}
and
\href{https://www.axios.com/ibm-is-exiting-the-face-recognition-business-62e79f09-34a2-4f1d-a541-caba112415c6.html}{IBM}
announced they would stop or
\href{https://www.nytimes.com/aponline/2020/06/11/business/bc-us-microsoft-police-facial-recognition.html}{pause}
their facial recognition offerings for law enforcement. The gestures
were largely symbolic, given that the companies are not big players in
the industry. The technology police departments use is supplied by
companies that aren't household names, such as Vigilant Solutions,
Cognitec, NEC, Rank One Computing and
\href{https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html}{Clearview
AI}.

Clare Garvie, a lawyer at Georgetown University's Center on Privacy and
Technology, has written about problems with the
\href{https://www.flawedfacedata.com/}{government's use of facial
recognition}. She argues that low-quality search images --- such as a
still image from a grainy surveillance video --- should be banned, and
that the systems currently in use should be tested rigorously for
accuracy and bias.

``There are mediocre algorithms and there are good ones, and law
enforcement should only buy the good ones,'' Ms. Garvie said.

About Mr. Williams's experience in Michigan, she added: ``I
\href{https://www.aclu.org/blog/privacy-technology/surveillance-technologies/florida-using-facial-recognition-convict-people}{strongly}
\href{https://nymag.com/intelligencer/2019/11/the-future-of-facial-recognition-in-america.html}{suspect}
this is not the first case to misidentify someone to arrest them for a
crime they didn't commit. This is just the first time we know about
it.''

\hypertarget{in-a-perpetual-lineup}{%
\subsection{In a perpetual lineup}\label{in-a-perpetual-lineup}}

\includegraphics{https://static01.nyt.com/images/2020/06/24/business/24michigan-arrest4/merlin_173772126_cf489017-f4f1-4fb8-a049-bd15c81e623a-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

Mr. Williams's case combines flawed technology with poor police work,
illustrating how facial recognition can go awry.

The Shinola shoplifting occurred in October 2018. Katherine Johnston, an
investigator at Mackinac Partners, a loss prevention firm, reviewed the
store's surveillance video and sent a copy to the Detroit police,
according to their report.

Five months later, in March 2019, Jennifer Coulson, a digital image
examiner for the Michigan State Police, uploaded a ``probe image'' ---~a
still from the video, showing the man in the Cardinals cap --- to the
state's
\href{https://www.michigan.gov/msp/0,4643,7-123-72297_64747_64749-357133--,00.html\#:~:text=The\%20Statewide\%20Network\%20of\%20Agency,data\%20for\%20law\%20enforcement\%20access.}{facial
recognition database}. The system would have
\href{https://www.michigan.gov/documents/msp/Facial_Recognition_FAQ_666807_7.pdf}{mapped
the man's face and searched} for similar ones in a collection of 49
million photos.

The state's technology is supplied for
\href{https://www.michigan.gov/documents/buymichiganfirst/0200097_307265_7.pdf}{\$5.5
million} by a company called
\href{http://www.dataworksplus.com/}{DataWorks Plus}. Founded in South
Carolina in 2000, the company first offered mug shot management
software, said Todd Pastorini, a general manager. In 2005, the firm
began to expand the product, adding face recognition tools developed by
outside vendors.

When one of these subcontractors develops an algorithm for recognizing
faces, DataWorks attempts to judge its effectiveness by running searches
using low-quality images of individuals it knows are present in a
system. ``We've tested a lot of garbage out there,'' Mr. Pastorini said.
These checks, he added, are not ``scientific'' ---~DataWorks does not
formally measure the systems' accuracy or bias.

``We've become a pseudo-expert in the technology,'' Mr. Pastorini said.

In Michigan, the DataWorks software used by the state police
incorporates components developed by the Japanese tech giant NEC and by
Rank One Computing, based in Colorado, according to Mr. Pastorini and a
state police spokeswoman. In 2019, algorithms from both companies were
included in
\href{https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf}{a
federal study} of over 100 facial recognition systems that found
\href{https://www.nytimes.com/2019/12/19/technology/facial-recognition-bias.html}{they
were biased}, falsely identifying African-American and Asian faces 10
times to 100 times more than Caucasian faces.

Rank One's chief executive, Brendan Klare, said the company had
developed a new algorithm for NIST to review that ``tightens the
differences in accuracy between different demographic cohorts.''

After Ms. Coulson, of the state police, ran her search of the probe
image, the system
\href{https://www.michigan.gov/documents/msp/Facial_Recognition_FAQ_666807_7.pdf}{would
have provided} a row of results generated by NEC and a row from Rank
One, along with confidence scores. Mr. Williams's driver's license photo
was among the matches. Ms. Coulson sent it to the Detroit police as an
``Investigative Lead Report.''

``This document is not a positive identification,'' the file says in
bold capital letters at the top. ``It is an investigative lead only and
is not probable cause for arrest.''

This is what technology providers and law enforcement always
\href{https://www.nytimes.com/2019/07/08/us/detroit-facial-recognition-cameras.html}{emphasize}
when defending facial recognition: It is only supposed to be a clue in
the case, not a smoking gun. Before arresting Mr. Williams,
investigators might have sought other evidence that he committed the
theft, such as eyewitness testimony, location data from his phone or
proof that he owned the clothing that the suspect was wearing.

In this case, however, according to the Detroit police report,
investigators simply included Mr. Williams's picture in a ``6-pack photo
lineup'' they created and showed to Ms. Johnston, Shinola's
loss-prevention contractor, and she identified him. (Ms. Johnston
declined to comment.)

\hypertarget{i-guess-the-computer-got-it-wrong}{%
\subsection{`I guess the computer got it
wrong'}\label{i-guess-the-computer-got-it-wrong}}

Image

The Detroit Detention Center. Mr. Williams was held for 30
hours.Credit...Sylvia Jarrus for The New York Times

Mr. Pastorini was taken aback when the process was described to him.
``It sounds thin all the way around,'' he said.

Mr. Klare, of Rank One, found fault with Ms. Johnston's role in the
process. ``I am not sure if this qualifies them as an eyewitness, or
gives their experience any more weight than other persons who may have
viewed that same video after the fact,'' he said. John Wise, a spokesman
for NEC, said: ``A match using facial recognition alone is not a means
for positive identification.''

The Friday that Mr. Williams sat in a Detroit police interrogation room
was the day before his 42nd birthday. That morning, his wife emailed his
boss to say he would miss work because of a family emergency; it broke
his four-year record of perfect attendance.

In Mr. Williams's recollection, after he held the surveillance video
still next to his face, the two detectives leaned back in their chairs
and looked at one another. One detective, seeming chagrined, said to his
partner: ``I guess the computer got it wrong.''

They turned over a third piece of paper, which was another photo of the
man from the Shinola store next to Mr. Williams's driver's license. Mr.
Williams again pointed out that they were not the same person.

Mr. Williams asked if he was free to go. ``Unfortunately not,'' one
detective said.

Mr. Williams was kept in custody until that evening, 30 hours after
being arrested, and released on a \$1,000 personal bond. He waited
outside in the rain for 30 minutes until his wife could pick him up.
When he got home at 10 p.m., his five-year-old daughter was still awake.
She said she was waiting for him because he had said, while being
arrested, that he'd be right back.

She has since taken to playing ``cops and robbers'' and accuses her
father of stealing things, insisting on ``locking him up'' in the living
room.

\hypertarget{getting-help}{%
\subsection{Getting help}\label{getting-help}}

Image

Mr. Williams with his wife, Melissa, and their daughters at home in
Farmington Hills, Mich.Credit...Sylvia Jarrus for The New York Times

The Williams family contacted defense attorneys, most of whom, they
said, assumed Mr. Williams was guilty of the crime and quoted prices of
around \$7,000 to represent him. Ms. Williams, a real estate marketing
director and food blogger, also
\href{https://twitter.com/PPlates/status/1216813325310484481}{tweeted}
at the American Civil Liberties Union of Michigan, which took an
immediate interest.

*``*We've been active in trying to sound the alarm bells around facial
recognition, both as a threat to privacy when it works and a racist
threat to everyone when it doesn't,'' said Phil Mayor, an attorney at
the organization. ``We know these stories are out there, but they're
hard to hear about because people don't usually realize they've been the
victim of a bad facial recognition search.''

Two weeks after his arrest, Mr. Williams took a vacation day to appear
in a Wayne County court for an arraignment. When the case was called,
the prosecutor moved to dismiss, but ``without prejudice,'' meaning Mr.
Williams could later be charged again.

Maria Miller, a spokeswoman for the prosecutor, said a second witness
had been at the store in 2018 when the shoplifting occurred, but had not
been asked to look at a photo lineup. If the individual makes an
identification in the future, she said, the office will decide whether
to issue charges.

A Detroit police spokeswoman, Nicole Kirkwood, said that for now, the
department ``accepted the prosecutor's decision to dismiss the case.''
She also said that the department updated its
\href{https://detroitmi.gov/sites/detroitmi.localhost/files/2019-07/FACIAL\%20RECOGNITION\%20Directive\%20307.5_0.pdf}{facial
recognition policy} in July 2019 so that it is only used to investigate
violent crimes.

The department, she said in another statement, ``does not make arrests
based solely on facial recognition. The investigator reviewed video,
interviewed witnesses, conducted a photo lineup.''

On Wednesday, the A.C.L.U. of Michigan filed a
\href{https://www.aclu.org/letter/aclu-michigan-complaint-re-use-facial-recognition}{complaint}
with the city, asking for an absolute dismissal of the case, an apology
and the removal of Mr. Williams's information from Detroit's criminal
databases.

The Detroit Police Department ``should stop using facial recognition
technology as an investigatory tool,'' Mr. Mayor wrote in the complaint,
adding, ``as the facts of Mr. Williams's case prove both that the
technology is flawed and that DPD investigators are not competent in
making use of such technology.''

Mr. Williams's lawyer, Victoria Burton-Harris, said that her client is
``lucky,'' despite what he went through.

``He is alive,'' Ms. Burton-Harris said. *``*He is a very large man. My
experience has been, as a defense attorney, when officers interact with
very large men, very large black men, they immediately act out of fear.
They don't know how to de-escalate a situation.''

\hypertarget{it-was-humiliating}{%
\subsection{`It was humiliating'}\label{it-was-humiliating}}

Mr. Williams and his wife have not talked to their neighbors about what
happened. They wonder whether they need to put their daughters into
therapy. Mr. Williams's boss advised him not to tell anyone at work.

``My mother doesn't know about it. It's not something I'm proud of,''
Mr. Williams said. ``It's humiliating.''

He has since figured out what he was doing the evening the shoplifting
occurred. He was driving home from work, and had posted a video to his
private Instagram because a song he loved came on --- 1983's ``We Are
One,'' by Maze and Frankie Beverly. The lyrics go:

\begin{quote}
\emph{I can't understand}

\emph{Why we treat each other in this way}

\emph{Taking up time}

\emph{With the silly silly games we play}
\end{quote}

He had an alibi, had the Detroit police checked for one.

\includegraphics{https://static01.nyt.com/images/2017/01/29/podcasts/the-daily-album-art/the-daily-album-art-articleInline-v2.jpg?quality=75\&auto=webp\&disable=upscale}

\hypertarget{listen-to-the-daily-wrongfully-accused-by-an-algorithm}{%
\subsubsection{Listen to `The Daily': Wrongfully Accused by an
Algorithm}\label{listen-to-the-daily-wrongfully-accused-by-an-algorithm}}

In what may be the first known case of its kind, a faulty facial
recognition match led to a Michigan man's arrest for a crime he did not
commit.

transcript

Back to The Daily

bars

0:00/28:13

-28:13

transcript

\hypertarget{listen-to-the-daily-wrongfully-accused-by-an-algorithm-1}{%
\subsection{Listen to `The Daily': Wrongfully Accused by an
Algorithm}\label{listen-to-the-daily-wrongfully-accused-by-an-algorithm-1}}

\hypertarget{hosted-by-annie-brown-produced-by-lynsea-garrison-austin-mitchell-and-daniel-guillemette-and-edited-by-lisa-tobin-and-larissa-anderson}{%
\subsubsection{Hosted by Annie Brown, produced by Lynsea Garrison,
Austin Mitchell and Daniel Guillemette, and edited by Lisa Tobin and
Larissa
Anderson}\label{hosted-by-annie-brown-produced-by-lynsea-garrison-austin-mitchell-and-daniel-guillemette-and-edited-by-lisa-tobin-and-larissa-anderson}}

\hypertarget{in-what-may-be-the-first-known-case-of-its-kind-a-faulty-facial-recognition-match-led-to-a-michigan-mans-arrest-for-a-crime-he-did-not-commit}{%
\paragraph{In what may be the first known case of its kind, a faulty
facial recognition match led to a Michigan man's arrest for a crime he
did not
commit.}\label{in-what-may-be-the-first-known-case-of-its-kind-a-faulty-facial-recognition-match-led-to-a-michigan-mans-arrest-for-a-crime-he-did-not-commit}}

\begin{itemize}
\item
  michael barbaro\\
  From The New York Times, I'm Michael Barbaro. This is ``The Daily.''
\item
  {[}music{]}\\
  Today: Facial recognition is becoming an increasingly popular tool for
  solving crimes. The Daily's Annie Brown speaks to Kashmir Hill about
  how that software is not treating everybody equally.

  It's Monday, August 3.
\item
  kashmir hill\\
  I'm just going the tape record with an app that I use. Do you guys
  have any questions or concerns before we start talking about what
  happened?
\item
  robert williams\\
  No.
\item
  melissa williams\\
  No.
\end{itemize}

annie brown

OK. So where do you think we should start the story of this case,
Kashmir?

kashmir hill

The story started, for the Williams family, in January of 2020.

\begin{itemize}
\tightlist
\item
  robert williams\\
  Melissa got the call first. I got the call from her.
\end{itemize}

kashmir hill

It's a Thursday afternoon in Farmington Hills, Michigan, which is just
outside of Detroit.

\begin{itemize}
\tightlist
\item
  melissa williams\\
  So I picked up Julia from school. Regular Thursday.
\end{itemize}

kashmir hill

And Melissa Williams, a realtor, is driving home from work. She's
picking up her daughter.

\begin{itemize}
\tightlist
\item
  melissa williams\\
  And so it was right around, like, 4 o'clock. And I got a call.
\end{itemize}

kashmir hill

And she gets a call from somebody who says they're a police officer.

\begin{itemize}
\tightlist
\item
  melissa williams\\
  They immediately said, we're calling about Robert from an incident in
  2018. He needs to turn himself in. So I was confused off the bat.
\end{itemize}

kashmir hill

She is white. And her husband, Robert Williams, is Black.

\begin{itemize}
\item
  melissa williams\\
  And they said, we assume you're his baby mama or that you're not
  together anymore. And ---
\item
  kashmir hill\\
  What?
\item
  melissa williams\\
  Yeah. I said, that's my husband. And what is this regarding? And they
  said, we can't tell you. But he needs to come turn himself in. And I
  said, well, why didn't you call him? And they said, can't you just
  give him a message?
\end{itemize}

annie brown

Wait. So why is this officer calling her?

kashmir hill

She doesn't know why the officer is calling her. All she knows is that
the police want to be in touch with her husband. So she gives the
officer her husband's number. And then she calls Robert.

\begin{itemize}
\tightlist
\item
  melissa williams\\
  And I said, I just got a really weird call. I was like, what did you
  do? Like, what is this about?
\end{itemize}

kashmir hill

And while they're talking, Robert Williams gets a call from the police
department.

\begin{itemize}
\tightlist
\item
  robert williams\\
  Of course, I answered the other line. And he said he was a detective
  from Detroit and that I need to come turn myself in. So of course I'm
  like, for what? And he's like, well, I can't tell you over the phone.
  So I'm like, well, I can't turn myself in then.
\end{itemize}

kashmir hill

It was a couple of days before his birthday. So he thought maybe it was
a prank call. But it became pretty clear that the person was serious.

\begin{itemize}
\tightlist
\item
  robert williams\\
  About, uh, probably ten minutes later, I pull in the driveway.
\end{itemize}

kashmir hill

And when he pulls into his driveway, a police car pulls in behind him,
blocking him in. And two officers get out.

\begin{itemize}
\tightlist
\item
  robert williams\\
  Yeah. So I get out of the car. And the driver, like, runs up. And he's
  like, are you Robert Williams? I'm like, yeah. He's like, you're under
  arrest. I'm like, no I'm not. And the guy comes up with, like, a white
  sheet of paper. And it's said ``felony warrant'' on the top,
  ``larceny.'' And I'm confused, like, isn't larceny stealing?
\end{itemize}

kashmir hill

His wife comes out with his two young daughters. And his oldest
daughter, who's 5, is watching this happen.

\begin{itemize}
\tightlist
\item
  robert williams\\
  I said, Juju (ph), go back in the house. I'll be back in a minute.
  They're just making a mistake. The guy, the other cop, is behind me
  with his handcuffs out already. So he's like, come on, man. You
  already --- you know the drill. And I'm like, what?
\end{itemize}

kashmir hill

The officers arrest him. They have to use two pairs of handcuffs to get
his hands behind his back, because he's a really big guy.

\begin{itemize}
\tightlist
\item
  robert williams\\
  We started moving seats around, trying to get me in the back of this
  little bitty Impala. And off we go.
\end{itemize}

kashmir hill

And then they drive to the detention center.

{[}music{]}

\begin{itemize}
\item
  robert williams\\
  I took fingerprints. I took ---
\item
  kashmir hill\\
  Your mug shot.
\item
  robert williams\\
  Mug shot pictures.
\end{itemize}

kashmir hill

Then he's put in a cell to sleep overnight.

\begin{itemize}
\item
  robert williams\\
  At this point, I'm in a holding cell with two other guys. And they're
  like, what you in here for? And I'm like, I don't know.
\item
  kashmir hill\\
  So when do you actually find out why you've been arrested, beyond this
  kind of vague larceny?
\item
  robert williams\\
  Um, so --- well, maybe like noon the next day.
\end{itemize}

kashmir hill

Around noon the next day, he is taken to an interrogation room. And
there's two detectives there. And they have three pieces of paper face
down in front of them. And they turn over the first sheet of paper. And
it's a picture from a surveillance video of a large Black man standing
in a store, wearing a red Cardinals cap and a black jacket. And the
detectives ask, is this you?

\begin{itemize}
\tightlist
\item
  robert williams\\
  I laugh a little bit, and I say, no, that's not me. So then he turns
  over another paper.
\end{itemize}

kashmir hill

And they turn over a second piece of paper, which is just a close up of
that same guy's face.

\begin{itemize}
\tightlist
\item
  robert williams\\
  And he says I guess that's not you either. And I said, no. This is not
  me.
\end{itemize}

kashmir hill

So Robert picks the piece of paper up, holds it next to his own face ---

\begin{itemize}
\tightlist
\item
  robert williams\\
  I was like, what you think, all Black men look alike?
\end{itemize}

kashmir hill

--- and says, do all Black men look the same to you?

annie brown

So what's your understanding, Kashmir, of what happened to bring Robert
Williams into that police department?

kashmir hill

So Robert Williams had no idea what was happening. But two years
earlier, in October 2018, a man who was not him walked into a Shinola
store in downtown Detroit. And Shinola is kind of like a high-end store
that sells expensive watches and bikes. So this man came in. He was
there for a few minutes. He stole five watches worth \$3,800 and walked
out. None of the employees there actually saw the theft occur. And so
they had to review the surveillance footage. And they found the moment
it happened. So they sent that surveillance footage picture that Robert
Williams had been shown to the Detroit police. And the police turned to
what a lot of police turn to these days when they have a suspect that
they don't recognize --- a facial recognition system. So they ran a
search on this, what they call a probe image, this picture for the
surveillance video, which is really grainy. It's not a very good photo.
And the way these systems work is that they have access not just to mug
shots but also to driver's license photos. You get a bunch of different
results. And there's a human involved who decides which of the results
looks the most like the person who committed the crime.

annie brown

Mm. So you're saying the facial recognition algorithm basically created
a lineup of potential suspects. And then from that lineup, someone picks
the person that they think looks the most like the man in the
surveillance video.

kashmir hill

Right. And so that is how they wound up arresting Robert Williams.

{[}music{]}

So back in this room, the two detectives now have the real Robert
Williams in front of them. And he doesn't look like this guy.

\begin{itemize}
\tightlist
\item
  robert williams\\
  You know, they sat back and looked at each other and was like, with
  the oops face, right? Says, so I guess the computer got it wrong too.
\end{itemize}

kashmir hill

And so they kind of leaned back and said, I guess the computer got it
wrong.

\begin{itemize}
\tightlist
\item
  robert williams\\
  Well, the computer got it wrong is what threw me off. And I'm like,
  computer got it wrong?
\end{itemize}

annie brown

And what is the significance of that statement, ``that the computer got
it wrong``?

kashmir hill

So this was an admission by the detectives that it was a computer that
had pointed the finger at Robert Williams. And that's significant,
because this is the first documented case of an innocent person being
arrested because of a flawed facial recognition match.

{[}music{]}

annie brown

And just to put all of this into context for a second, the last time
that you and I talked, Kashmir, we were talking about a different
development in facial recognition --- this new algorithm being used by
some police departments that drew from pictures all over social media
and all over the internet to make a kind of super algorithm. But the
fear wasn't that it wasn't accurate. It was almost that it was too
accurate, that it knew too much. But what you're describing is something
altogether different. Right?

kashmir hill

So when we talk about facial recognition, we often think of it as a
monolith, that there's kind of one facial recognition. But in fact,
there's a bunch of different companies that all have their own
algorithms. And some work well. And some don't work well. And some work
well sometimes. Like, identifying a really clear photo is a lot easier
than identifying surveillance footage.

annie brown

And why wouldn't police departments be using the most sophisticated, the
most kind of up-to-date version of this software?

kashmir hill

I mean, this is where you run into just bureaucracy. Right? You have
contracts with companies that go back years and just a lot of different
vendors. And so in this case, I tried to figure out exactly whose
algorithms were responsible for Robert Williams getting arrested. And I
had to really dig down. And I discovered the police had no idea. You
know, they contract out to a company called DataWorks Plus. And
DataWorks Plus contracts out to two other companies called N.E.C. and
Rank One that actually supply the algorithm. It's this whole chain of
companies that are involved. And there is no standardized testing.
There's no one really regulating this. There's just nobody saying which
algorithms, you know, pass the test to be used by law enforcement. It's
just up to police officers, who, for the most part, seem to be just
testing it in the field to see if it works, if it's identifying the
right people.

But the really big problem is that these systems have been proven to be
biased.

{[}music{]}

michael barbaro

We'll be right back.

annie brown

So, Kashmir, help me understand how an algorithm can become biased.

kashmir hill

Well, the bias tends to come from how the algorithm is trained. And
these algorithms tend to be trained by basically feeding them with a
bunch of images of people. But the problem with the algorithms is that
they tended to be trained with non-diverse data sets.

annie brown

Mm.

kashmir hill

So one good example is that many of the algorithms used by law
enforcement in the U.S., by government in the U.S., are very good at
recognizing white men and not as good at recognizing Black people or
Asian-Americans. But if you go to an algorithm from a company in China,
where they fed it with a lot of images of Asian people, they're really
good at recognizing Asian people and not as good at recognizing white
men. So you can just, you can see the biases that come in from the kind
of data that we feed into these systems.

annie brown

And is this a widely agreed upon reality --- that because of these
methods, the algorithms used in the U.S. are just worse at identifying
faces that aren't white men?

kashmir hill

Yeah. A few years ago, an M.I.T. researcher did this study and found
that facial recognition algorithms were biased to be able to recognize
white men better. And shortly after that, NIST, the National Institute
of Standards and Technology, decide to run its own study on this. And it
found the same thing. It looked at over 100 different algorithms. And it
found that they were biased. And actually, the two algorithms that were
at the heart of this case --- the Robert Williams's case --- were in
that study.

annie brown

So the algorithm that was used by this police department was actually
studied by the federal government and was proven to be biased against
faces like Robert Williams.

kashmir hill

Exactly.

annie brown

So given these widely-understood problems with these algorithms, how can
police departments justify continuing to use them?

kashmir hill

So police departments are aware of the bias problem. But they feel that
face recognition is just too valuable a tool in their tool set to solve
crimes. And their defense is that they never arrest somebody based on
facial recognition alone, that facial recognition is only what they call
an investigative lead. It doesn't supply probable cause for arrest.

So what police are supposed to do is they get a facial recognition
match, and you're supposed to do more investigating. So you could go to
the person's social media account and see if there are other photos of
them wearing the same clothes that they were wearing on the day they
committed this crime. Or, you know, you can try to get proof that they
were in that part of town on the day that the theft occurred. You know,
try to get location data. Basically, find other evidence that this
person is the person that committed the crime.

The detectives just went to the woman who had spotted the theft on the
video and showed her a photo of six people --- they call it a six pack.
And she said Robert Williams looked the most like the person that was in
the video.

annie brown

Mm. So they're supposed to use the facial recognition match as a kind of
clue. And then the protocol calls for them to do more police work to
verify it. But in this case, they basically just had someone watch the
video and then identify Robert Williams as the one who looks most like
the guy in the video.

kashmir hill

Yeah, they just did facial recognition a second time, but with a human
who's not actually trained. And they didn't do any other investigating.
Based on that, they went out and they arrested Mr. Williams.

annie brown

But if the police had done their job correctly --- if they had looked
into his social media accounts, if they had tried to get his location
data from his phone records, essentially surveilling him more closely
--- wouldn't that be its own sort of violation? Just because their
technology wrongfully identified this man, he gets more closely watched
by the police without his knowledge.

kashmir hill

Right. And this is actually what police asked the facial recognition
vendors to do. They want to have more, what you call false positives,
because they want to have the greatest pool of possible suspects that
they can, because they want to find the bad guy.

annie brown

Huh.

kashmir hill

But there's a real toll from that.

annie brown

Hmm.

kashmir hill

I just, you know, as a person who's been reporting on technology for a
decade, I just think people trust computers. And even when we know
something is flawed, if it's a computer telling us to do it, we just
think it's right. And this is why we always used to see, for a long
time, when mapping technology was first being developed and it wasn't
that great, you know, people would drive into lakes. They would drive
over cliffs, because a mapping app said, you're supposed to go straight
here.

annie brown

Right.

kashmir hill

And even though they could look and see that their life is going to be
in danger, they would think, well, this app must know what it's talking
about. That's facial recognition now. And when I was reporting this
story, all the experts I talked to said this is surely not the first
case where somebody has been mistakenly --- an innocent person has been
mistakenly arrested because of a bad face recognition match. But usually
people don't find out about it. Police don't tell people that they're
there because of face recognition.

annie brown

Hmm.

kashmir hill

Usually, when they charge them, they'll just say they were identified
through investigative means. It's kind of a vague, ``There were clues
that pointed at you.'' In that way, Robert's case was unusual, because
there was so little evidence against him. They basically had to tell him
that they used facial recognition, you know, to put him there.

annie brown

Right. They showed him what most people don't get to see, which is this
false match between his photo and the photo of the crime.

kashmir hill

Right.

annie brown

And what's happened since Robert was arrested?

kashmir hill

So Robert had to hire a lawyer to defend himself. But when he went to
the hearing, the prosecutor decided to drop the case. But they dropped
it without prejudice, which meant that they could charge him again.

annie brown

For the same crime?

kashmir hill

With the same crime. So as I was reporting out the story, you know, I
went to the prosecutor's office. I went to the Detroit Police
Department. And I said, you know, what happened here? Did you have any
other evidence? This just seems like a clear misfire and misuse of
facial recognition. And everyone involved was pretty defensive and said,
well, you know, there might be more evidence that proves that Robert
Williams did it.

But after the story came out, everybody's tune changed dramatically.
Prosecutors office apologized, said that Robert Williams shouldn't have
spent any time in jail. The Detroit Police Department said this was a
horrible investigation. The police officers involved just did this all
wrong. This isn't how it's supposed to work. And they said that Robert
Williams would have his information expunged from the system --- his mug
shot, his DNA. And they personally apologized to the Williams family,
though the Williams family told me that no one ever actually called them
to personally apologize.

annie brown

But he can no longer be charged in the future for this crime?

kashmir hill

That's exactly right.

annie brown

And what about their use of facial recognition software? Has there been
any change there?

kashmir hill

So one thing the Detroit Police Department said was, well, this was a
case that predates this new policy we have that says, you know, we're
only supposed to be using facial recognition for violent crimes.

annie brown

Hmm. And what do you make of that? Why only use this tool for that?

kashmir hill

Well, their justification is that when it comes to violent crimes, when
it comes to murder, you know, rape, they need to solve these cases. And
they'll use any clue they can to do it, including facial recognition.
But I think about something that Robert's wife said.

\begin{itemize}
\tightlist
\item
  melissa williams\\
  When they pulled up to our house, they were already combative on the
  phone. They were aggressive in the doorway to me. What if he had been
  argumentative? If he'd been defensive, if he hadn't complied, you
  know, what could that have turned into in our yard? Like, it could
  have went a different way. And the recent news has shown us that it
  definitely could have went a different way.
\end{itemize}

{[}music{]}

\begin{itemize}
\item
  kashmir hill\\
  Do you feel like there's a shame to this, that the police arrested you
  even though you did nothing?
\item
  robert williams\\
  It's a little humiliating. You know, it's not something that easily
  rolls off the tongue, like, oh yeah, and guess what? I got arrested.
\end{itemize}

{[}music{]}

annie brown

And what about for Robert himself? What has life been like for him after
the arrest?

kashmir hill

So this was very embarrassing for him and kind of painful in some ways.
So he had a perfect attendance at work until that day that he was
arrested. And his wife had to email his boss and say that they had a
family emergency and that he couldn't show up that day. Once he did tell
his boss what happened, his boss said, you know, you don't want to tell
other people at work. You know, it could be bad for you. The night he
got home, his daughter --- his 5-year-old was still awake.

\begin{itemize}
\tightlist
\item
  robert williams\\
  Julia was still up. And I was like, what are you doing up? And she was
  like, I'm waiting for you. And I was like, I told you I'll be right
  back. And she was like, you didn't come right back though. So I just
  kept telling her that they made a mistake. And it just took longer
  than we expected. But ---
\end{itemize}

kashmir hill

She started wanting to play cops and robbers. And she would always
pretend like he was the robber who stole something, and she would need
to lock him up in the living room.

annie brown

Hmm.

\begin{itemize}
\item
  melissa williams\\
  Oh yeah. She told us that she told one of her --- Jackson, her friend
  at school. And we weren't sure, did she tell her teacher? Did she tell
  her friends? We were not sure. And we didn't know what to say to
  people. Like, just bring it up out of nowhere, like, oh yeah, in case
  anyone mentioned it, he was arrested, but he didn't do anything.
\item
  kashmir hill\\
  Has this made you look back to see where you --- like, where you were
  October 2018?
\item
  robert williams\\
  Yeah. I pulled it up. At the time, I was on my Facebook or on my
  Instagram Live.
\end{itemize}

kashmir hill

He has since looked back and realized that he had posted to Instagram at
basically the same time as the shoplifting was occurring. He was driving
home from work, and a song came on the radio that his mother loved: the
song ``We Are One'' by Maze and Frankie Beverly.

\begin{itemize}
\tightlist
\item
  robert williams\\
  I was singing songs on my way home in the car.
\end{itemize}

annie brown

So if the cops had looked in to his social media, if they had tried to
verify that it was possible that he could have committed this crime,
they could have found this video.

kashmir hill

Right. If the police had done a real investigation, they would have
found out he had an alibi that day.

\begin{itemize}
\tightlist
\item
  archived recording\\
  {[}``WE ARE ONE'' PLAYING{]}
\end{itemize}

annie brown

Kashmir, thank you so much.

kashmir hill

Thank you.

{[}music{]}

michael barbaro

We'll be right back.

Here's what else you need to know today. Federal unemployment benefits
have expired for tens of millions of Americans after Congress failed to
reach a deal to renew them last week.

\begin{itemize}
\item
  archived recording\\
  So what do you say to those 30 million Americans who are now without
  federal unemployment help?
\item
  archived recording (nancy pelosi)\\
  I say to them, talk to President Trump. He's the one who is standing
  in the way of that. We have been for the \$600. They have a \$200
  proposal, which does not meet the needs of America's working families.
  And ---
\end{itemize}

michael barbaro

In interviews on Sunday with ABC's ``This Week,'' House Speaker Nancy
Pelosi blamed Republicans for demanding a drastic cut in the weekly
benefit, while Treasury Secretary Steve Mnuchin claimed that the \$600
payments risked overpaying unemployed workers.

\begin{itemize}
\item
  archived recording\\
  So you do think it is a disincentive to find a job if you have that
  extra \$600?
\item
  archived recording (steven mnuchin)\\
  There's no question. In certain cases where we're paying people more
  stay home than to work, that's created issues in the entire economy.
\end{itemize}

michael barbaro

And The Times reports that July was a devastating month for the pandemic
in the U.S. The country recorded nearly 2 million new infections, twice
as many as any previous month.

\begin{itemize}
\tightlist
\item
  archived recording (deborah birx)\\
  I want to be very clear. What we're seeing today is different from
  March and April. It is extraordinarily widespread. It's into the rural
  as equal urban areas.
\end{itemize}

michael barbaro

In an interview on Sunday with CNN, Dr. Deborah Birx, a top White House
adviser on the pandemic, acknowledged that the United States has failed
to contain the virus.

\begin{itemize}
\tightlist
\item
  archived recording (deborah birx)\\
  And to everybody who lives in a rural area, you are not immune or
  protected from this virus. And that's why we keep saying, no matter
  where you live in America, you need to wear a mask and socially
  distance. Do the personal hygiene ---
\end{itemize}

michael barbaro

That's it for ``The Daily.'' I'm Michael Barbaro. See you tomorrow.

{[}music{]}

Aaron Krolik contributed reporting.

Advertisement

\protect\hyperlink{after-bottom}{Continue reading the main story}

\hypertarget{site-index}{%
\subsection{Site Index}\label{site-index}}

\hypertarget{site-information-navigation}{%
\subsection{Site Information
Navigation}\label{site-information-navigation}}

\begin{itemize}
\tightlist
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice}{©~2020~The
  New York Times Company}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \href{https://www.nytco.com/}{NYTCo}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us}{Contact
  Us}
\item
  \href{https://www.nytco.com/careers/}{Work with us}
\item
  \href{https://nytmediakit.com/}{Advertise}
\item
  \href{http://www.tbrandstudio.com/}{T Brand Studio}
\item
  \href{https://www.nytimes.com/privacy/cookie-policy\#how-do-i-manage-trackers}{Your
  Ad Choices}
\item
  \href{https://www.nytimes.com/privacy}{Privacy}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service}{Terms
  of Service}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale}{Terms
  of Sale}
\item
  \href{https://spiderbites.nytimes.com}{Site Map}
\item
  \href{https://help.nytimes.com/hc/en-us}{Help}
\item
  \href{https://www.nytimes.com/subscription?campaignId=37WXW}{Subscriptions}
\end{itemize}
