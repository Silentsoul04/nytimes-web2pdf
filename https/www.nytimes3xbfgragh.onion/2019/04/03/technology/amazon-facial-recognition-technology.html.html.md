<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Technology](https://www.nytimes3xbfgragh.onion/section/technology)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes3xbfgragh.onion/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes3xbfgragh.onion/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Technology](/section/technology)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">A.I.
Experts Question Amazon’s Facial-Recognition
Technology</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2Uqin5E</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-1vkm6nb ehdk2mb0">

# A.I. Experts Question Amazon’s Facial-Recognition Technology

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">A protest
against Amazon’s facial-recognition technology in October. The
demonstrators held masks of Jeff Bezos, the chief
executive.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Elaine
Thompson/Associated
Press</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/04/03/business/03amazonletter1/merlin_146148123_26da2645-ae5a-4651-aef5-b8736ba6698b-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-xt80pu e12qa4dv0">

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz" itemprop="name">Cade
Metz</span>](https://www.nytimes3xbfgragh.onion/by/cade-metz) and
[<span class="css-1baulvz last-byline" itemprop="name">Natasha
Singer</span>](https://www.nytimes3xbfgragh.onion/by/natasha-singer)

</div>

</div>

  - April 3,
    2019

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

SAN FRANCISCO — At least 25 prominent artificial-intelligence
researchers, including experts at Google, Facebook, Microsoft and a
recent winner of [the prestigious Turing
Award](https://www.nytimes3xbfgragh.onion/2019/03/27/technology/turing-award-ai.html),
have signed a letter calling on Amazon to stop selling its
facial-recognition technology to law enforcement agencies because it is
biased against women and people of color.

The letter, which was publicly released Wednesday, reflects growing
concern in academia and the tech industry that bias in
facial-recognition technology is a systemic problem. Some researchers —
and even some companies — are arguing the technology cannot be properly
controlled without government regulation.

Amazon sells a product called Rekognition through its cloud-computing
division, Amazon Web Services. The company said last year that early
customers included the Orlando Police Department in Florida and the
Washington County Sheriff’s Office in Oregon.

In January, two researchers at the Massachusetts Institute of Technology
[published a peer-reviewed
study](https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html)
showing that Amazon Rekognition had more trouble identifying the gender
of female and darker-skinned faces in photos than similar services from
IBM and Microsoft. It mistook women for men 19 percent of the time, the
study showed, and misidentified darker-skinned women for men 31 percent
of the time.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Before publishing their findings on Amazon Rekognition, the M.I.T.
researchers released a similar study examining services from IBM,
Microsoft and Megvii, an artificial-intelligence company in China. All
three updated their services to address concerns raised by the
researchers.

In separate blog posts from the Amazon executives [Matthew
Wood](https://aws.amazon.com/blogs/machine-learning/thoughts-on-recent-research-paper-and-associated-article-on-amazon-rekognition/)
and [Michael
Punke](https://aws.amazon.com/blogs/machine-learning/some-thoughts-on-facial-recognition-legislation/),
the company disputed the study and [a Jan. 24
article](https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html)
in The New York Times describing it.

“The answer to anxieties over new technology is not to run ‘tests’
inconsistent with how the service is designed to be used, and to amplify
the test’s false and misleading conclusions through the news media,” Dr.
Wood wrote. Amazon did not directly engage with the M.I.T. researchers.

The letter released on Wednesday was signed by the Google researchers
Margaret Mitchell, Andrea Frome and Timnit Gebru; the Facebook
researcher Georgia Gkioxari; William Isaac, a researcher at DeepMind,
the London lab owned by Google’s parent company, Alphabet; and Yoshua
Bengio, one of the world’s most important A.I. researchers.

Last week, Dr. Bengio was one of three people to receive the Turing
Award — often called “the Nobel Prize of computing” — for his work with
[neural
networks](https://www.nytimes3xbfgragh.onion/2018/03/06/technology/google-artificial-intelligence.html),
the technology that underpins modern facial recognition services.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“There are no laws or required standards to ensure that Rekognition is
used in a manner that does not infringe on civil liberties,” the A.I.
researchers wrote. “We call on Amazon to stop selling Rekognition to law
enforcement.”

The researchers added that Dr. Wood and Mr. Punke had “misrepresented
the technical details” of the M.I.T. study and modern facial-recognition
technology. Amazon declined to comment on the letter on Wednesday.

A day after this article was published, an Amazon spokeswoman responded,
saying that the company had updated its Rekognition service since the
M.I.T. researchers completed their study and that it had found no
differences in error rates by gender and race when running similar
tests.

Microsoft, by contrast, [improved the
accuracy](https://blogs.microsoft.com/ai/gender-skin-tone-facial-recognition-improvement/)
of its facial recognition last year after an earlier M.I.T. study
reported that its system was better at identifying the gender of
lighter-skinned men in a photo database than darker-skinned women.

During a February talk at the Cornell Tech graduate school in New York,
Brad Smith, Microsoft’s president and chief legal officer, said the
company had “participated in the market for law enforcement in the
United States,” but had also turned down sales when there was concern it
could unreasonably infringe on people’s rights.

In February, Microsoft backed a bill in Washington State that would
require notices to be posted in public places using facial-recognition
tech and ensure that government agencies obtain a court order when
looking for specific people. The bill is still pending. But the company
did not back other legislation that provides much stronger protections.

Mr. Punke wrote in his February blog post that Amazon also supported
regulation of facial-recognition technology and called for law
enforcement agencies to “be transparent in how they use
facial-recognition technology.” But Amazon has declined to disclose how
police or intelligence agencies are using its Rekognition system and
whether the company puts any restrictions on its use.

Amazon has said that it has not received any reports of Rekognition
misuse by law enforcement, and that the company’s acceptable use policy
prohibits customers from using its services in ways that violate laws.

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
