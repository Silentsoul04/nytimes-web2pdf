<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[U.S.](https://www.nytimes3xbfgragh.onion/section/us)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes3xbfgragh.onion/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes3xbfgragh.onion/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[U.S.](/section/us)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">San
Francisco Bans Facial Recognition
Technology</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2VG3Zr9</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 
  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-1vkm6nb ehdk2mb0">

# San Francisco Bans Facial Recognition Technology

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Attendees
interacting with a facial recognition demonstration at this year’s CES
in Las
Vegas.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Joe
Buglewicz for The New York
Times</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/05/14/us/14facialrecognition-01/14facialrecognition-01-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-xt80pu e12qa4dv0">

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz" itemprop="name">Kate
Conger</span>](https://www.nytimes3xbfgragh.onion/by/kate-conger),
[<span class="css-1baulvz" itemprop="name">Richard
Fausset</span>](https://www.nytimes3xbfgragh.onion/by/richard-fausset)
and [<span class="css-1baulvz last-byline" itemprop="name">Serge F.
Kovaleski</span>](https://www.nytimes3xbfgragh.onion/by/serge-f-kovaleski)

</div>

</div>

  - May 14,
    2019

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

SAN FRANCISCO — San Francisco, long at the heart of the technology
revolution, took a stand against potential abuse on Tuesday by banning
the use of facial recognition software by the police and other agencies.

The action, which came in an 8-to-1 vote by the Board of Supervisors,
makes San Francisco the first major American city to block a tool that
many police forces are turning to in the search for both [small-time
criminal
suspects](https://www.washingtonpost.com/technology/2019/04/30/amazons-facial-recognition-technology-is-supercharging-local-police/)
and perpetrators of mass carnage.

The authorities used the technology to help identify the suspect [in the
mass
shooting](https://www.nytimes3xbfgragh.onion/2019/04/29/us/capital-gazette-shooting-suspect.html)
at an Annapolis, Md., newspaper last June. But civil liberty groups have
expressed unease about the technology’s potential abuse by government
amid fears that it may shove the United States in the direction of an
overly oppressive surveillance state.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*\[Facial recognition technology has stoked controversy over the years.*
[*Here’s a look
back*](https://www.nytimes3xbfgragh.onion/2019/05/15/business/facial-recognition-software-controversy.html?action=click&module=Intentional&pgtype=Article)*.\]*

Aaron Peskin, the city supervisor who sponsored the bill, said that it
sent a particularly strong message to the nation, coming from a city
transformed by tech.

</div>

</div>

![<span class="css-16f3y1r e13ogyst0">San Francisco banned the use of
facial recognition software by the police and other agencies on Tuesday.
The city is one of the first to block this
tool.</span><span class="css-cch8ym"><span class="css-1dv1kvn">Credit</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Eric
Risberg/Associated
Press</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/05/14/us/14facialrecognition-02/merlin_154763151_db66aec5-ab5c-437a-9586-4f9b5a5dda0f-videoSixteenByNine3000.jpg)

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“I think part of San Francisco being the real and perceived headquarters
for all things tech also comes with a responsibility for its local
legislators,” Mr. Peskin said. “We have an outsize responsibility to
regulate the excesses of technology precisely because they are
headquartered here.”

But critics said that rather than focusing on bans, the city should find
ways to craft regulations that acknowledge the usefulness of face
recognition. “It is ridiculous to deny the value of this technology in
securing airports and border installations,” said Jonathan Turley, a
constitutional law expert at George Washington University. “It is hard
to deny that there is a public safety value to this technology.”

There will be an obligatory second vote next week, but it is seen as a
formality.

Similar bans are under consideration in Oakland and in Somerville,
Mass., outside of Boston. In Massachusetts, a
[bill](https://malegislature.gov/Bills/191/S1385) in the State
Legislature would put a moratorium on facial recognition and other
remote biometric surveillance systems. On Capitol Hill, a
[bill](https://www.congress.gov/bill/116th-congress/senate-bill/847)
introduced last month would ban users of commercial face recognition
technology from collecting and sharing data for identifying or tracking
consumers without their consent, although it does not address the
government’s uses of the technology.

Matt Cagle, a lawyer with the A.C.L.U. of Northern California, on
Tuesday summed up the broad concerns of facial recognition: The
technology, he said, “provides government with unprecedented power to
track people going about their daily lives. That’s incompatible with a
healthy democracy.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The San Francisco proposal, he added, “is really forward-looking and
looks to prevent the unleashing of this dangerous technology against the
public.”

In one form or another, facial recognition is already being used in many
American airports and big stadiums, and by a number of other police
departments. The pop star Taylor Swift has reportedly incorporated the
technology at one of her shows, using it to [help identify
stalkers](https://www.nytimes3xbfgragh.onion/2018/12/13/arts/music/taylor-swift-facial-recognition.html).

The facial recognition fight in San Francisco is largely theoretical —
the police department does not currently deploy such technology, and it
is only in use at the international airport and ports that are under
federal jurisdiction and are not impacted by the legislation.

Some local homeless shelters use biometric finger scans and photos to
track shelter usage, said Jennifer Friedenbach, the executive director
of the Coalition on Homelessness. The practice has driven undocumented
residents away from the shelters, she said.

Still, it has been a particularly charged topic in a city with a rich
history of incubating dissent and individual liberties, but one that has
also suffered lately from [high
rates](https://www.nytimes3xbfgragh.onion/2018/06/06/us/-homelessness-housing-san-francisco.html)
of property crime.

The ban prohibits city agencies from using facial recognition
technology, or information gleaned from external systems that use the
technology. It is part of a larger legislative package devised to govern
the use of surveillance technologies in the city that requires local
agencies to create policies controlling their use of these tools. There
are some exemptions, including one that would give prosecutors a way out
if the transparency requirements might interfere with their
investigations.

Still, the San Francisco Police Officers Association, an officers’
union, said the ban would hinder their members’ efforts to investigate
crime.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Although we understand that it’s not a 100 percent accurate technology
yet, it’s still evolving,” said Tony Montoya, the president of the
association. “I think it has been successful in at least providing leads
to criminal investigators.”

Mr. Cagle and other experts said that it was difficult to know exactly
how widespread the technology was in the United States. “Basically,
governments and companies have been very secretive about where it’s
being used, so the public is largely in the dark about the state of
play,” he said.

But Dave Maass, the senior investigative researcher at the Electronic
Frontier Foundation, offered a partial list of police departments that
he said used the technology, including Las Vegas, Orlando, San Jose, San
Diego, New York City, Boston, Detroit and Durham, N.C.

Other users, Mr. Maass said, include the Colorado Department of Public
Safety, the Pinellas County Sheriff’s Office in Florida, the California
Department of Justice and the Virginia State Police.

U.S. Customs and Border Protection is now using facial recognition in
many airports and ports of sea entry. At airports, international
travelers stand before cameras, then have their pictures matched against
photos provided in their passport applications. The agency says the
process complies with privacy laws, but it has still come in for
criticism from the Electronic Privacy Information Center, which argues
that the government, though promising travelers that they may opt out,
has made it increasingly difficult to do so.

But there is a broader concern. “When you have the ability to track
people in physical space, in effect everybody becomes subject to the
surveillance of the government,” said Marc Rotenberg, the group’s
executive director.

In the last few years, facial recognition technology has improved and
spread at lightning speed, powered by the rise of cloud computing,
machine learning and extremely precise digital cameras. That has meant
once-unimaginable new features for users of smartphones, who may now use
facial recognition to unlock their devices, and to tag and sort photos.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

But some experts fear the advances are outstripping government’s ability
to set guardrails to protect privacy.

Mr. Cagle and others said that a worst-case scenario already exists in
China, where facial recognition is used [to keep close
tabs](https://www.nytimes3xbfgragh.onion/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html)
on the Uighurs, a largely Muslim minority, and is being integrated into
a national [digital panopticon
system](https://www.nytimes3xbfgragh.onion/2018/07/08/business/china-surveillance-technology.html)
powered by roughly 200 million surveillance cameras.

American civil liberties advocates warn that the ability of facial
surveillance to identify people at a distance, or online, without their
knowledge or consent presents unique risks — threatening Americans’
ability to freely attend political protests or simply go about their
business anonymously in public. Last year, Bradford L. Smith, the
president of Microsoft, warned that the technology was too risky for
companies to police on their own and [asked Congress to oversee its
use](https://www.nytimes3xbfgragh.onion/2018/07/13/technology/microsoft-facial-recognition.html).

The battle over the technology intensified last year after [two
researchers published a
study](https://www.nytimes3xbfgragh.onion/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)
showing bias in some of the most popular facial surveillance systems.
Called Gender Shades, the study reported that systems from IBM and
Microsoft were much better at identifying the gender of white men’s
faces than they were at identifying the gender of darker-skinned or
female faces.

Another study this year [reported similar problems with Amazon’s
technology](https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html),
called Rekognition. Microsoft and IBM have since said they improved
their systems, while [Amazon has said it updated its system since the
researchers tested it and had found no differences in
accuracy](https://www.nytimes3xbfgragh.onion/2019/04/03/technology/amazon-facial-recognition-technology.html).

Warning that African-Americans, women and others could [easily be
incorrectly
identified](https://www.nytimes3xbfgragh.onion/2018/07/26/technology/amazon-aclu-facial-recognition-congress.html)
as suspects and wrongly arrested, the American Civil Liberties Union and
other nonprofit groups last year called on Amazon to stop selling its
technology to law enforcement.

But even with improvements in accuracy, civil rights advocates and
researchers warn that, in the absence of government oversight, the
technology could easily be misused to surveil immigrants or unfairly
target African-Americans or low-income neighborhoods. In a recent essay,
Luke Stark, a postdoctoral researcher at Microsoft Research Montreal,
described facial surveillance as “the plutonium of artificial
intelligence,” arguing that it should be “recognized as anathema to the
health of human society, and heavily restricted as a result.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Alvaro Bedoya, who directs Georgetown University’s Center on Privacy and
Technology, said that more than 30 states allow local or state
authorities, or the F.B.I., to search their driver’s license photos.

Mr. Bedoya said that these images are tantamount to being in a perpetual
police lineup, as law enforcement agencies use them to check against the
faces of suspected criminals. He said that the difference is that an
algorithm, not a human being, is pointing to the suspect.

He also said that comprehensive regulation of the technology is sorely
lacking. “This is the most pervasive and risky surveillance technology
of the 21st century,” he said.

Daniel Castro, director of the Center for Data Innovation at the
Information Technology and Innovation Foundation, is among those who
opposed the idea of a ban. He said he would prefer to see
face-recognition data accessible to the police only if they have secured
a warrant from a judge, following guidelines the Supreme Court has set
for [other
forms](https://www.nytimes3xbfgragh.onion/2012/01/24/us/police-use-of-gps-is-ruled-unconstitutional.html)of
electronic surveillance.

But proponents of the bans say they are an effort to hit the pause
button and study the matter before harm is done. The proposed ban in
Somerville, the Boston suburb, was sponsored by a councilor, Ben
Ewen-Campen. “The government and the public don’t have a handle on what
the technology is and what it will become,” he said on Tuesday.

Next door in Boston, Ed Davis, the former police commissioner, said it
was “premature to be banning things.” Mr. Davis, who led the department
during the Boston Marathon attack, said that no one in the United States
wanted to follow the Chinese model.

But he also sees the potential. “This technology is still developing,”
he said, “and as it improves, this could be the answer to a lot of
problems we have about securing our communities.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Joel Engardio, the vice president of Stop Crime SF, said that he agreed
that current facial recognition technologies were flawed, but said that
the city should not prohibit their use in the future, if they were
improved.

“Instead of an outright ban, why not a moratorium?” Mr. Engardio asked.
“Let’s keep the door open for when the technology improves. I’m not a
fan of banning things when eventually it could actually be helpful.”

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
