<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Business](https://www.nytimes3xbfgragh.onion/section/business)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes3xbfgragh.onion/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes3xbfgragh.onion/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Business](/section/business)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">Facial
Recognition’s Many Controversies, From Stadium Surveillance to Racist
Software</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/30ohhHp</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-1vkm6nb ehdk2mb0">

# Facial Recognition’s Many Controversies, From Stadium Surveillance to Racist Software

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">The use of
facial recognition technology in the public and private sectors has long
been the subject of intense
debate.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>David
Mcnew/Agence France-Presse — Getty
Images</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/05/15/multimedia/15xp-face/merlin_154874394_ed81e779-d275-4298-b984-bdb066b7711d-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-xt80pu e12qa4dv0">

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Niraj
Chokshi</span>](https://www.nytimes3xbfgragh.onion/by/niraj-chokshi)

</div>

</div>

  - May 15,
    2019

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The long-raging debate around facial recognition software, with all the
privacy worries it brings with it, has taken on new urgency as the
technology has improved and spread by leaps and bounds.

On Tuesday, San Francisco became the first major American city to [block
police and other law enforcement
agencies](https://www.nytimes3xbfgragh.onion/2019/05/14/us/facial-recognition-ban-san-francisco.html)
from using the software.

Here is a look back at some of the many controversies over facial
recognition and its use.

## The 2001 Super Bowl

In January 2001, the city of Tampa, Fla., used a facial recognition
surveillance system as it hosted Super Bowl XXXV.

It was an early real-world example of how the technology could be used
and prompted a backlash from privacy advocates [including the American
Civil Liberties
Union](https://www.aclu.org/other/use-facial-recognition-super-bowl-and-tampa).

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The system identified 19 people thought to be subjects of outstanding
warrants, though none were arrested. The police were not prepared for
the number of matches, nor for the difficulty of finding and arresting
the identified individuals.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Aaron
Peskin, a member of the San Francisco Board of Supervisors, speaking
before the city’s vote on facial recognition technology on
Tuesday.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Jeffrey
Dastin/Reuters</span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/05/15/multimedia/15xp-face2/merlin_154849260_86d298e3-f266-4c62-9aa8-388032423c7b-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“We thought we were ready to use it, but getting through the crowd and
the architecture of the stadium proved overwhelming,” [Detective Bill
Todd said at the
time](https://www.nytimes3xbfgragh.onion/2001/07/04/us/tampa-scans-the-faces-in-its-crowds-for-criminals.html).

## The webcam that doesn’t see black people

A decade ago, Desi Cryer [uploaded a video to
YouTube](https://www.youtube.com/watch?v=t4DT3tQqgRM) in which he showed
that Hewlett-Packard’s new face-tracking web camera did not appear to
see black people.

The camera [failed to track Mr.
Cryer](http://www.cnn.com/2009/TECH/12/22/hp.webcams/), who is black,
but had no problem following his white colleague, Wanda Zamen, when she
entered its field of vision.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

At the time, Mr. Cryer said he found the situation amusing, but it
portended the more serious potential of bias to be baked into facial
recognition and artificial intelligence systems.

## The Snowden revelations

In 2014, The New York Times reported that the National Security Agency
had intercepted millions of images a day, [tens of thousands of which
were identified as “facial recognition
quality,”](https://www.nytimes3xbfgragh.onion/2014/06/01/us/nsa-collecting-millions-of-faces-from-web-images.html)
according to documents obtained by Edward J.
Snowden.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:579.3555555555556px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Joy
Buolamwini, a researcher at the M.I.T. Media Lab, has emerged as an
advocate in the new field of “algorithmic
accountability.”</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Tony
Luong for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

That revelation raised concerns among civil liberties advocates. At the
time, the technology was still seen as nascent, though experts noted
that methods to analyze such data were constantly improving.

“There are still technical limitations on it, but the computational
power keeps growing, and the databases keep growing, and the algorithms
keep improving,” Alessandro Acquisti, a researcher on facial recognition
technology at Carnegie Mellon University at the time, [told The
Times](https://www.nytimes3xbfgragh.onion/2014/06/01/us/nsa-collecting-millions-of-faces-from-web-images.html).

## The race problems continue

In 2015, Google
[apologized](https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/)
after its then-new Photos application labeled some black people as
“gorillas.” The company said in a statement that it was “appalled and
genuinely sorry,” but it was just one of many examples of facial
recognition technology’s racial failings.

Last year, [The Times reported on the findings of a Massachusetts
Institute of Technology
researcher](https://www.nytimes3xbfgragh.onion/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)
who found that some facial recognition software could identify a white
man with near-perfect precision, but failed spectacularly at identifying
a darker-skinned woman.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The problem, in part, is that facial recognition is only as good as the
examples on which it is trained. And one widely used data set was
estimated to be more than 75 percent male and more than 80 percent
white.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:257.77777777777777px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Fans
arriving at Madison Square Garden for the Big East Conference men’s
basketball tournament. The Garden has used facial-recognition technology
to identify people entering the
building.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Benjamin
Norman for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## Facial recognition at entertainment venues

Last year, The Times reported that Madison Square Garden [had been
quietly
using](https://www.nytimes3xbfgragh.onion/2018/03/13/sports/facial-recognition-madison-square-garden.html?module=inline)
facial-scanning technology for security.

But some vendors and team officials said that using the technology for
customer engagement and marketing could be even more valuable for sports
facilities than for security.

Advocates pushed back.

“We are in a kind of legal Wild West when it comes to this stuff,” Jay
Stanley, a policy analyst at the A.C.L.U., told The Times. “I should
know if I am being subject to facial recognition if I am going into any
business, including a stadium.”

Such technology was also [reportedly
used](https://www.nytimes3xbfgragh.onion/2018/12/13/arts/music/taylor-swift-facial-recognition.html)
at Taylor Swift concerts to identify potential stalkers.

## Microsoft calls for regulations

In July, Microsoft became the first tech giant to join civil liberties
advocates and others in [calling for federal regulations on facial
recognition](https://www.nytimes3xbfgragh.onion/2018/07/13/technology/microsoft-facial-recognition.html).

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

In a blog post, Bradford L. Smith, the company’s president, urged
Congress to take action.

“We live in a nation of laws, and the government needs to play an
important role in regulating facial recognition technology,” he
said.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:257.77777777777777px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">A visitor in
Shanghai testing a facial recognition system by SenseTime, an artificial
intelligence
company.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Gilles
Sabrié for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Mr. Smith suggested that Congress appointed a commission to study the
issue and oversee the technology’s use.

## Worries about a potential for bias in Amazon’s technology

A study this year raised concerns about Rekognition, a facial
recognition system that Amazon had aggressively marketed in recent years
to local and federal law enforcement.

In the study, the M.I.T. Media Lab found that the system misclassified
women as men 19 percent of the time and mistook darker-skinned women for
men 31 percent of the time.

“Not only do I want to see them address our concerns with the sense of
urgency it deserves,” Representative Jimmy Gomez, a California Democrat
who has investigated Amazon’s facial recognition practices, [told The
Times](https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html),
“but I also want to know if law enforcement is using it in ways that
violate civil liberties, and what — if any — protections Amazon has
built into the technology to protect the rights of our constituents.”

## China using it to profile Uighurs

For years, privacy advocates have warned that governments could use such
software for nefarious purposes. Last month, The Times reported that
[China was the first known government that used it for racial
profiling](https://www.nytimes3xbfgragh.onion/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html),
according to experts.

The country has been using a wide-ranging, secret facial recognition
system to track and control the Uighurs, a largely Muslim minority, The
Times reported.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The advanced system is integrated into China’s growing network of
surveillance cameras and is constantly tracking where Uighurs come and
go.

“If you make a technology that can classify people by an ethnicity,
someone will use it to repress that ethnicity,” Clare Garvie, an
associate at the Center on Privacy and Technology at Georgetown Law,
said at the time.

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
