Sections

SEARCH

\protect\hyperlink{site-content}{Skip to
content}\protect\hyperlink{site-index}{Skip to site index}

\href{https://www.nytimes3xbfgragh.onion/section/business}{Business}

\href{https://myaccount.nytimes3xbfgragh.onion/auth/login?response_type=cookie\&client_id=vi}{}

\href{https://www.nytimes3xbfgragh.onion/section/todayspaper}{Today's
Paper}

\href{/section/business}{Business}\textbar{}Facial Recognition's Many
Controversies, From Stadium Surveillance to Racist Software

\url{https://nyti.ms/30ohhHp}

\begin{itemize}
\item
\item
\item
\item
\item
\end{itemize}

Advertisement

\protect\hyperlink{after-top}{Continue reading the main story}

Supported by

\protect\hyperlink{after-sponsor}{Continue reading the main story}

\hypertarget{facial-recognitions-many-controversies-from-stadium-surveillance-to-racist-software}{%
\section{Facial Recognition's Many Controversies, From Stadium
Surveillance to Racist
Software}\label{facial-recognitions-many-controversies-from-stadium-surveillance-to-racist-software}}

\includegraphics{https://static01.graylady3jvrrxbe.onion/images/2019/05/15/multimedia/15xp-face/merlin_154874394_ed81e779-d275-4298-b984-bdb066b7711d-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

By \href{https://www.nytimes3xbfgragh.onion/by/niraj-chokshi}{Niraj
Chokshi}

\begin{itemize}
\item
  May 15, 2019
\item
  \begin{itemize}
  \item
  \item
  \item
  \item
  \item
  \end{itemize}
\end{itemize}

The long-raging debate around facial recognition software, with all the
privacy worries it brings with it, has taken on new urgency as the
technology has improved and spread by leaps and bounds.

On Tuesday, San Francisco became the first major American city to
\href{https://www.nytimes3xbfgragh.onion/2019/05/14/us/facial-recognition-ban-san-francisco.html}{block
police and other law enforcement agencies} from using the software.

Here is a look back at some of the many controversies over facial
recognition and its use.

\hypertarget{the-2001-super-bowl}{%
\subsection{The 2001 Super Bowl}\label{the-2001-super-bowl}}

In January 2001, the city of Tampa, Fla., used a facial recognition
surveillance system as it hosted Super Bowl XXXV.

It was an early real-world example of how the technology could be used
and prompted a backlash from privacy advocates
\href{https://www.aclu.org/other/use-facial-recognition-super-bowl-and-tampa}{including
the American Civil Liberties Union}.

The system identified 19 people thought to be subjects of outstanding
warrants, though none were arrested. The police were not prepared for
the number of matches, nor for the difficulty of finding and arresting
the identified individuals.

\includegraphics{https://static01.graylady3jvrrxbe.onion/images/2019/05/15/multimedia/15xp-face2/merlin_154849260_86d298e3-f266-4c62-9aa8-388032423c7b-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

``We thought we were ready to use it, but getting through the crowd and
the architecture of the stadium proved overwhelming,''
\href{https://www.nytimes3xbfgragh.onion/2001/07/04/us/tampa-scans-the-faces-in-its-crowds-for-criminals.html}{Detective
Bill Todd said at the time}.

\hypertarget{the-webcam-that-doesnt-see-black-people}{%
\subsection{The webcam that doesn't see black
people}\label{the-webcam-that-doesnt-see-black-people}}

A decade ago, Desi Cryer
\href{https://www.youtube.com/watch?v=t4DT3tQqgRM}{uploaded a video to
YouTube} in which he showed that Hewlett-Packard's new face-tracking web
camera did not appear to see black people.

The camera \href{http://www.cnn.com/2009/TECH/12/22/hp.webcams/}{failed
to track Mr. Cryer}, who is black, but had no problem following his
white colleague, Wanda Zamen, when she entered its field of vision.

At the time, Mr. Cryer said he found the situation amusing, but it
portended the more serious potential of bias to be baked into facial
recognition and artificial intelligence systems.

\hypertarget{the-snowden-revelations}{%
\subsection{The Snowden revelations}\label{the-snowden-revelations}}

In 2014, The New York Times reported that the National Security Agency
had intercepted millions of images a day,
\href{https://www.nytimes3xbfgragh.onion/2014/06/01/us/nsa-collecting-millions-of-faces-from-web-images.html}{tens
of thousands of which were identified as ``facial recognition
quality,''} according to documents obtained by Edward J. Snowden.

Image

Joy Buolamwini, a researcher at the M.I.T. Media Lab, has emerged as an
advocate in the new field of ``algorithmic
accountability.''Credit...Tony Luong for The New York Times

That revelation raised concerns among civil liberties advocates. At the
time, the technology was still seen as nascent, though experts noted
that methods to analyze such data were constantly improving.

``There are still technical limitations on it, but the computational
power keeps growing, and the databases keep growing, and the algorithms
keep improving,'' Alessandro Acquisti, a researcher on facial
recognition technology at Carnegie Mellon University at the time,
\href{https://www.nytimes3xbfgragh.onion/2014/06/01/us/nsa-collecting-millions-of-faces-from-web-images.html}{told
The Times}.

\hypertarget{the-race-problems-continue}{%
\subsection{The race problems
continue}\label{the-race-problems-continue}}

In 2015, Google
\href{https://www.usatoday.com/story/tech/2015/07/01/google-apologizes-after-photos-identify-black-people-as-gorillas/29567465/}{apologized}
after its then-new Photos application labeled some black people as
``gorillas.'' The company said in a statement that it was ``appalled and
genuinely sorry,'' but it was just one of many examples of facial
recognition technology's racial failings.

Last year,
\href{https://www.nytimes3xbfgragh.onion/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html}{The
Times reported on the findings of a Massachusetts Institute of
Technology researcher} who found that some facial recognition software
could identify a white man with near-perfect precision, but failed
spectacularly at identifying a darker-skinned woman.

The problem, in part, is that facial recognition is only as good as the
examples on which it is trained. And one widely used data set was
estimated to be more than 75 percent male and more than 80 percent
white.

Image

Fans arriving at Madison Square Garden for the Big East Conference men's
basketball tournament. The Garden has used facial-recognition technology
to identify people entering the building.Credit...Benjamin Norman for
The New York Times

\hypertarget{facial-recognition-at-entertainment-venues}{%
\subsection{Facial recognition at entertainment
venues}\label{facial-recognition-at-entertainment-venues}}

Last year, The Times reported that Madison Square Garden
\href{https://www.nytimes3xbfgragh.onion/2018/03/13/sports/facial-recognition-madison-square-garden.html?module=inline}{had
been quietly using} facial-scanning technology for security.

But some vendors and team officials said that using the technology for
customer engagement and marketing could be even more valuable for sports
facilities than for security.

Advocates pushed back.

``We are in a kind of legal Wild West when it comes to this stuff,'' Jay
Stanley, a policy analyst at the A.C.L.U., told The Times. ``I should
know if I am being subject to facial recognition if I am going into any
business, including a stadium.''

Such technology was also
\href{https://www.nytimes3xbfgragh.onion/2018/12/13/arts/music/taylor-swift-facial-recognition.html}{reportedly
used} at Taylor Swift concerts to identify potential stalkers.

\hypertarget{microsoft-calls-for-regulations}{%
\subsection{Microsoft calls for
regulations}\label{microsoft-calls-for-regulations}}

In July, Microsoft became the first tech giant to join civil liberties
advocates and others in
\href{https://www.nytimes3xbfgragh.onion/2018/07/13/technology/microsoft-facial-recognition.html}{calling
for federal regulations on facial recognition}.

In a blog post, Bradford L. Smith, the company's president, urged
Congress to take action.

``We live in a nation of laws, and the government needs to play an
important role in regulating facial recognition technology,'' he said.

Image

A visitor in Shanghai testing a facial recognition system by SenseTime,
an artificial intelligence company.Credit...Gilles Sabri√© for The New
York Times

Mr. Smith suggested that Congress appointed a commission to study the
issue and oversee the technology's use.

\hypertarget{worries-about-a-potential-for-bias-in-amazons-technology}{%
\subsection{Worries about a potential for bias in Amazon's
technology}\label{worries-about-a-potential-for-bias-in-amazons-technology}}

A study this year raised concerns about Rekognition, a facial
recognition system that Amazon had aggressively marketed in recent years
to local and federal law enforcement.

In the study, the M.I.T. Media Lab found that the system misclassified
women as men 19 percent of the time and mistook darker-skinned women for
men 31 percent of the time.

``Not only do I want to see them address our concerns with the sense of
urgency it deserves,'' Representative Jimmy Gomez, a California Democrat
who has investigated Amazon's facial recognition practices,
\href{https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html}{told
The Times}, ``but I also want to know if law enforcement is using it in
ways that violate civil liberties, and what --- if any --- protections
Amazon has built into the technology to protect the rights of our
constituents.''

\hypertarget{china-using-it-to-profile-uighurs}{%
\subsection{China using it to profile
Uighurs}\label{china-using-it-to-profile-uighurs}}

For years, privacy advocates have warned that governments could use such
software for nefarious purposes. Last month, The Times reported that
\href{https://www.nytimes3xbfgragh.onion/2019/04/14/technology/china-surveillance-artificial-intelligence-racial-profiling.html}{China
was the first known government that used it for racial profiling},
according to experts.

The country has been using a wide-ranging, secret facial recognition
system to track and control the Uighurs, a largely Muslim minority, The
Times reported.

The advanced system is integrated into China's growing network of
surveillance cameras and is constantly tracking where Uighurs come and
go.

``If you make a technology that can classify people by an ethnicity,
someone will use it to repress that ethnicity,'' Clare Garvie, an
associate at the Center on Privacy and Technology at Georgetown Law,
said at the time.

Advertisement

\protect\hyperlink{after-bottom}{Continue reading the main story}

\hypertarget{site-index}{%
\subsection{Site Index}\label{site-index}}

\hypertarget{site-information-navigation}{%
\subsection{Site Information
Navigation}\label{site-information-navigation}}

\begin{itemize}
\tightlist
\item
  \href{https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice}{¬©~2020~The
  New York Times Company}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \href{https://www.nytco.com/}{NYTCo}
\item
  \href{https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us}{Contact
  Us}
\item
  \href{https://www.nytco.com/careers/}{Work with us}
\item
  \href{https://nytmediakit.com/}{Advertise}
\item
  \href{http://www.tbrandstudio.com/}{T Brand Studio}
\item
  \href{https://www.nytimes3xbfgragh.onion/privacy/cookie-policy\#how-do-i-manage-trackers}{Your
  Ad Choices}
\item
  \href{https://www.nytimes3xbfgragh.onion/privacy}{Privacy}
\item
  \href{https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service}{Terms
  of Service}
\item
  \href{https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale}{Terms
  of Sale}
\item
  \href{https://spiderbites.nytimes3xbfgragh.onion}{Site Map}
\item
  \href{https://help.nytimes3xbfgragh.onion/hc/en-us}{Help}
\item
  \href{https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW}{Subscriptions}
\end{itemize}
