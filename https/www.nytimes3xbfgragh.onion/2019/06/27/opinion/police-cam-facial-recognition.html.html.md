<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes3xbfgragh.onion/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes3xbfgragh.onion/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Opinion](/section/opinion)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">A
Major Police Body Cam Company Just Banned Facial
Recognition</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2X0iOAI</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 
  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div class="css-v5btjw etb61u70">

<div class="css-v05ibm etb61u71">

[Opinion](/section/opinion)

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# A Major Police Body Cam Company Just Banned Facial Recognition

</div>

Its ethics board says the technology is not reliable enough to justify
using.

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1p10dcb ey68jwv0" data-aria-hidden="true">

[![Charlie
Warzel](https://static01.graylady3jvrrxbe.onion/images/2019/03/15/opinion/charlie-warzel/charlie-warzel-thumbLarge-v3.png
"Charlie Warzel")](https://www.nytimes3xbfgragh.onion/by/charlie-warzel)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Charlie
Warzel</span>](https://www.nytimes3xbfgragh.onion/by/charlie-warzel)

<div class="css-8atqhb">

Mr. Warzel is an Opinion writer at large.

</div>

</div>

</div>

  - June 27,
    2019

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
      - 
    
    </div>
    
    </div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Claire
Merchlinsky</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/06/27/opinion/sunday/27Warzel/58268f35d5d84f90a5fc3be1d69c0130-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Axon, the company that supplies 47 out of the 69 largest police agencies
in the United States with body cameras and software, announced Thursday
that it would ban the use of facial recognition systems on its devices.

“Face recognition technology is not currently reliable enough to
ethically justify its use,” the company’s independent ethics board
concluded.

Even as facial recognition systems are rolled out by privacy companies —
from airlines to smartphone makers — institutions nationwide are balking
at government use of algorithmically powered surveillance tools.

In May, San Francisco’s Board of Supervisors [voted to
ban](https://www.nytimes3xbfgragh.onion/2019/05/14/us/facial-recognition-ban-san-francisco.html?module=inline)
use of facial recognition technology by the city’s police and other
agencies. Other cities, including
[Berkeley](https://www.govtech.com/public-safety/Oakland-Berkeley-Might-Follow-SFs-Facial-Recognition-Ban.html)
and
[Oakland](https://twitter.com/matt_cagle/status/1143725978293698565?s=12),
Calif., and Somerville, Mass., are also mulling or close on bans.
Earlier this month, [California lawmakers
announced](https://www.latimes.com/business/technology/la-fi-tn-face-recognition-ban-california-police-body-camera-20190607-story.html)
they’re considering a statewide ban on facial recognition in police body
cams.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

In a 28-page report, Axon’s ethics board, which was handpicked by
members of the Policing Project at New York University School of Law,
argued that the technology “does not perform as well on people of color
compared to whites, on women compared to men, or young people compared
to older people.”

The report also cautioned that facial recognition is especially prone to
inaccuracy when used with police body cameras, which frequently operate
in low-light conditions and produce shaky footage.

“The tech is just not accurate enough,” Barry Friedman, founding
director of N.Y.U.’s Policing Project and a member of the ethics board,
told me. “Until that’s fixed we don’t need to say another word. And that
could be
years.”

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006451534" data-slug="privacy-mid-nav-module" style="max-width:1050px">

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Axon’s move is a rare departure from the “move fast and break things”
style of innovation traditionally associated with new technologies. And
it may very well indicate that, when it comes to facial tracking and
privacy, policing may be where we draw the line.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

It’s a crucial moment for facial recognition. Though most police
departments have yet to deploy it, some uses by law enforcement have
been troubling.

This year researchers found that Detroit had [signed a $1 million
deal](https://www.nytimes3xbfgragh.onion/2019/05/16/opinion/columnists/facial-recognition-ban-privacy.html?rref=collection%2Fbyline%2Ffarhad-manjoo&action=click&contentCollection=undefined&region=stream&module=stream_unit&version=latest&contentPlacement=5&pgtype=collection)
with a vendor to continuously screen hundreds of public cameras
throughout the city without citizen approval. In May, Clare Garvie, a
facial recognition researcher at Georgetown Law, [revealed sketchy
tactics](https://www.nytimes3xbfgragh.onion/2019/05/16/opinion/columnists/facial-recognition-ban-privacy.html?rref=collection%2Fbyline%2Ffarhad-manjoo&action=click&contentCollection=undefined&region=stream&module=stream_unit&version=latest&contentPlacement=5&pgtype=collection)
used by the New York Police Department to match security camera footage
with potential suspects who looked like celebrities.

*\[If you’re online — and, well, you are — chances are someone is using
your information. We’ll tell you what you can do about it.* [*Sign up
for our limited-run
newsletter*](https://www.nytimes3xbfgragh.onion/newsletters/privacy-project?action=click&module=Intentional&pgtype=Article)*.\]*

The technical limitations and biases of facial recognition technology
are not well understood even by the companies that market the systems,
which makes oversight of its use in the real world particularly
problematic. Critics, meanwhile, worry that widespread deployment of the
technology risks laying the foundation of a comprehensive surveillance
state (just [look at
China](https://www.nytimes3xbfgragh.onion/interactive/2019/04/04/world/asia/xinjiang-china-surveillance-prison.html?module=inline)).

“There’s a race to the bottom right now with this technology, and the
challenge is to stop that elevator before it goes through the ground
floor,” Mr. Friedman said. It’s something Axon’s ethics board report
fought to change. According to the ethics board report, in early
conversations about facial recognition, Axon initially argued that it
“could not dictate to customers how products were used, nor its
customers’ policies, and that it could not feasibly patrol misuse of its
product.” That’s Big Tech’s version of “guns don’t kill people, people
kill people.” And it’s a view that’s very widely held across the
industry.

Mr. Friedman hopes that Axon’s pledge will force other vendors to think
about where the new technology might be headed and how it could impact
the most vulnerable. “We want them to remember that just because you can
build it, doesn’t mean you should.”

The ultimate goal of the ethics board goes a step further: forcing the
company to see that the customer for Axon products is not law
enforcement but “the community that those law enforcement and public
safety organizations serve.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Axon’s ban isn’t necessarily foolproof. An Axon representative confirmed
that law enforcement officials could potentially download Axon body cam
footage and then transfer it to a third-party service, like Amazon’s
Rekognition. However, Eric Piza, an associate professor at the John Jay
College of Criminal Justice, said that the process is time-consuming and
requires spending the money for yet another tech service. “If six
officers respond to a scene, that’s hours of manpower and extra expense,
which might reduce the likelihood they use the technology,” he said.

Still, Mr. Piza sees Axon’s moratorium as an important step. “Everyone’s
concerned about big data policing and that they put privacy above
short-term financials is not something that we see enough.”

Axon’s decision won’t completely stop law enforcement from using the
technology — police departments could still use it on surveillance
videos, for instance. And true progress will have to come from
regulation at the city, state or federal level.

But the move demonstrates the potential for independent ethics boards to
help guide technology companies whose products could drastically alter
public life. If the stewards of our biggest technology companies don’t
operate with an internal conscience, the least they could do is
outsource one.

*Like other media companies, The Times collects data on its visitors
when they read stories like this one. For more detail please see* [*our
privacy
policy*](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014892108-Privacy-policy?module=inline)
*and* [*our publisher's
description*](https://www.nytimes3xbfgragh.onion/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection%2Fspotlightcollection%2Fprivacy-project-does-privacy-matter&action=click&contentCollection=opinion&region=stream&module=stream_unit&version=latest&contentPlacement=8&pgtype=collection)
*of The Times's practices and continued steps to increase transparency
and protections.*

*Follow* [*@privacyproject*](https://twitter.com/privacyproject) *on
Twitter and The New York Times Opinion Section on*
[*Facebook*](https://www.facebookcorewwwi.onion/nytopinion)
*and*[*Instagram*](https://www.instagram.com/nytopinion/)*.*

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006450604" data-slug="privacy-collection" style="max-width:2000px">

</div>

</div>

<div id="privacy-glossary-embed" class="section interactive-content interactive-size-scoop css-bvtwvj" data-id="100000006427375">

## glossary replacer

<div class="css-17ih8de interactive-body" data-sourceid="100000006427375">

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
