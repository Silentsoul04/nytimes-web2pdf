<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-ikk3s8 e1suatyy0">

<div class="section css-133zg39 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[U.S.](/section/us)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">As
Cameras Track Detroit’s Residents, a Debate Ensues Over Racial
Bias</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2JtnB94</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-11qgg8s">

</div>

<div id="fullBleedHeaderContent">

<div class="css-9fsmc8">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Surveillance
cameras have been deployed across Detroit as part of Project Green
Light, which is meant to deter
crime.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Brittany
Greeson for The New York
Times</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/07/02/us/00greenlight-01/merlin_156466074_e9dc031b-f704-4eda-bee4-a7d86adb1106-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

<div class="css-1aqq9tq">

<div class="css-1vkm6nb ehdk2mb0">

# As Cameras Track Detroit’s Residents, a Debate Ensues Over Racial Bias

</div>

Studies have shown that facial recognition software can return more
false matches for African-Americans than for white people, a sign of
what experts call “algorithmic bias.”

</div>

<div class="css-nwzfg5 e1gnum310">

<span class="css-1f9pvn2 us">Surveillance cameras have been deployed
across Detroit as part of Project Green Light, which is meant to deter
crime.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Brittany
Greeson for The New York Times</span></span></span>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-1wx1auc e1gnum311">

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Amy
Harmon</span>](https://www.nytimes3xbfgragh.onion/by/amy-harmon)

</div>

</div>

  - July 8,
    2019

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*\[For more coverage of race,* *[sign up
here](https://www.nytimes3xbfgragh.onion/2018/10/01/us/subscribe-race-related-newsletter.html?module=inline)*
*to have our Race/Related newsletter delivered weekly to your inbox.\]*

DETROIT — Twenty-four hours a day, video from [thousands of
cameras](https://detroitmi.gov/webapp/project-green-light-map) stationed
around Detroit, at gas stations, restaurants, mini-marts, apartment
buildings, churches and schools, streams into the Police Department’s
downtown headquarters.

The surveillance program, which began in 2016, is the opposite of
covert. A flashing green light marks each participating location, and
the point of the popular initiative, known as Project Green Light, has
been for the cameras to be noticed and help deter crime. Detroit’s
mayor, Mike Duggan, received applause when he promised at his [State of
the City address](https://www.youtube.com/watch?v=dXAZoMCl3qs) earlier
this year that expanding the network to include several hundred traffic
light cameras would allow the police to “track any shooter or carjacker
across the city.”

But in recent weeks, a public outcry has erupted over a less-touted tool
employed in conjunction with the cameras: software that can, in a matter
of seconds, suggest the identities of the anonymous people captured on
video.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The facial recognition program matches the faces picked up across the
city against 50 million driver’s license photographs and mug shots
contained in a Michigan police database. The practice has attracted
public attention recently as the department seeks approval for a [formal
policy](https://detroitmi.gov/document/facial-recognition) governing its
use from a [civilian oversight
board](https://detroitmi.gov/government/boards/board-police-commissioners).

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Video from
the cameras streams into the Police Department’s downtown
headquarters.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Brittany
Greeson for The New York
Times</span></span>](https://static01.graylady3jvrrxbe.onion/images/2019/07/09/us/09Greenlight-Print/merlin_156466131_cdc242e2-0883-4605-9436-acc01b7faa9c-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Please, facial recognition software — that’s too far,” pleaded one
resident at a recent meeting of the board.

The debate in Detroit is one of [several unfolding around the
country](https://www.nytimes3xbfgragh.onion/2019/07/01/us/facial-recognition-san-francisco.html)
as [rapid advances in facial
recognition](https://www.nytimes3xbfgragh.onion/2017/11/28/technology/artificial-intelligence-research-toronto.html)
offer potentially disquieting new powers to a [surveillance
infrastructure](https://www.nytimes3xbfgragh.onion/2018/05/26/us/chicago-police-surveillance.html)that
Americans have largely accepted as a fact of urban life. [Immigration
officials have
mined](https://www.nytimes3xbfgragh.onion/2019/07/07/us/politics/ice-drivers-licenses-facial-recognition.html)
driver’s license databases in at least three states, according to newly
released records. The F.B.I. also routinely uses facial recognition
technology to scan state driver’s license databases without the approval
or knowledge of the license-holders, which a bipartisan group of
lawmakers said last month raises privacy concerns.

In Detroit, whose share of black residents is larger than in any other
sizable American city, it is a racial disparity in the performance of
facial recognition technology that is a primary source of consternation.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Facial recognition software proves to be less accurate at identifying
people with darker pigmentation,” George Byers II, a black software
engineer, told the police board last month. “We live in a major black
city. That’s a problem.”

Researchers at the Massachusetts Institute of Technology [reported in
January](https://www.nytimes3xbfgragh.onion/2019/01/24/technology/amazon-facial-technology-study.html)
that facial recognition software marketed by Amazon misidentified
darker-skinned women as men 31 percent of the time. Others have shown
that algorithms used in facial recognition [return false matches at a
higher rate for African-Americans](https://arxiv.org/pdf/1904.07325.pdf)
than white people unless explicitly recalibrated for a black population
— in which case their failure rate at finding positive matches for
white people climbs. [That study](https://arxiv.org/pdf/1904.07325.pdf),
posted in May by computer scientists at the Florida Institute of
Technology and the University of Notre Dame, suggests that a single
algorithm cannot be applied to both groups with equal accuracy.

Mr. Byers and other critics spoke at [a public
hearing](http://video.detroitmi.gov/CablecastPublicSite/show/7361?channel=3)
called by the Detroit Board of Police Commissioners after what the board
called unprecedented public interest in two facial recognition items on
its agenda. One item, specific to the new traffic light cameras, was
approved last week. The other, a comprehensive “acceptable use” policy
for facial recognition, has yet to be put to a
vote.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:257.77777777777777px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Residents
spoke in opposition to the expansion of Project Green Light, which uses
facial recognition technology, during a police board meeting in Detroit
in
June.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Brittany
Greeson for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Gathered in a packed church in the Second Precinct on the city’s west
side, those who expressed concerns about what is called “algorithmic
bias” included Denzel McCampbell, press secretary to Representative
Rashida Tlaib, the Michigan Democrat whose district includes Detroit,
and Blair Anderson, a [former member of the Black Panther
Party](https://www.nytimes3xbfgragh.onion/1970/05/09/archives/7-panthers-freed-in-chicago-clash-states-attorney-cites-lack-of.html)
who invoked the [law enforcement
surveillance](https://www.intelligence.senate.gov/sites/default/files/94755_II.pdf)
that helped destroy the political group as [a cautionary
tale](https://openjurist.org/600/f2d/600/hampton-v-hanrahan).

Tawana Petty, an activist with the [Detroit Community Technology
Project](https://detroitcommunitytech.org/?q=content/critical-summary-detroit%E2%80%99s-project-green-light-and-its-greater-context),
urged fellow Detroiters to consider the city’s place in the national
conversation on facial recognition. “If we allow racially biased
technologies to succeed here,” she said in an interview, “there really
isn’t any hope for black residents anywhere else in the United States.”

Not everyone who spoke was against the use of facial recognition.

“I’m the pastor getting the call from mothers whose son was shot or
their baby got snatched up,” said Maurice Hardwick, a black pastor at a
nondenominational ministry who founded a group that works with high
school gang members. “People want to know two things: What happened to
my child, my loved one? And who did this?”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Another Detroit resident, a white woman who walked with a cane, added:
“If you’re afraid of the cameras, either you’re paranoid or you’ve got
something to hide.”

Others were more concerned with a provision that would allow the police
to go beyond identifying violent crime suspects with facial recognition
and allow officers to try to identify anyone for whom a “reasonable
suspicion” exists that they could provide information relevant to an
active criminal investigation. There was also concern that the
photograph of anyone who gets a Michigan state ID or driver’s license is
searchable by state and local law enforcement agencies, and the F.B.I.,
[likely without their
knowledge](https://www.freep.com/story/news/local/michigan/2019/03/11/michigan-state-police-facial-recognition-database/3102139002/).

Facial recognition, the Detroit police stress, has indeed helped lead to
arrests. In late May, for instance, officers ran a video image through
facial recognition after survivors of a shooting directed police
officers to a gas station equipped with Green Light cameras where they
had met with a man now charged with three counts of first-degree murder
and two counts of assault. The lead generated by the software matched
the description provided by the
witnesses.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:252.62222222222223px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">A map at
police headquarters shows the various camera locations throughout the
city.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Brittany
Greeson for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

In the absence of federal legislation regulating the technology, experts
say cities and states are destined to be the first to weigh the societal
risks of technology that [many law enforcement
officials](https://www.nytimes3xbfgragh.onion/2019/05/18/us/facial-recognition-police.html)
say is [critical for ensuring public
safety](https://www.nytimes3xbfgragh.onion/2019/06/09/opinion/facial-recognition-police-new-york-city.html).

As in San Francisco, which this spring became the first major city to
[block the police from using facial
recognition](https://www.nytimes3xbfgragh.onion/2019/07/01/us/facial-recognition-san-francisco.html),
critics here have argued that facial recognition threatens civil
liberties and that the
[pervasive](https://www.bjs.gov/content/pub/pdf/cpp15.pdf) [racial
bias](https://www.detroitnews.com/story/news/local/detroit-city/2019/04/24/detroit-police-chief-cites-racially-tone-deaf-culture-6th-precinct/3554141002/)
[in
policing](https://www.washingtonpost.com/news/opinions/wp/2018/09/18/theres-overwhelming-evidence-that-the-criminal-justice-system-is-racist-heres-the-proof/?utm_term=.01ee3c3c5895)
will inevitably extend to how it is wielded, not least because
African-Americans are disproportionately represented in mug-shot
databases.

When James White, an assistant police chief in charge of the Detroit
Police Department’s technology, rose to respond to critics at the public
hearing, he provided unexpected backup to the charge that the software
comes with baked-in bias. He himself, the assistant chief said, had been
misidentified as other African-American men by the facial recognition
algorithm that Facebook uses to tag photos.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“On the question of false positives — that is absolutely factual, and
it’s well-documented,” he said. “So that concerns me as an
African-American male.”

The solution, Chief White said, is to exercise extra care. The
department’s policy specifies that facial recognition will be used only
to investigate violent crimes. Although the department has the ability
to implement real-time screening of anyone who passes by a camera — as
detailed in [a recent report](https://www.americaunderwatch.com/)by the
Georgetown Law Center on Privacy and Technology — there is no plan to
use it, he said, except in extraordinary circumstances.

No one in Detroit, Chief White emphasized, would be arrested solely on
the basis of a facial recognition
match.

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:257.1333333333334px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">A business
participating in Project Green
Light.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Brittany
Greeson for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Facial recognition technology isn’t where the work stops,” he said.
“It’s where the work starts.”

Civil liberties advocates say that protection isn’t enough, especially
because defendants are not typically informed that facial recognition
has been used in their identification. In one of the few cases to have
[argued that such information should be disclosed because it is
potentially
exonerating](https://www.jacksonville.com/public-safety/2016-11-11/how-accused-drug-dealer-revealed-jso-s-facial-recognition-network),
a Florida appeals court ruled that a black man, Willie Allen Lynch, had
[no legal right to see the other
matches](https://www.jacksonville.com/news/20190123/florida-court-prosecutors-had-no-obligation-to-turn-over-facial-recognition-evidence)
returned by the facial recognition program that helped lead to his
drug-offense conviction. Mr. Lynch had argued that he was misidentified.

A January 2018 study by two M.I.T. researchers first [focused public
attention](https://www.nytimes3xbfgragh.onion/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)
on the higher misidentification rates for dark-skinned women by three
leading purveyors of facial recognition algorithms. One of the
co-authors, Joy Buolamwini, posted YouTube videos showing the technology
misclassifying famous African-American women, like Michelle Obama, as
men. The phenomenon, Ms. Buolamwini [wrote in a New York Times
Op-Ed](https://www.nytimes3xbfgragh.onion/2018/06/21/opinion/facial-analysis-technology-bias.html),
is “a reminder that artificial intelligence, often heralded for its
potential to change the world, can actually reinforce bias and
exclusion, even when it’s used in the most well-intended ways.”

The companies examined in the paper subsequently improved their
algorithms for that particular test. But a second paper this year found
that Amazon’s software had more trouble identifying the gender of female
and darker-skinned faces, prompting prominent artificial-intelligence
researchers to call on the company to [stop selling its
software](https://www.nytimes3xbfgragh.onion/2019/04/03/technology/amazon-facial-recognition-technology.html)
to law enforcement agencies. Amazon executives have disputed the study.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

It is not clear why facial recognition algorithms perform differently on
different racial groups, researchers say. One reason may be that the
algorithms, which learn to recognize patterns in faces by looking at
large numbers of them, are not being trained on a diverse enough array
of photographs.

But Kevin Bowyer, a Notre Dame computer scientist, said that was not the
case for a study he recently published. Nor is it certain that skin tone
is the culprit: Facial structure, hairstyles and other factors may
contribute.

In Dr. Bowyer’s experiments, the recognition algorithms could achieve
the same degree of accuracy for white and black Americans, but only when
the algorithm was tuned to a cutoff, say, of no more than one in 10,000
false matches for the two separate groups. Given that the norm is to use
the same threshold for everybody, “those programs are seeing a higher
false match rate for the population of African-Americans,” Dr. Bowyer
said.

A dual-threshold system would not necessarily solve the problem, he
added. That would require law enforcement authorities to make a judgment
about each individual’s race and apply the appropriately tweaked facial
recognition software — which would in turn introduce human bias.

“Technically, it’s a very reasonable thing to say to do,” Dr. Bowyer
said. “But how do you defend it, and once you put that knob out there
for police to use, how do you make sure it’s not misused?”

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
