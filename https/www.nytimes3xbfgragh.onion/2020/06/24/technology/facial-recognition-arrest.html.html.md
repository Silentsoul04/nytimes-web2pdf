<div id="app">

<div>

<div>

<div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Technology](/section/technology)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">Wrongfully
Accused by an
Algorithm</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/3dAQA89</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 
  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-11qgg8s">

</div>

<div id="fullBleedHeaderContent">

<div class="css-1mre5cn">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">“This is
not me,” Robert Julian-Borchak Williams told investigators. “You think
all Black men look
alike?”</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Sylvia
Jarrus for The New York
Times</span></span></span>](https://static01.graylady3jvrrxbe.onion/images/2020/06/24/business/24michigan-arrest1/24michigan-arrest1-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

<div class="css-hy7cq4">

<div class="css-6cn7ki">

<div class="NYTAppHideMasthead css-1bcu9v6 e1suatyy0">

<div class="section css-1o1qe8k e1suatyy2">

<div class="css-cu5p7t er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

[Skip to content](#site-content)[Skip to site index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

</div>

<span class="css-10ej3is ezdmqqa0">The Great Read</span>

<div class="css-1sojcmr ehdk2mb0">

# Wrongfully Accused by an Algorithm

</div>

In what may be the first known case of its kind, a faulty facial
recognition match led to a Michigan man’s arrest for a crime he did not
commit.

</div>

</div>

<div class="css-nwzfg5 e1gnum310">

<span class="css-1f9pvn2 technology">“This is not me,” Robert
Julian-Borchak Williams told investigators. “You think all Black men
look
alike?”</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Sylvia
Jarrus for The New York Times</span></span></span>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-1wx1auc e1gnum311">

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-hus3qt ey68jwv0" data-aria-hidden="true">

[![Kashmir
Hill](https://static01.graylady3jvrrxbe.onion/images/2020/07/24/business/author-hill-kashmir/author-hill-kashmir-thumbLarge-v2.png
"Kashmir Hill")](https://www.nytimes3xbfgragh.onion/by/kashmir-hill)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Kashmir
Hill</span>](https://www.nytimes3xbfgragh.onion/by/kashmir-hill)

</div>

</div>

  - 
    
    <div class="css-ld3wwf e16638kd2">
    
    Published June 24, 2020Updated Aug. 3,
    2020
    
    </div>

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-pvvomx" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
      - 
    
    </div>
    
    </div>

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*Note: In response to this article, the Wayne County prosecutor’s office
said that Robert Julian-Borchak Williams could have the case and his
fingerprint data expunged. “We apologize,” the prosecutor, Kym L.
Worthy, said in a*
[*statement*](https://int.graylady3jvrrxbe.onion/data/documenthelper/7046-facial-recognition-arrest/5a6d6d0047295fad363b/optimized/full.pdf#page=1)*,
adding, “This does not in any way make up for the hours that Mr.
Williams spent in jail.”*

</div>

</div>

<div class="audioFigureHeading">

### Listen to This Article

<span class="css-16qbtva">Audio Recording by Audm</span>

</div>

<div class="css-qe9gm7">

<div>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*To hear more audio stories from publishers like The New York Times,
download*[**](https://www.audm.com/?utm_source=nytmag&utm_medium=embed&utm_campaign=left_behind_draper)[*Audm
for iPhone or
Android*](https://www.audm.com/?utm_source=nyt&utm_medium=embed&utm_campaign=wrongfully_accused_algorithm)*.*

On a Thursday afternoon in January, Robert Julian-Borchak Williams was
in his office at an automotive supply company when he got a call from
the Detroit Police Department telling him to come to the station to be
arrested. He thought at first that it was a prank.

An hour later, when he pulled into his driveway in a quiet subdivision
in Farmington Hills, Mich., a police car pulled up behind, blocking him
in. Two officers got out and handcuffed Mr. Williams on his front lawn,
in front of his wife and two young daughters, who were distraught. The
police wouldn’t say why he was being arrested, only showing him a piece
of paper with his photo and the words “felony warrant” and “larceny.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

His wife, Melissa, asked where he was being taken. “Google it,” she
recalls an officer replying.

The police drove Mr. Williams to a detention center. He had his mug
shot, fingerprints and DNA taken, and was held overnight. Around noon on
Friday, two detectives took him to an interrogation room and placed
three pieces of paper on the table, face down.

“When’s the last time you went to a Shinola store?” one of the
detectives asked, in Mr. Williams’s recollection. Shinola is an upscale
boutique that sells watches, bicycles and leather goods in the trendy
Midtown neighborhood of Detroit. Mr. Williams said he and his wife had
checked it out when the store first opened in 2014.

The detective turned over the first piece of paper. It was a still image
from a surveillance video, showing a heavyset man, dressed in black and
wearing a red St. Louis Cardinals cap, standing in front of a watch
display. Five timepieces, worth $3,800, were shoplifted.

“Is this you?” asked the detective.

The second piece of paper was a close-up. The photo was blurry, but it
was clearly not Mr. Williams. He picked up the image and held it next to
his face.

“No, this is not me,” Mr. Williams said. “You think all black men look
alike?”

Mr. Williams knew that he had not committed the crime in question. What
he could not have known, as he sat in the interrogation room, is that
his case may be the first known account of an American being wrongfully
arrested based on a flawed match from a facial recognition algorithm,
according to experts on technology and the law.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## A faulty system

A nationwide debate is raging about [racism in law
enforcement](https://www.nytimes3xbfgragh.onion/news-event/george-floyd-protests-minneapolis-new-york-los-angeles).
Across the country, millions are protesting not just the actions of
individual officers, but bias in the systems used to surveil communities
and identify people for prosecution.

Facial recognition systems have been used by police forces for [more
than two
decades](https://www.nytimes3xbfgragh.onion/2020/01/12/technology/facial-recognition-police.html).
Recent studies by
[M.I.T.](https://www.nytimes3xbfgragh.onion/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)
and the [National Institute of Standards and
Technology](https://www.nytimes3xbfgragh.onion/2019/12/19/technology/facial-recognition-bias.html),
or NIST, have found that while the technology works relatively well on
white men, the results are less accurate for other demographics, in part
because of a lack of diversity in the images used to develop the
underlying databases.

Last year, during a public hearing about the use of [facial recognition
in
Detroit](https://www.nytimes3xbfgragh.onion/2019/07/08/us/detroit-facial-recognition-cameras.html),
an assistant police chief was among those who raised concerns. “On the
question of false positives — that is absolutely factual, and it’s
well-documented,” James White said. “So that concerns me as an
African-American male.”

This month,
[Amazon](https://www.nytimes3xbfgragh.onion/2020/06/10/technology/amazon-facial-recognition-backlash.html),
[Microsoft](https://www.cnn.com/2020/06/18/tech/brad-smith-microsoft-facial-recognition/index.html)
and
[IBM](https://www.axios.com/ibm-is-exiting-the-face-recognition-business-62e79f09-34a2-4f1d-a541-caba112415c6.html)
announced they would stop or
[pause](https://www.nytimes3xbfgragh.onion/aponline/2020/06/11/business/bc-us-microsoft-police-facial-recognition.html)
their facial recognition offerings for law enforcement. The gestures
were largely symbolic, given that the companies are not big players in
the industry. The technology police departments use is supplied by
companies that aren’t household names, such as Vigilant Solutions,
Cognitec, NEC, Rank One Computing and [Clearview
AI](https://www.nytimes3xbfgragh.onion/2020/01/18/technology/clearview-privacy-facial-recognition.html).

Clare Garvie, a lawyer at Georgetown University’s Center on Privacy and
Technology, has written about problems with the [government’s use of
facial recognition](https://www.flawedfacedata.com/). She argues that
low-quality search images — such as a still image from a grainy
surveillance video — should be banned, and that the systems currently in
use should be tested rigorously for accuracy and bias.

“There are mediocre algorithms and there are good ones, and law
enforcement should only buy the good ones,” Ms. Garvie said.

About Mr. Williams’s experience in Michigan, she added: “I
[strongly](https://www.aclu.org/blog/privacy-technology/surveillance-technologies/florida-using-facial-recognition-convict-people)
[suspect](https://nymag.com/intelligencer/2019/11/the-future-of-facial-recognition-in-america.html)
this is not the first case to misidentify someone to arrest them for a
crime they didn’t commit. This is just the first time we know about it.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## In a perpetual lineup

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">In October
2018, someone shoplifted five watches, worth $3,800, from a Shinola
store in
Detroit.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Sylvia
Jarrus for The New York
Times</span></span>](https://static01.graylady3jvrrxbe.onion/images/2020/06/24/business/24michigan-arrest4/merlin_173772126_cf489017-f4f1-4fb8-a049-bd15c81e623a-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Mr. Williams’s case combines flawed technology with poor police work,
illustrating how facial recognition can go awry.

The Shinola shoplifting occurred in October 2018. Katherine Johnston, an
investigator at Mackinac Partners, a loss prevention firm, reviewed the
store’s surveillance video and sent a copy to the Detroit police,
according to their report.

Five months later, in March 2019, Jennifer Coulson, a digital image
examiner for the Michigan State Police, uploaded a “probe image” — a
still from the video, showing the man in the Cardinals cap — to the
state’s [facial recognition
database](https://www.michigan.gov/msp/0,4643,7-123-72297_64747_64749-357133--,00.html#:~:text=The%20Statewide%20Network%20of%20Agency,data%20for%20law%20enforcement%20access.).
The system would have [mapped the man’s face and
searched](https://www.michigan.gov/documents/msp/Facial_Recognition_FAQ_666807_7.pdf)
for similar ones in a collection of 49 million photos.

The state’s technology is supplied for [$5.5
million](https://www.michigan.gov/documents/buymichiganfirst/0200097_307265_7.pdf)
by a company called [DataWorks Plus](http://www.dataworksplus.com/).
Founded in South Carolina in 2000, the company first offered mug shot
management software, said Todd Pastorini, a general manager. In 2005,
the firm began to expand the product, adding face recognition tools
developed by outside vendors.

When one of these subcontractors develops an algorithm for recognizing
faces, DataWorks attempts to judge its effectiveness by running searches
using low-quality images of individuals it knows are present in a
system. “We’ve tested a lot of garbage out there,” Mr. Pastorini said.
These checks, he added, are not “scientific” — DataWorks does not
formally measure the systems’ accuracy or bias.

“We’ve become a pseudo-expert in the technology,” Mr. Pastorini said.

In Michigan, the DataWorks software used by the state police
incorporates components developed by the Japanese tech giant NEC and by
Rank One Computing, based in Colorado, according to Mr. Pastorini and a
state police spokeswoman. In 2019, algorithms from both companies were
included in [a federal
study](https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8280.pdf) of
over 100 facial recognition systems that found [they were
biased](https://www.nytimes3xbfgragh.onion/2019/12/19/technology/facial-recognition-bias.html),
falsely identifying African-American and Asian faces 10 times to 100
times more than Caucasian faces.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Rank One’s chief executive, Brendan Klare, said the company had
developed a new algorithm for NIST to review that “tightens the
differences in accuracy between different demographic cohorts.”

After Ms. Coulson, of the state police, ran her search of the probe
image, the system [would have
provided](https://www.michigan.gov/documents/msp/Facial_Recognition_FAQ_666807_7.pdf)
a row of results generated by NEC and a row from Rank One, along with
confidence scores. Mr. Williams’s driver’s license photo was among the
matches. Ms. Coulson sent it to the Detroit police as an “Investigative
Lead Report.”

“This document is not a positive identification,” the file says in bold
capital letters at the top. “It is an investigative lead only and is not
probable cause for arrest.”

This is what technology providers and law enforcement always
[emphasize](https://www.nytimes3xbfgragh.onion/2019/07/08/us/detroit-facial-recognition-cameras.html)
when defending facial recognition: It is only supposed to be a clue in
the case, not a smoking gun. Before arresting Mr. Williams,
investigators might have sought other evidence that he committed the
theft, such as eyewitness testimony, location data from his phone or
proof that he owned the clothing that the suspect was wearing.

In this case, however, according to the Detroit police report,
investigators simply included Mr. Williams’s picture in a “6-pack photo
lineup” they created and showed to Ms. Johnston, Shinola’s
loss-prevention contractor, and she identified him. (Ms. Johnston
declined to
comment.)

## ‘I guess the computer got it wrong’

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:257.77777777777777px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">The Detroit
Detention Center. Mr. Williams was held for 30
hours.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Sylvia
Jarrus for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Mr. Pastorini was taken aback when the process was described to him. “It
sounds thin all the way around,” he said.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Mr. Klare, of Rank One, found fault with Ms. Johnston’s role in the
process. “I am not sure if this qualifies them as an eyewitness, or
gives their experience any more weight than other persons who may have
viewed that same video after the fact,” he said. John Wise, a spokesman
for NEC, said: “A match using facial recognition alone is not a means
for positive identification.”

The Friday that Mr. Williams sat in a Detroit police interrogation room
was the day before his 42nd birthday. That morning, his wife emailed his
boss to say he would miss work because of a family emergency; it broke
his four-year record of perfect attendance.

In Mr. Williams’s recollection, after he held the surveillance video
still next to his face, the two detectives leaned back in their chairs
and looked at one another. One detective, seeming chagrined, said to his
partner: “I guess the computer got it wrong.”

They turned over a third piece of paper, which was another photo of the
man from the Shinola store next to Mr. Williams’s driver’s license. Mr.
Williams again pointed out that they were not the same person.

Mr. Williams asked if he was free to go. “Unfortunately not,” one
detective said.

Mr. Williams was kept in custody until that evening, 30 hours after
being arrested, and released on a $1,000 personal bond. He waited
outside in the rain for 30 minutes until his wife could pick him up.
When he got home at 10 p.m., his five-year-old daughter was still awake.
She said she was waiting for him because he had said, while being
arrested, that he’d be right back.

She has since taken to playing “cops and robbers” and accuses her father
of stealing things, insisting on “locking him up” in the living
room.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## Getting help

</div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

<div class="css-1xdhyk6 erfvjey0">

<span class="css-1ly73wi e1tej78p0">Image</span>

<div class="css-zjzyr8">

<div data-testid="lazyimage-container" style="height:483.33333333333326px">

</div>

</div>

</div>

<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Mr. Williams
with his wife, Melissa, and their daughters at home in Farmington Hills,
Mich.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span>Sylvia
Jarrus for The New York Times</span></span>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The Williams family contacted defense attorneys, most of whom, they
said, assumed Mr. Williams was guilty of the crime and quoted prices of
around $7,000 to represent him. Ms. Williams, a real estate marketing
director and food blogger, also
[tweeted](https://twitter.com/PPlates/status/1216813325310484481) at the
American Civil Liberties Union of Michigan, which took an immediate
interest.

*“*We’ve been active in trying to sound the alarm bells around facial
recognition, both as a threat to privacy when it works and a racist
threat to everyone when it doesn’t,” said Phil Mayor, an attorney at the
organization. “We know these stories are out there, but they’re hard to
hear about because people don’t usually realize they’ve been the victim
of a bad facial recognition search.”

Two weeks after his arrest, Mr. Williams took a vacation day to appear
in a Wayne County court for an arraignment. When the case was called,
the prosecutor moved to dismiss, but “without prejudice,” meaning Mr.
Williams could later be charged again.

Maria Miller, a spokeswoman for the prosecutor, said a second witness
had been at the store in 2018 when the shoplifting occurred, but had not
been asked to look at a photo lineup. If the individual makes an
identification in the future, she said, the office will decide whether
to issue charges.

A Detroit police spokeswoman, Nicole Kirkwood, said that for now, the
department “accepted the prosecutor’s decision to dismiss the case.” She
also said that the department updated its [facial recognition
policy](https://detroitmi.gov/sites/detroitmi.localhost/files/2019-07/FACIAL%20RECOGNITION%20Directive%20307.5_0.pdf)
in July 2019 so that it is only used to investigate violent crimes.

The department, she said in another statement, “does not make arrests
based solely on facial recognition. The investigator reviewed video,
interviewed witnesses, conducted a photo lineup.”

On Wednesday, the A.C.L.U. of Michigan filed a
[complaint](https://www.aclu.org/letter/aclu-michigan-complaint-re-use-facial-recognition)
with the city, asking for an absolute dismissal of the case, an apology
and the removal of Mr. Williams’s information from Detroit’s criminal
databases.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The Detroit Police Department “should stop using facial recognition
technology as an investigatory tool,” Mr. Mayor wrote in the complaint,
adding, “as the facts of Mr. Williams’s case prove both that the
technology is flawed and that DPD investigators are not competent in
making use of such technology.”

Mr. Williams’s lawyer, Victoria Burton-Harris, said that her client is
“lucky,” despite what he went through.

“He is alive,” Ms. Burton-Harris said. *“*He is a very large man. My
experience has been, as a defense attorney, when officers interact with
very large men, very large black men, they immediately act out of fear.
They don’t know how to de-escalate a situation.”

## ‘It was humiliating’

Mr. Williams and his wife have not talked to their neighbors about what
happened. They wonder whether they need to put their daughters into
therapy. Mr. Williams’s boss advised him not to tell anyone at work.

“My mother doesn’t know about it. It’s not something I’m proud of,” Mr.
Williams said. “It’s humiliating.”

He has since figured out what he was doing the evening the shoplifting
occurred. He was driving home from work, and had posted a video to his
private Instagram because a song he loved came on — 1983’s “We Are One,”
by Maze and Frankie Beverly. The lyrics go:

> *I can’t understand*
> 
> *Why we treat each other in this way*
> 
> *Taking up time*
> 
> *With the silly silly games we play*

He had an alibi, had the Detroit police checked for
one.

</div>

</div>

<div class="audioFigureHeading">

<div class="css-1et479a">

![](https://static01.graylady3jvrrxbe.onion/images/2017/01/29/podcasts/the-daily-album-art/the-daily-album-art-articleInline-v2.jpg?quality=75&auto=webp&disable=upscale)

</div>

### Listen to ‘The Daily’: Wrongfully Accused by an Algorithm

<span class="css-59o34k">In what may be the first known case of its
kind, a faulty facial recognition match led to a Michigan man’s arrest
for a crime he did not commit.</span>

</div>

<div class="css-qe9gm7">

<div>

<div class="css-1g7y0i5 e1drnplw0">

<div class="css-1ceswkc e1drnplw1">

</div>

<div class="css-f2fzwx e1drnplw2">

<div data-aria-labelledby="modal-title" data-role="region">

<div id="modal-title" class="css-mln36k">

transcript

</div>

<div class="css-pbq7ev">

</div>

<span>Back to The
Daily</span>

<div class="css-f6lhej">

<div class="css-1ialerq">

<div class="css-1701swk">

bars

</div>

<div>

<div class="css-1t7yl1y">

0:00/28:13

</div>

<div class="css-og85jy">

\-28:13

</div>

</div>

</div>

</div>

<div class="css-15fbio0">

<div class="css-1p4nyns">

transcript

## Listen to ‘The Daily’: Wrongfully Accused by an Algorithm

### Hosted by Annie Brown, produced by Lynsea Garrison, Austin Mitchell and Daniel Guillemette, and edited by Lisa Tobin and Larissa Anderson

#### In what may be the first known case of its kind, a faulty facial recognition match led to a Michigan man’s arrest for a crime he did not commit.

</div>

  - michael barbaro  
    From The New York Times, I’m Michael Barbaro. This is “The Daily.”

  - \[music\]  
    Today: Facial recognition is becoming an increasingly popular tool
    for solving crimes. The Daily’s Annie Brown speaks to Kashmir Hill
    about how that software is not treating everybody equally.
    
    It’s Monday, August 3.

  - kashmir hill  
    I’m just going the tape record with an app that I use. Do you guys
    have any questions or concerns before we start talking about what
    happened?

  - robert williams  
    No.

  - melissa williams  
    No.

annie brown

OK. So where do you think we should start the story of this case,
Kashmir?

kashmir hill

The story started, for the Williams family, in January of 2020.

  - robert williams  
    Melissa got the call first. I got the call from her.

kashmir hill

It’s a Thursday afternoon in Farmington Hills, Michigan, which is just
outside of Detroit.

  - melissa williams  
    So I picked up Julia from school. Regular Thursday.

kashmir hill

And Melissa Williams, a realtor, is driving home from work. She’s
picking up her daughter.

  - melissa williams  
    And so it was right around, like, 4 o’clock. And I got a call.

kashmir hill

And she gets a call from somebody who says they’re a police officer.

  - melissa williams  
    They immediately said, we’re calling about Robert from an incident
    in 2018. He needs to turn himself in. So I was confused off the bat.

kashmir hill

She is white. And her husband, Robert Williams, is Black.

  - melissa williams  
    And they said, we assume you’re his baby mama or that you’re not
    together anymore. And —

  - kashmir hill  
    What?

  - melissa williams  
    Yeah. I said, that’s my husband. And what is this regarding? And
    they said, we can’t tell you. But he needs to come turn himself in.
    And I said, well, why didn’t you call him? And they said, can’t you
    just give him a message?

annie brown

Wait. So why is this officer calling her?

kashmir hill

She doesn’t know why the officer is calling her. All she knows is that
the police want to be in touch with her husband. So she gives the
officer her husband’s number. And then she calls Robert.

  - melissa williams  
    And I said, I just got a really weird call. I was like, what did you
    do? Like, what is this about?

kashmir hill

And while they’re talking, Robert Williams gets a call from the police
department.

  - robert williams  
    Of course, I answered the other line. And he said he was a detective
    from Detroit and that I need to come turn myself in. So of course
    I’m like, for what? And he’s like, well, I can’t tell you over the
    phone. So I’m like, well, I can’t turn myself in then.

kashmir hill

It was a couple of days before his birthday. So he thought maybe it was
a prank call. But it became pretty clear that the person was serious.

  - robert williams  
    About, uh, probably ten minutes later, I pull in the driveway.

kashmir hill

And when he pulls into his driveway, a police car pulls in behind him,
blocking him in. And two officers get out.

  - robert williams  
    Yeah. So I get out of the car. And the driver, like, runs up. And
    he’s like, are you Robert Williams? I’m like, yeah. He’s like,
    you’re under arrest. I’m like, no I’m not. And the guy comes up
    with, like, a white sheet of paper. And it’s said “felony warrant”
    on the top, “larceny.” And I’m confused, like, isn’t larceny
    stealing?

kashmir hill

His wife comes out with his two young daughters. And his oldest
daughter, who’s 5, is watching this happen.

  - robert williams  
    I said, Juju (ph), go back in the house. I’ll be back in a minute.
    They’re just making a mistake. The guy, the other cop, is behind me
    with his handcuffs out already. So he’s like, come on, man. You
    already — you know the drill. And I’m like, what?

kashmir hill

The officers arrest him. They have to use two pairs of handcuffs to get
his hands behind his back, because he’s a really big guy.

  - robert williams  
    We started moving seats around, trying to get me in the back of this
    little bitty Impala. And off we go.

kashmir hill

And then they drive to the detention center.

\[music\]

  - robert williams  
    I took fingerprints. I took —

  - kashmir hill  
    Your mug shot.

  - robert williams  
    Mug shot pictures.

kashmir hill

Then he’s put in a cell to sleep overnight.

  - robert williams  
    At this point, I’m in a holding cell with two other guys. And
    they’re like, what you in here for? And I’m like, I don’t know.

  - kashmir hill  
    So when do you actually find out why you’ve been arrested, beyond
    this kind of vague larceny?

  - robert williams  
    Um, so — well, maybe like noon the next day.

kashmir hill

Around noon the next day, he is taken to an interrogation room. And
there’s two detectives there. And they have three pieces of paper face
down in front of them. And they turn over the first sheet of paper. And
it’s a picture from a surveillance video of a large Black man standing
in a store, wearing a red Cardinals cap and a black jacket. And the
detectives ask, is this you?

  - robert williams  
    I laugh a little bit, and I say, no, that’s not me. So then he turns
    over another paper.

kashmir hill

And they turn over a second piece of paper, which is just a close up of
that same guy’s face.

  - robert williams  
    And he says I guess that’s not you either. And I said, no. This is
    not me.

kashmir hill

So Robert picks the piece of paper up, holds it next to his own face —

  - robert williams  
    I was like, what you think, all Black men look alike?

kashmir hill

— and says, do all Black men look the same to you?

annie brown

So what’s your understanding, Kashmir, of what happened to bring Robert
Williams into that police department?

kashmir hill

So Robert Williams had no idea what was happening. But two years
earlier, in October 2018, a man who was not him walked into a Shinola
store in downtown Detroit. And Shinola is kind of like a high-end store
that sells expensive watches and bikes. So this man came in. He was
there for a few minutes. He stole five watches worth $3,800 and walked
out. None of the employees there actually saw the theft occur. And so
they had to review the surveillance footage. And they found the moment
it happened. So they sent that surveillance footage picture that Robert
Williams had been shown to the Detroit police. And the police turned to
what a lot of police turn to these days when they have a suspect that
they don’t recognize — a facial recognition system. So they ran a search
on this, what they call a probe image, this picture for the surveillance
video, which is really grainy. It’s not a very good photo. And the way
these systems work is that they have access not just to mug shots but
also to driver’s license photos. You get a bunch of different results.
And there’s a human involved who decides which of the results looks the
most like the person who committed the crime.

annie brown

Mm. So you’re saying the facial recognition algorithm basically created
a lineup of potential suspects. And then from that lineup, someone picks
the person that they think looks the most like the man in the
surveillance video.

kashmir hill

Right. And so that is how they wound up arresting Robert Williams.

\[music\]

So back in this room, the two detectives now have the real Robert
Williams in front of them. And he doesn’t look like this guy.

  - robert williams  
    You know, they sat back and looked at each other and was like, with
    the oops face, right? Says, so I guess the computer got it wrong
    too.

kashmir hill

And so they kind of leaned back and said, I guess the computer got it
wrong.

  - robert williams  
    Well, the computer got it wrong is what threw me off. And I’m like,
    computer got it wrong?

annie brown

And what is the significance of that statement, “that the computer got
it wrong“?

kashmir hill

So this was an admission by the detectives that it was a computer that
had pointed the finger at Robert Williams. And that’s significant,
because this is the first documented case of an innocent person being
arrested because of a flawed facial recognition match.

\[music\]

annie brown

And just to put all of this into context for a second, the last time
that you and I talked, Kashmir, we were talking about a different
development in facial recognition — this new algorithm being used by
some police departments that drew from pictures all over social media
and all over the internet to make a kind of super algorithm. But the
fear wasn’t that it wasn’t accurate. It was almost that it was too
accurate, that it knew too much. But what you’re describing is something
altogether different. Right?

kashmir hill

So when we talk about facial recognition, we often think of it as a
monolith, that there’s kind of one facial recognition. But in fact,
there’s a bunch of different companies that all have their own
algorithms. And some work well. And some don’t work well. And some work
well sometimes. Like, identifying a really clear photo is a lot easier
than identifying surveillance footage.

annie brown

And why wouldn’t police departments be using the most sophisticated, the
most kind of up-to-date version of this software?

kashmir hill

I mean, this is where you run into just bureaucracy. Right? You have
contracts with companies that go back years and just a lot of different
vendors. And so in this case, I tried to figure out exactly whose
algorithms were responsible for Robert Williams getting arrested. And I
had to really dig down. And I discovered the police had no idea. You
know, they contract out to a company called DataWorks Plus. And
DataWorks Plus contracts out to two other companies called N.E.C. and
Rank One that actually supply the algorithm. It’s this whole chain of
companies that are involved. And there is no standardized testing.
There’s no one really regulating this. There’s just nobody saying
which algorithms, you know, pass the test to be used by law enforcement.
It’s just up to police officers, who, for the most part, seem to be just
testing it in the field to see if it works, if it’s identifying the
right people.

But the really big problem is that these systems have been proven to be
biased.

\[music\]

michael barbaro

We’ll be right back.

annie brown

So, Kashmir, help me understand how an algorithm can become biased.

kashmir hill

Well, the bias tends to come from how the algorithm is trained. And
these algorithms tend to be trained by basically feeding them with a
bunch of images of people. But the problem with the algorithms is that
they tended to be trained with non-diverse data sets.

annie brown

Mm.

kashmir hill

So one good example is that many of the algorithms used by law
enforcement in the U.S., by government in the U.S., are very good at
recognizing white men and not as good at recognizing Black people or
Asian-Americans. But if you go to an algorithm from a company in China,
where they fed it with a lot of images of Asian people, they’re really
good at recognizing Asian people and not as good at recognizing white
men. So you can just, you can see the biases that come in from the kind
of data that we feed into these systems.

annie brown

And is this a widely agreed upon reality — that because of these
methods, the algorithms used in the U.S. are just worse at identifying
faces that aren’t white men?

kashmir hill

Yeah. A few years ago, an M.I.T. researcher did this study and found
that facial recognition algorithms were biased to be able to recognize
white men better. And shortly after that, NIST, the National Institute
of Standards and Technology, decide to run its own study on this. And it
found the same thing. It looked at over 100 different algorithms. And it
found that they were biased. And actually, the two algorithms that were
at the heart of this case — the Robert Williams’s case — were in that
study.

annie brown

So the algorithm that was used by this police department was actually
studied by the federal government and was proven to be biased against
faces like Robert Williams.

kashmir hill

Exactly.

annie brown

So given these widely-understood problems with these algorithms, how can
police departments justify continuing to use them?

kashmir hill

So police departments are aware of the bias problem. But they feel that
face recognition is just too valuable a tool in their tool set to solve
crimes. And their defense is that they never arrest somebody based on
facial recognition alone, that facial recognition is only what they call
an investigative lead. It doesn’t supply probable cause for arrest.

So what police are supposed to do is they get a facial recognition
match, and you’re supposed to do more investigating. So you could go to
the person’s social media account and see if there are other photos of
them wearing the same clothes that they were wearing on the day they
committed this crime. Or, you know, you can try to get proof that they
were in that part of town on the day that the theft occurred. You know,
try to get location data. Basically, find other evidence that this
person is the person that committed the crime.

The detectives just went to the woman who had spotted the theft on the
video and showed her a photo of six people — they call it a six pack.
And she said Robert Williams looked the most like the person that was in
the video.

annie brown

Mm. So they’re supposed to use the facial recognition match as a kind of
clue. And then the protocol calls for them to do more police work to
verify it. But in this case, they basically just had someone watch the
video and then identify Robert Williams as the one who looks most like
the guy in the video.

kashmir hill

Yeah, they just did facial recognition a second time, but with a human
who’s not actually trained. And they didn’t do any other investigating.
Based on that, they went out and they arrested Mr. Williams.

annie brown

But if the police had done their job correctly — if they had looked into
his social media accounts, if they had tried to get his location data
from his phone records, essentially surveilling him more closely —
wouldn’t that be its own sort of violation? Just because their
technology wrongfully identified this man, he gets more closely watched
by the police without his knowledge.

kashmir hill

Right. And this is actually what police asked the facial recognition
vendors to do. They want to have more, what you call false positives,
because they want to have the greatest pool of possible suspects that
they can, because they want to find the bad guy.

annie brown

Huh.

kashmir hill

But there’s a real toll from that.

annie brown

Hmm.

kashmir hill

I just, you know, as a person who’s been reporting on technology for a
decade, I just think people trust computers. And even when we know
something is flawed, if it’s a computer telling us to do it, we just
think it’s right. And this is why we always used to see, for a long
time, when mapping technology was first being developed and it wasn’t
that great, you know, people would drive into lakes. They would drive
over cliffs, because a mapping app said, you’re supposed to go straight
here.

annie brown

Right.

kashmir hill

And even though they could look and see that their life is going to be
in danger, they would think, well, this app must know what it’s talking
about. That’s facial recognition now. And when I was reporting this
story, all the experts I talked to said this is surely not the first
case where somebody has been mistakenly — an innocent person has been
mistakenly arrested because of a bad face recognition match. But usually
people don’t find out about it. Police don’t tell people that they’re
there because of face recognition.

annie brown

Hmm.

kashmir hill

Usually, when they charge them, they’ll just say they were identified
through investigative means. It’s kind of a vague, “There were clues
that pointed at you.” In that way, Robert’s case was unusual, because
there was so little evidence against him. They basically had to tell him
that they used facial recognition, you know, to put him there.

annie brown

Right. They showed him what most people don’t get to see, which is this
false match between his photo and the photo of the crime.

kashmir hill

Right.

annie brown

And what’s happened since Robert was arrested?

kashmir hill

So Robert had to hire a lawyer to defend himself. But when he went to
the hearing, the prosecutor decided to drop the case. But they dropped
it without prejudice, which meant that they could charge him again.

annie brown

For the same crime?

kashmir hill

With the same crime. So as I was reporting out the story, you know, I
went to the prosecutor’s office. I went to the Detroit Police
Department. And I said, you know, what happened here? Did you have any
other evidence? This just seems like a clear misfire and misuse of
facial recognition. And everyone involved was pretty defensive and said,
well, you know, there might be more evidence that proves that Robert
Williams did it.

But after the story came out, everybody’s tune changed dramatically.
Prosecutors office apologized, said that Robert Williams shouldn’t have
spent any time in jail. The Detroit Police Department said this was a
horrible investigation. The police officers involved just did this all
wrong. This isn’t how it’s supposed to work. And they said that Robert
Williams would have his information expunged from the system — his mug
shot, his DNA. And they personally apologized to the Williams family,
though the Williams family told me that no one ever actually called them
to personally apologize.

annie brown

But he can no longer be charged in the future for this crime?

kashmir hill

That’s exactly right.

annie brown

And what about their use of facial recognition software? Has there been
any change there?

kashmir hill

So one thing the Detroit Police Department said was, well, this was a
case that predates this new policy we have that says, you know, we’re
only supposed to be using facial recognition for violent crimes.

annie brown

Hmm. And what do you make of that? Why only use this tool for that?

kashmir hill

Well, their justification is that when it comes to violent crimes, when
it comes to murder, you know, rape, they need to solve these cases. And
they’ll use any clue they can to do it, including facial recognition.
But I think about something that Robert’s wife said.

  - melissa williams  
    When they pulled up to our house, they were already combative on the
    phone. They were aggressive in the doorway to me. What if he had
    been argumentative? If he’d been defensive, if he hadn’t complied,
    you know, what could that have turned into in our yard? Like, it
    could have went a different way. And the recent news has shown us
    that it definitely could have went a different way.

\[music\]

  - kashmir hill  
    Do you feel like there’s a shame to this, that the police arrested
    you even though you did nothing?

  - robert williams  
    It’s a little humiliating. You know, it’s not something that easily
    rolls off the tongue, like, oh yeah, and guess what? I got arrested.

\[music\]

annie brown

And what about for Robert himself? What has life been like for him after
the arrest?

kashmir hill

So this was very embarrassing for him and kind of painful in some ways.
So he had a perfect attendance at work until that day that he was
arrested. And his wife had to email his boss and say that they had a
family emergency and that he couldn’t show up that day. Once he did tell
his boss what happened, his boss said, you know, you don’t want to tell
other people at work. You know, it could be bad for you. The night he
got home, his daughter — his 5-year-old was still awake.

  - robert williams  
    Julia was still up. And I was like, what are you doing up? And she
    was like, I’m waiting for you. And I was like, I told you I’ll be
    right back. And she was like, you didn’t come right back though. So
    I just kept telling her that they made a mistake. And it just took
    longer than we expected. But —

kashmir hill

She started wanting to play cops and robbers. And she would always
pretend like he was the robber who stole something, and she would need
to lock him up in the living room.

annie brown

Hmm.

  - melissa williams  
    Oh yeah. She told us that she told one of her — Jackson, her friend
    at school. And we weren’t sure, did she tell her teacher? Did she
    tell her friends? We were not sure. And we didn’t know what to say
    to people. Like, just bring it up out of nowhere, like, oh yeah, in
    case anyone mentioned it, he was arrested, but he didn’t do
    anything.

  - kashmir hill  
    Has this made you look back to see where you — like, where you were
    October 2018?

  - robert williams  
    Yeah. I pulled it up. At the time, I was on my Facebook or on my
    Instagram Live.

kashmir hill

He has since looked back and realized that he had posted to Instagram at
basically the same time as the shoplifting was occurring. He was driving
home from work, and a song came on the radio that his mother loved: the
song “We Are One” by Maze and Frankie Beverly.

  - robert williams  
    I was singing songs on my way home in the car.

annie brown

So if the cops had looked in to his social media, if they had tried to
verify that it was possible that he could have committed this crime,
they could have found this video.

kashmir hill

Right. If the police had done a real investigation, they would have
found out he had an alibi that day.

  - archived recording  
    \[“WE ARE ONE” PLAYING\]

annie brown

Kashmir, thank you so much.

kashmir hill

Thank you.

\[music\]

michael barbaro

We’ll be right back.

Here’s what else you need to know today. Federal unemployment benefits
have expired for tens of millions of Americans after Congress failed to
reach a deal to renew them last week.

  - archived recording  
    So what do you say to those 30 million Americans who are now without
    federal unemployment help?

  - archived recording (nancy pelosi)  
    I say to them, talk to President Trump. He’s the one who is standing
    in the way of that. We have been for the $600. They have a $200
    proposal, which does not meet the needs of America’s working
    families. And —

michael barbaro

In interviews on Sunday with ABC’s “This Week,” House Speaker Nancy
Pelosi blamed Republicans for demanding a drastic cut in the weekly
benefit, while Treasury Secretary Steve Mnuchin claimed that the $600
payments risked overpaying unemployed workers.

  - archived recording  
    So you do think it is a disincentive to find a job if you have that
    extra $600?

  - archived recording (steven mnuchin)  
    There’s no question. In certain cases where we’re paying people more
    stay home than to work, that’s created issues in the entire economy.

michael barbaro

And The Times reports that July was a devastating month for the pandemic
in the U.S. The country recorded nearly 2 million new infections, twice
as many as any previous month.

  - archived recording (deborah birx)  
    I want to be very clear. What we’re seeing today is different from
    March and April. It is extraordinarily widespread. It’s into the
    rural as equal urban areas.

michael barbaro

In an interview on Sunday with CNN, Dr. Deborah Birx, a top White House
adviser on the pandemic, acknowledged that the United States has failed
to contain the virus.

  - archived recording (deborah birx)  
    And to everybody who lives in a rural area, you are not immune or
    protected from this virus. And that’s why we keep saying, no matter
    where you live in America, you need to wear a mask and socially
    distance. Do the personal hygiene —

michael barbaro

That’s it for “The Daily.” I’m Michael Barbaro. See you tomorrow.

\[music\]

</div>

</div>

</div>

</div>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Aaron Krolik contributed reporting.

</div>

</div>

<div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes3xbfgragh.onion/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes3xbfgragh.onion/privacy)
  - [Terms of
    Service](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes3xbfgragh.onion/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes3xbfgragh.onion)
  - [Help](https://help.nytimes3xbfgragh.onion/hc/en-us)
  - [Subscriptions](https://www.nytimes3xbfgragh.onion/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
