<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Opinion](/section/opinion)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">We’re
Banning Facial Recognition. We’re Missing the
Point.</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2G76rNq</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div class="css-v5btjw etb61u70">

<div class="css-v05ibm etb61u71">

[Opinion](/section/opinion)

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# We’re Banning Facial Recognition. We’re Missing the Point.

</div>

The whole point of modern surveillance is to treat people differently,
and facial recognition technologies are only a small part of that.

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By <span class="css-1baulvz last-byline" itemprop="name">Bruce
Schneier</span>

<div class="css-8atqhb">

Mr. Schneier is a fellow at the Harvard Kennedy School.

</div>

</div>

</div>

  - Jan. 20,
    2020

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Ariel
Davis</span></span></span>](https://static01.nyt.com/images/2020/01/20/opinion/20schneier-privacy/20schneier-privacy-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Communities across the United States are starting to ban facial
recognition technologies. In May of last year, [San
Francisco](https://www.nytimes.com/2019/05/14/us/facial-recognition-ban-san-francisco.html)
banned facial recognition; the neighboring city of
[Oakland](https://www.vice.com/en_us/article/zmpaex/oakland-becomes-third-us-city-to-ban-facial-recognition-xz)
soon followed, as did
[Somerville](https://www.bostonglobe.com/metro/2019/06/27/somerville-city-council-passes-facial-recognition-ban/SfaqQ7mG3DGulXonBHSCYK/story.html)
and
[Brookline](https://www.boston.com/news/local-news/2019/12/12/brookline-facial-recognition)
in Massachusetts (a [statewide
ban](https://www.aclum.org/en/news/massachusetts-voters-strongly-support-pausing-use-unregulated-face-recognition-technology)
may follow). In December, [San
Diego](https://www.fastcompany.com/90440198/san-diegos-massive-7-year-experiment-with-facial-recognition-technology-appears-to-be-a-flop)
suspended a facial recognition program in advance of a new statewide
law, which declared it illegal, coming into effect. Forty major music
festivals
[pledged](https://www.vice.com/en_us/article/ywakpj/40-major-music-festivals-have-pledged-not-to-use-facial-recognition-technology)
not to use the technology, and
[activists](https://www.banfacialrecognition.com/) **** are calling for
a nationwide ban. Many Democratic presidential candidates [support at
least a partial
ban](https://www.vox.com/policy-and-politics/2019/12/3/20965470/2020-presidential-candidates-facial-recognition)
on the technology.

These efforts are well intentioned, but facial recognition bans are the
wrong way to fight against modern surveillance. Focusing on one
particular identification method misconstrues the nature of the
surveillance society we’re in the process of building. Ubiquitous mass
surveillance is increasingly the norm. In countries like China, a
surveillance infrastructure is being built by the government for social
control. In countries like the United States, it’s being built by
corporations in order to influence our buying behavior, and is
incidentally used by the
government.

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006451534" data-slug="privacy-mid-nav-module" style="max-width:1050px">

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

In all cases, modern mass surveillance has three broad components:
identification, correlation and discrimination. Let’s take them in turn.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Facial recognition is a technology that can be used to identify people
without their knowledge or consent. It relies on the prevalence of
cameras, which are becoming both more powerful and smaller, and machine
learning technologies that can match the output of these cameras with
images from a database of existing photos.

But that’s just one identification technology among many. People can be
identified at a distance by their [heart
beat](https://www.technologyreview.com/s/613891/the-pentagon-has-a-laser-that-can-identify-people-from-a-distanceby-their-heartbeat/)
or by their [gait](http://www.watrix.ai/en/gait-recognition/), using a
laser-based system. Cameras are so good that they can read
[fingerprints](https://www.technologyreview.com/s/422400/fingerprints-go-the-distance/)
and
[iris](https://www.theatlantic.com/technology/archive/2015/05/long-range-iris-scanning-is-here/393065/)**[](https://www.theatlantic.com/technology/archive/2015/05/long-range-iris-scanning-is-here/393065/)**[patterns](https://www.theatlantic.com/technology/archive/2015/05/long-range-iris-scanning-is-here/393065/)
from meters away. And even without any of these technologies, we can
always be identified because our smartphones
[broadcast](https://www.howtogeek.com/196998/your-devices-broadcast-unique-numbers-and-theyre-being-used-to-track-you/)
unique numbers called MAC addresses. Other things identify us as well:
our phone numbers, our credit card numbers, the license plates on our
cars. China, for example, [uses multiple identification
technologies](https://www.nytimes.com/2019/12/17/technology/china-surveillance.html)
to support its surveillance state.

Once we are identified, the data about who we are and what we are doing
can be correlated with other data collected at other times. This might
be movement data, which can be used to “follow” us as we move throughout
our day. It can be purchasing data, internet browsing data, or data
about who we talk to via email or text. It might be data about our
income, ethnicity, lifestyle, profession and interests. There is an
entire industry of data brokers who make a living analyzing and
[augmenting data](https://www.eff.org/wp/behind-the-one-way-mirror)
about who we are — using surveillance data collected by all sorts of
companies and then sold without our knowledge or consent.

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

There is a huge — and almost entirely unregulated — data broker industry
in the United States that trades on our information. This is how large
internet companies like Google and Facebook make their money. It’s not
just that they know who we are, it’s that they correlate what they know
about us to create profiles about who we are and what our interests are.
This is why many companies [buy license plate
data](https://www.vice.com/en_us/article/43kxzq/dmvs-selling-data-private-investigators-making-millions-of-dollars)
from states. It’s also why companies [like
Google](https://www.nytimes.com/2019/11/11/business/google-ascension-health-data.html)
are buying health records, and part of the reason Google [bought the
company
Fitbit](https://www.forbes.com/sites/brucelee/2019/11/02/google-to-buy-fitbit-for-21-billion-what-about-privacy-concerns/),
along with all of its data.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The whole purpose of this process is for companies — and governments —
to treat individuals differently. We are shown different ads on the
internet and receive different offers for credit cards. [Smart
billboards](https://www.bloomberg.com/opinion/articles/2018-08-10/google-s-targeted-ads-are-coming-to-a-billboard-near-you)
display different advertisements based on who we are. In the future, we
might be treated differently when we walk into a store, just as we
currently are when we visit websites.

The point is that it doesn’t matter which technology is used to identify
people. That there currently is no comprehensive database of heart beats
or gaits doesn’t make the technologies that gather them any less
effective. And most of the time, it doesn’t matter if identification
isn’t tied to a real name. What’s important is that we can be
consistently identified over time. We might be completely anonymous in a
[system that uses unique
cookies](https://privacy.net/stop-cookies-tracking/) to track us as we
browse the internet, but the same process of correlation and
discrimination still occurs. It’s the same with faces; we can be tracked
as we move around a store or shopping mall, even if that tracking isn’t
tied to a specific name. And that anonymity is fragile: If we ever order
something online with a credit card, or purchase something with a credit
card in a store, then suddenly our real names are attached to what was
anonymous tracking information.

Regulating this system means addressing all three steps of the process.
A ban on facial recognition won’t make any difference if, in response,
surveillance systems switch to identifying people by smartphone MAC
addresses. The problem is that we are being identified without our
knowledge or consent, and society needs rules about when that is
permissible.

Similarly, we need rules about how our data can be combined with other
data, and then bought and sold without our knowledge or consent. The
data broker industry is almost entirely unregulated; there’s only one
law — passed in
[Vermont](https://www.fastcompany.com/90302036/over-120-data-brokers-inch-out-of-the-shadows-under-landmark-vermont-law)
in 2018 — that requires data brokers to register and explain in broad
terms what kind of data they collect. The large internet surveillance
companies like Facebook and Google collect dossiers on us more detailed
than those of any police state of the previous century. Reasonable laws
would prevent the worst of their abuses.

Finally, we need better rules about when and how it is permissible for
companies to discriminate. Discrimination based on protected
characteristics like race and gender is already illegal, but those rules
are ineffectual against the current technologies of surveillance and
control. When people can be identified and their data correlated at a
speed and scale previously unseen, we need new rules.

Today, facial recognition technologies are receiving the brunt of the
tech backlash, but focusing on them misses the point. We need to have a
serious conversation about all the technologies of identification,
correlation and discrimination, and decide how much we as a society want
to be spied on by governments and corporations — and what sorts of
influence we want them to have over our lives.

Bruce Schneier is a fellow at the Harvard Kennedy School and the author,
most recently, of “Click Here to Kill Everybody: Security and Survival
in a Hyper-Connected World.”

*Like other media companies, The Times collects data on its visitors
when they read stories like this one. For more detail please see* [*our
privacy
policy*](https://help.nytimes.com/hc/en-us/articles/115014892108-Privacy-policy?module=inline)
*and* [*our publisher's
description*](https://www.nytimes.com/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection%2Fspotlightcollection%2Fprivacy-project-does-privacy-matter&action=click&contentCollection=opinion&region=stream&module=stream_unit&version=latest&contentPlacement=8&pgtype=collection)
*of The Times's practices and continued steps to increase transparency
and protections.*

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*Follow* [*@privacyproject*](https://twitter.com/privacyproject) *on
Twitter and The New York Times Opinion Section on*
[*Facebook*](https://www.facebook.com/nytopinion)
*and*[*Instagram*](https://www.instagram.com/nytopinion/)*.*

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006450604" data-slug="privacy-collection" style="max-width:2000px">

</div>

</div>

<div id="privacy-glossary-embed" class="section interactive-content interactive-size-scoop css-bvtwvj" data-id="100000006427375">

## glossary replacer

<div class="css-17ih8de interactive-body" data-sourceid="100000006427375">

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
