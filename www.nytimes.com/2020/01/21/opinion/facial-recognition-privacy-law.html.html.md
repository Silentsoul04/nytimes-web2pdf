<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Opinion](/section/opinion)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">We
Need a Law to Save Us From
Dystopia</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2NO5LRc</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div class="css-v5btjw etb61u70">

<div class="css-v05ibm etb61u71">

[Opinion](/section/opinion)

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# We Need a Law to Save Us From Dystopia

</div>

It’s not too late. And it better be comprehensive.

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1p10dcb ey68jwv0" data-aria-hidden="true">

[![Charlie
Warzel](https://static01.nyt.com/images/2019/03/15/opinion/charlie-warzel/charlie-warzel-thumbLarge-v3.png
"Charlie Warzel")](https://www.nytimes.com/by/charlie-warzel)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Charlie
Warzel</span>](https://www.nytimes.com/by/charlie-warzel)

<div class="css-8atqhb">

Mr. Warzel is an Opinion writer at large.

</div>

</div>

</div>

  - Jan. 21,
    2020

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Hoan
Ton-That testing the Clearview AI
app.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Amr
Alfiky for The New York
Times</span></span></span>](https://static01.nyt.com/images/2020/01/21/opinion/21warzelWeb/merlin_167287026_e9863609-1a6a-4104-b9cb-f3ebcef5c25b-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Over the long weekend, my newsroom colleague Kashmir Hill had [a
blockbuster article about a facial recognition
company](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html)
“that might end privacy as we know it.” It charts the rise of Clearview
AI, a company that scrapes images from social networks like Facebook,
YouTube, Venmo and millions of other sites to create a repository of
billions of images. Using Clearview’s app, law enforcement and
government agencies can upload a photo of a person and the database will
return matches to more photos and links to where the pictures came from.

You should read the whole article but one part that’s really stayed with
me comes from one of Clearview’s early investors, David Scalzo:

> “I’ve come to the conclusion that because information constantly
> increases, there’s never going to be privacy,” Mr. Scalzo said. “Laws
> have to determine what’s legal, but you can’t ban technology. Sure,
> that might lead to a dystopian future or something, but you can’t ban
> it.”

Mr. Scalzo’s quotation is helpful because he’s saying the quiet part out
loud. His reasoning is alarming: Privacy is dead and nothing should halt
the march of technological progress — not even the possibility of
dystopia.

Clearview’s founder, Hoan Ton-That, also seemed caught off guard when
asked to imagine the negative externalities of his tech. “There’s always
going to be a community of bad people who will misuse it,” he told The
Times. And when faced with the bigger question — How do you feel about
effectively eroding the ability to be anonymous in a crowd? — Mr.
Ton-That was hesitant. “I have to think about that,” he said. “Our
belief is that this is the best use of the technology.”

Mr. Ton-That and Mr. Scalzo give a master class in what the writer Rose
Eveleth calls “[the myth of inevitable technological
progress](https://www.vox.com/the-highlight/2019/10/1/20887003/tech-technology-evolution-natural-inevitable-ethics).”
Technologists decide to compare the creep of new tools to evolution — a
natural process. Of course, this isn’t true. Tech doesn’t evolve
naturally; it’s the result of calculated decisions by people motivated
by any number of factors: ambition, greed, curiosity or even boredom.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

A better, more depressing explanation comes from Al Gidari, a professor
specializing in privacy issues at Stanford Law School, who argues that
companies like Clearview will proliferate because “there is no monopoly
on math.” He then utters the most ominous line in the article: “Absent a
very strong federal privacy law, we’re all screwed.”

Professor Gidari is right. But what does a very strong federal privacy
law look like? It’s hard to know. In reporting out [our series on
location
data](https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html),
I kept running into examples of companies using loopholes to skirt
privacy laws like Europe’s General Data Protection Regulation.

Location data is declared technically “anonymous” even though it’s
easily tied to advertiser IDs or deanonymized. And so the companies
didn’t have to classify it as “personally identifiable information”
and don’t have to provide it to citizens who request it. In other cases,
I’ve heard anecdotes about companies simply claiming falsely that they
complied with privacy laws because they knew full well that regulators
wouldn’t scrutinize them.

Without teeth and tough enforcement, a federal privacy law won’t stop
techno-evolutionists like Mr. Ton-That and Mr. Scalzo. Which means the
law would have to be comprehensive. This brings me to a [Privacy Project
essay on
Monday](https://www.nytimes.com/2020/01/20/opinion/facial-recognition-ban-privacy.html)
by Bruce Schneier, a Harvard Kennedy School fellow and computer security
professional. In it, he discusses the scourge of facial recognition but
suggests that simply banning it isn’t enough. Instead, he argues, mass
surveillance has three important components: identification, correlation
and discrimination. Any privacy law needs to tackle all three.

Here’s Mr. Schneier’s key point:

> A ban on facial recognition won’t make any difference if, in response,
> surveillance systems switch to identifying people by smartphone MAC
> addresses. The problem is that we are being identified without our
> knowledge or consent, and society needs rules about when that is
> permissible.

Think of it this way: Facial recognition apps like Clearview AI are an
engine. But for the engine to run, it needs some kind of fuel, which is
provided by other areas of the surveillance economy. In Clearview’s
case, it’s the social networks like Facebook, which with lax privacy
settings and default-to-public profiles, allowed its users’ photos to be
scraped against the platforms’ own terms of service. None of these
companies operated in a vacuum and, as Mr. Schneier notes, even random
bits of information can tie anonymous data back to your true identity.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Perhaps most important, Mr. Schneier argues for “better rules about when
and how it is permissible for companies to discriminate.” This is
absolutely crucial as it is more about societal norms than any
particular line of code or piece of technology. Setting clear rules
about when technology can single us out and treat us differently based
on unique identification requires that we all pause and do the difficult
work of imagining the world we want to build. It means not hiding behind
the false premise that privacy-obliterating technology is inevitable, as
Mr. Ton-That and Mr. Scalzo have chosen to do.

We don’t have to resign ourselves to dystopia. It’s not inevitable. But
it will require something. We have to envision the world we want and
lobby for it. We have to demand that lawmakers create a framework that
allows technology to operate inside those constraints. And if we don’t,
Professor Gidari is likely right. We're all
screwed.

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006451534" data-slug="privacy-mid-nav-module" style="max-width:1050px">

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## Policing the Porch

I absolutely [loved this article on Ring doorbell
cameras](https://www.nytimes.com/2020/01/19/style/ring-video-doorbell-home-security.html)
by my newsroom colleague John Herrman. In it, he describes how Ring is
changing our relationships to the places we live in ways that feel
subtle now, but may soon feel drastic. “Ring is something like a
home-security counterpart to the work email account on your personal
phone, or the scheduling app buzzing you about a shift, ensuring you can
never truly clock out,” he writes. “Home surveillance means you’re never
quite home, but you’re never completely away from home, either.”

Here Mr. Herrman gets at something important. Privacy-eroding technology
warps our attention by allowing us to pay attention to things (like our
front steps) that we previously couldn’t. In Ring’s case there’s a
personal effect, which is that you’re constantly tethered to your home.
But there’s also a public element to Ring’s surveillance, as the article
notes:

> The presence of a camera at the door creates peculiar new forms of
> interaction. The father who half-seriously interrogated his daughter’s
> date — in a video publicized by the company and later covered by
> national news outlets — was at work when his phone buzzed. He
> conducted his grilling remotely, using the doorbell’s voice function.
> Ring cameras themselves are [now being
> stolen](https://chicago.cbslocal.com/2019/12/19/ring-home-camera-thefts/),
> leaving their owners with a final few seconds of footage — a hand, a
> face, a mask — before losing their connections.

Already we’re seeing ways that Ring is commandeering and warping our
attention. Ring’s social network, Neighbors, feeds a steady stream of
porch videos onto the internet. They fuel local news coverage, sometimes
depicting funny or silly moments but, more often than not, showing a
petty thief absconding with a box. The clips go viral, and sometimes
they’re picked up by national news outlets.

In this way, Ring makes the hyperlocal national. Our attention is
directed to a porch in a small town we’ve never heard of, watching
footage of somebody we don’t know that’s been recorded by somebody who
isn’t home. And yet maybe we feel violated just watching those clips.
The world feels less safe. We think about our own porches and the
packages that may or may not be waiting for us. Who’s on our stoop? Who
might show up?

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The type of constant surveillance offered by technology like Ring has
many obvious downsides. It can fuel our paranoia or our worst,
discriminatory instincts. But, just as important, it can begin to chip
away at our sense of place. As Mr. Herrman writes, it places us in a
strange tech-fueled purgatory. We’re never quite in the moment, but
we’re never quite removed from it, either.

## What I’m Reading:

[Can we ever trust Google with our health
data?](https://www.ft.com/content/4ade8884-1b40-11ea-97df-cc63de1d73f4)

[Apple vs. F.B.I.: Pensacola Isn’t San
Bernardino](https://www.lawfareblog.com/apple-vs-fbi-pensacola-isnt-san-bernardino)

[Thousands of Chinese Students’ Data Exposed on
Internet](https://www.wsj.com/articles/thousands-of-chinese-students-data-exposed-on-internet-11579283410?mod=e2tw)

[E.U. Considers Temporary Ban on Facial Recognition in Public
Spaces](https://www.politico.eu/pro/eu-considers-temporary-ban-on-facial-recognition-in-public-spaces/)

*Like other media companies, The Times collects data on its visitors
when they read articles like this one. For more detail please see* [*our
privacy
policy*](https://help.nytimes.com/hc/en-us/articles/115014892108-Privacy-policy?module=inline)
*and* [*our publisher's
description*](https://www.nytimes.com/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection%2Fspotlightcollection%2Fprivacy-project-does-privacy-matter&action=click&contentCollection=opinion&region=stream&module=stream_unit&version=latest&contentPlacement=8&pgtype=collection)
*of The Times's practices and continued steps to increase transparency
and protections.*

*Follow* [*@privacyproject*](https://twitter.com/privacyproject) *on
Twitter and The New York Times Opinion Section on*
[*Facebook*](https://www.facebook.com/nytopinion)
*and*[*Instagram*](https://www.instagram.com/nytopinion/)*.*

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006450604" data-slug="privacy-collection" style="max-width:2000px">

</div>

</div>

<div id="privacy-glossary-embed" class="section interactive-content interactive-size-scoop css-bvtwvj" data-id="100000006427375">

## glossary replacer

<div class="css-17ih8de interactive-body" data-sourceid="100000006427375">

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
