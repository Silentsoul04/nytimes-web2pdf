<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Opinion](/section/opinion)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">The
Flawed Humanity of Silicon
Valley</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2vuAlsM</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div class="css-v5btjw etb61u70">

<div class="css-v05ibm etb61u71">

[Opinion](/section/opinion)

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# The Flawed Humanity of Silicon Valley

</div>

Behind the scenes of the surveillance economy.

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1p10dcb ey68jwv0" data-aria-hidden="true">

[![Charlie
Warzel](https://static01.nyt.com/images/2019/03/15/opinion/charlie-warzel/charlie-warzel-thumbLarge-v3.png
"Charlie Warzel")](https://www.nytimes.com/by/charlie-warzel)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Charlie
Warzel</span>](https://www.nytimes.com/by/charlie-warzel)

<div class="css-8atqhb">

Mr. Warzel is an opinion writer at large.

</div>

</div>

</div>

  - Jan. 28,
    2020

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">“Uncanny
Valley,” a memoir by Anna
Wiener.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Sonny
Figueroa/The New York
Times</span></span></span>](https://static01.nyt.com/images/2020/01/28/opinion/28warzelWeb/28warzelWeb-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Every week brings a fresh hell in the tech world. As news of the latest
scandals pile up over weeks, months and eventually years, narratives
switch. Friendly tech companies become “Big Tech.” The narrative is
flattened. The tech giants become monolithic and their employees become
caricatures — often of villains.

The truth is always messier, more interesting and more human. It is a
central tension animating Anna Wiener’s excellent memoir, “[Uncanny
Valley.](https://us.macmillan.com/books/9780374719760)” The book traces
Ms. Wiener’s navigating the tech world as a start-up employee in the mid
2010s — what might be thought of as the last years before Silicon
Valley’s fall from darling status. Ms. Wiener said she was drawn into
the tech world by its propulsive qualities. Graduating into a recession
and spending her early 20s in publishing, tech offered opportunities:
jobs, the seductive feeling of creating something and, of course, the
money was good.

But what makes “Uncanny Valley” so valuable is the way it humanizes the
tech industry without letting it off the hook. The book allows us to see
the way that flawed technology is made and marketed: not by villains,
but by blind spots, uncritical thinking and armies of ambivalent people
coming into work each day trying their best — all while, sometimes
unwittingly, laying the foundation of the surveillance economy.

From a privacy standpoint, “Uncanny Valley” is helpful in understanding
what it’s like being on the other end of the torrent of information that
streams from our devices each minute. Early on, Ms. Wiener recounts
working for a successful data analytics company and the gold rush toward
big data, noting that “not everyone knew what they needed from big data,
but everyone knew that they needed it.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

When confronted with the mass of information her company collected, Ms.
Wiener describes feeling uncomfortable with the “God Mode” view that
granted employees full access to user data. “This was a privileged
vantage point from which to observe the tech industry, and we tried not
to talk about it,” she writes. This, she notes, becomes a pattern. When
Edward Snowden blew the whistle on the [National Security Agency’s Prism
program
in 2013](https://www.washingtonpost.com/news/wonk/wp/2013/06/12/heres-everything-we-know-about-prism-to-date/),
employees at her own data company never discussed the news.

What she describes is a familiar dissociation for anyone who spends time
interrogating tech companies on their privacy policies. Her company
simply didn’t consider itself part of the surveillance economy:

> “We weren’t thinking about our role in facilitating and normalizing
> the creation of unregulated, privately held databases on human
> behavior. We were just allowing product managers to run better A/B
> tests. We were just helping developers make better apps. It was all so
> simple: people loved our product and leveraged it to improve their own
> products, so that people would love them, too. There was nothing
> nefarious about it. Besides, if we didn’t do it, someone else would.
> We were far from the only third-party analytics tool on the market.
> The sole moral quandary in our space that we acknowledged outright was
> the question of whether or not to sell data to advertisers. This was
> something we did not do, and we were righteous about it. We were just
> a neutral platform, a conduit. If anyone raised concerns about the
> information our users were collecting, or the potential for abuse of
> our product, the solutions manager would try to bring us back to earth
> by reminding us that we weren’t data brokers. We did not build
> cross-platform profiles. We didn’t involve third parties. Users might
> not know they were being tracked, but that was between them and our
> customer companies.”

They were, in other words, just doing their jobs.

Ms. Wiener frequently returns to this reticence to question the product,
the end goals of the technology and the Silicon Valley ethos as a
whole.

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006451534" data-slug="privacy-mid-nav-module" style="max-width:1050px">

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

At her next job working on the terms of service team for a large open
source code platform, she reveals how the evolution of the internet
pushed her and her co-workers into becoming “reluctant content
moderators.” Soon it became her team’s job to fashion a balance between
preserving free speech on her platform and protecting it from trolls and
neo-Nazis:

> “We wanted to tread lightly: core participants in the open-source
> software community were sensitive to corporate oversight, and we
> didn’t want to undercut anyone’s techno-utopianism by becoming an
> overreaching arm of the company-state. We wanted to be on the side of
> human rights, free speech and free expression, creativity and
> equality. At the same time, it was an international platform, and who
> among us could have articulated a coherent stance on international
> human rights?”

As a journalist who has covered content moderation issues for the better
part of a decade, the perspective is somewhat clarifying. Decisions that
feel ad hoc or made by one or two people in the belly of a large company
often are. What looks from the outside like a conspiracy or nefarious
techno-authoritarianism is often just confusion caused by poor
management, poor communication and dizzying growth. “Most of the company
did not seem aware of how common it was for our tools to be abused,” Ms.
Wiener writes of her group of de facto moderators. “They did not even
seem to know that our team existed. It wasn’t their fault — we were easy
to miss. There were four of us for the platform’s nine million users.”

In this instance, “Uncanny Valley” shows how the internet can thrust
ordinary people into extraordinary positions of power — usually without
qualifications or a how-to guide. This is not to say that the book
excuses any of the industry’s reckless behavior. Like a good travel
writer, Ms. Wiener positions herself as an insider-outsider,
“participating in something bigger than myself and still feeling apart
from it.” And she is sufficiently critical of her and her peers’
participation in the industry. She writes that she would “wonder whether
the N.S.A. whistle-blower had been the first moral test for my
generation of entrepreneurs and tech workers, and we had blown it,” she
writes at one point near the end of the memoir.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Ms. Wiener’s memoir comes at a point where the backlash against Silicon
Valley is strong enough to have earned its own name. Narratives have
hardened and aggrieved tech employees are adopting a [“bunker
mentality.”](https://www.buzzfeednews.com/article/charliewarzel/facebooks-tensions-zuckerberg-sandberg)
As [Ranjan Roy of the newsletter Margins
wrote](https://themargins.substack.com/p/facebooks-pr-feels-broken)
recently of Facebook, “the rank and file are seeing that they are the
villains, and will increasingly become so.” As so much of the reporting
shows, the increased scrutiny and criticism of the techlash is important
and almost all is warranted. Big Tech has amassed wild, unregulated
power that has grown unchecked.

Still, it’s easy to get conspiratorial and to fall comfortably into
black and white notions of good versus evil. “Uncanny Valley” is a
reminder that the reality is far more muddled but no less damning. Our
dystopia isn’t just the product of mustache-twirling billionaires drunk
with power and fueled by greed — though it is that, too, sometimes. It’s
also the result of uncritical thinking, blind spots caused by an
overwhelmingly white male work force and a pathological reluctance to
ask the bigger question: Where is this all going? What am I building?

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## What I’m Reading:

[Facebook will now show you exactly how it stalks you — even when you’re
not using
Facebook.](https://www.washingtonpost.com/technology/2020/01/28/off-facebook-activity-page/)

[Ring doorbell app packed with third-party
trackers.](https://www.eff.org/deeplinks/2020/01/ring-doorbell-app-packed-third-party-trackers)

[Leaked documents expose the secretive market for your web browsing
data.](https://t.co/kXGegjaSPp?amp=1)

[40 groups have called for a U.S. moratorium on facial recognition
technology](https://www.technologyreview.com/f/615098/facial-recognition-clearview-ai-epic-privacy-moratorium-surveillance/)

*Like other media companies, The Times collects data on its visitors
when they read stories like this one. For more detail please see* [*our
privacy
policy*](https://help.nytimes.com/hc/en-us/articles/115014892108-Privacy-policy?module=inline)
*and* [*our publisher's
description*](https://www.nytimes.com/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection%2Fspotlightcollection%2Fprivacy-project-does-privacy-matter&action=click&contentCollection=opinion&region=stream&module=stream_unit&version=latest&contentPlacement=8&pgtype=collection)
*of The Times's practices and continued steps to increase transparency
and protections.*

*Follow* [*@privacyproject*](https://twitter.com/privacyproject) *on
Twitter and The New York Times Opinion Section on*
[*Facebook*](https://www.facebook.com/nytopinion)
*and*[*Instagram*](https://www.instagram.com/nytopinion/)*.*

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006450604" data-slug="privacy-collection" style="max-width:2000px">

</div>

</div>

<div id="privacy-glossary-embed" class="section interactive-content interactive-size-scoop css-bvtwvj" data-id="100000006427375">

## glossary replacer

<div class="css-17ih8de interactive-body" data-sourceid="100000006427375">

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
