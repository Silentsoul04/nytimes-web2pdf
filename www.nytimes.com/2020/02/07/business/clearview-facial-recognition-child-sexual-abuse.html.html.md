<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Business](https://www.nytimes.com/section/business)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Business](/section/business)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">Clearview’s
Facial Recognition App Is Identifying Child Victims of
Abuse</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/2OAw6Cq</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# Clearview’s Facial Recognition App Is Identifying Child Victims of Abuse

</div>

Though a breakthrough for law enforcement, the technique could allow the
little-known start-up to collect an extraordinarily sensitive set of
data and images.

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Hoan
Ton-That, the founder of Clearview AI, testing the company’s app last
month.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Amr
Alfiky for The New York
Times</span></span></span>](https://static01.nyt.com/images/2020/02/07/business/07CLEARVIEW-01/merlin_167287035_0c3ff0e2-b4b7-4c2b-a1a7-e5054b500409-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz" itemprop="name">Kashmir
Hill</span>](https://www.nytimes.com/by/kashmir-hill) and
[<span class="css-1baulvz last-byline" itemprop="name">Gabriel J.X.
Dance</span>](https://www.nytimes.com/by/gabriel-dance)

</div>

</div>

  - 
    
    <div class="css-ld3wwf e16638kd2">
    
    Published Feb. 7, 2020Updated Feb. 10,
    2020
    
    </div>

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-pvvomx" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Law enforcement agencies across the United States and Canada are using
[Clearview
AI](https://www.nytimes.com/2020/02/10/podcasts/the-daily/facial-recognition-surveillance.html)
— a secretive facial recognition start-up with a database of three
billion images — to identify children who are victims of sexual abuse.
It’s a powerful use case for the company’s technology, but raises new
questions about the tool’s accuracy and how the company handles data.

Investigators say Clearview’s tools allow them to learn the names or
locations of minors in exploitative videos and photos who otherwise
might not have been identified. In one case in Indiana, detectives ran
images of 21 victims of the same offender through Clearview’s app and
received 14 IDs, according to Charles Cohen, a retired chief of the
state police. The youngest was 13.

“These were kids or young women, and we wanted to be able to find them
to tell them we had arrested this guy and see if they wanted to make
victim statements,” Mr. Cohen said.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Another official, a victim identification officer in Canada, who was not
authorized to discuss investigations publicly, described Clearview’s
technology as “the biggest breakthrough in the last decade” in the field
of child sexual abuse crimes.

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

But privacy advocates say the company’s database is untested and
unregulated, and could cause new kinds of harm. Clearview stores
pictures uploaded by investigators — known as probe images — on its
servers, meaning it could amass an extraordinarily sensitive data set of
child victims of sexual abuse and exploitation.

“We understand the extreme sensitivity involved with identifying
children,” Clearview’s founder, Hoan Ton-That, wrote in an email. “Our
mission is to protect children.”

According to a [company
document](https://int.nyt.com/data/documenthelper/6690-clearview-faq/c8b081a0bcca12e7903a/optimized/full.pdf#page=1)
distributed to clients, “searches are retained forever” by default, but
administrators can change their settings so search images are purged
after 30 days.

Clearview operated largely in the shadows until [a New York Times
report](https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html)
last month revealed its use by local and federal law enforcement
agencies across the country. The company has harvested billions of
photos of individuals from the public internet, including sites such as
Facebook, Twitter, Venmo and YouTube. When a user uploads a person’s
photo to Clearview, the app returns other images of the person and the
web addresses where they appeared.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

In numerous publicity documents, Clearview promotes the use of its
technology by law enforcement to solve child sexual abuse cases. But
until recently, the company focused on its role in **** identifying
perpetrators, not victims.

Critics of Clearview said the benefits of such a database did not
outweigh its harms.

“It’s tough. Everybody wants safety and to save kids,” said Liz
O’Sullivan, technology director at the Surveillance Technology
Oversight Project. “There is always some way to normalize surveillance,
but it would be dangerous for us to focus on the potential upsides.
Facial recognition makes a lot of mistakes.”

Ms. O’Sullivan said she was concerned that Clearview’s software had not
been tested for accuracy by an independent agency. Facial recognition
algorithms can work poorly on young people, partly because their faces
change as they age, and partly because children are often not included
in the data sets used to train the algorithms.

Ms. O’Sullivan noted that if the tool made an incorrect match, there
could be devastating effects for wrongly identified children and their
families.

“The exchange of freedom and privacy for some early anecdotal evidence
that it might help some people is wholly insufficient to trade away our
civil liberties,” she said.

Law enforcement is required to verify each identity when it uses the
Clearview app, Mr. Ton-That said in his email. But he could not say how
many children were in its database.

“We do not track the age, gender or racial breakdown of our image
database,” he said. “We are a search engine for public images, not a
surveillance system.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The app is being used by task forces in Florida, Indiana and South
Dakota dedicated to investigating child abuse, as well as by the
Department of Homeland Security and law enforcement in Canada.

Like several officers who spoke with The Times, the Canadian
investigator was reluctant to discuss Clearview, fearing offenders would
shift their tactics.

“Our concern is that when bad guys hear this is available, they will
cover up the victims’ faces more,” the officer said. “We don’t want bad
guys to know this is
possible.”

</div>

</div>

<div class="audioFigureHeading">

<div class="css-1et479a">

![](https://static01.nyt.com/images/2017/01/29/podcasts/the-daily-album-art/the-daily-album-art-articleInline-v2.jpg?quality=75&auto=webp&disable=upscale)

</div>

### Listen to ‘The Daily’: The End of Privacy as We Know It?

<span class="css-59o34k">An unregulated facial recognition app can
probably tell the police your name, and help them find out where you
live and who your friends are.</span>

</div>

<div class="css-qe9gm7">

<div>

<div class="css-1g7y0i5 e1drnplw0">

<div class="css-1ceswkc e1drnplw1">

</div>

<div class="css-f2fzwx e1drnplw2">

<div data-aria-labelledby="modal-title" data-role="region">

<div id="modal-title" class="css-mln36k">

transcript

</div>

<div class="css-pbq7ev">

</div>

<span>Back to The
Daily</span>

<div class="css-f6lhej">

<div class="css-1ialerq">

<div class="css-1701swk">

bars

</div>

<div>

<div class="css-1t7yl1y">

0:00/31:46

</div>

<div class="css-og85jy">

\-31:46

</div>

</div>

</div>

</div>

<div class="css-15fbio0">

<div class="css-1p4nyns">

transcript

## Listen to ‘The Daily’: The End of Privacy as We Know It?

### Hosted by Michael Barbaro; produced by Annie Brown and Daniel Guillemette; with help from Michael Simon Johnson; and edited by Paige Cowett and Larissa Anderson

#### An unregulated facial recognition app can probably tell the police your name, and help them find out where you live and who your friends are.

</div>

  - \[music\]

  - michael barbaro  
    From The New York Times, I’m Michael Barbaro. This is “The Daily.”
    
    Today: A secretive company promising the next generation of facial
    recognition software has compiled a database of images far bigger
    than anything ever constructed by the U.S. government. The Daily’s
    Annie Brown speaks to reporter Kashmir Hill about whether the
    technology is a breakthrough for law enforcement or the end of
    privacy as we know it.
    
    It’s Monday, February 10.

  - annie brown  
    Kashmir, how did this story come to you?

  - kashmir hill  
    So I got an email. It was a Wednesday morning. I was checking my
    phone. And it was from a tipster who had gotten a bunch of documents
    from police departments. And one of the police departments had sent
    along this memo about a private company that was offering a radical
    new tool to solve crimes using facial recognition.

  - annie brown  
    And what would make a facial recognition tool radical?

  - kashmir hill  
    So law enforcement has for years had access to facial recognition
    tools. But what this company was offering was unlike any other
    facial recognition tools that police have been using, because they
    had scraped the open web of public photos — from Facebook, from
    Venmo, from Twitter, from education sites, employment sites — and
    had a massive database of billions of photos. So the pitch is that
    you can take a picture of a criminal suspect, put their face into
    this app and identify them in seconds.

  - annie brown  
    And when you read this memo, what do you make of what this company
    is offering?

  - kashmir hill  
    So I’ve been covering privacy for 10 years, and I know that a
    technology like this in public hands is the nightmare scenario.

  - \[music\]  
    This has been a tool that was too taboo for Silicon Valley giants
    who were capable of building it. Google in 2011 said that they could
    release a tool like this, but it was the one technology they were
    holding back because it could be used in a very bad way.

  - annie brown  
    And why exactly is this kind of technology this line in the sand
    that no one will cross? What makes it so dangerous?

  - kashmir hill  
    So imagine this technology in public hands. It would mean that if
    you were at a bar and someone saw you and was interested in you,
    they could take your photo, run your face through the app, and then
    it pulls up all these photos of you from the internet. It probably
    takes them back to your Facebook page. So now they know your name,
    they know who you’re friends with, they can Google your name, they
    can see where you live, where you work, maybe how much money you
    make. Let’s say you’re a parent and you’re walking down the street
    with your three-year-old. Somebody can take a photo of you and know
    where the two of you live. Imagine you’re a protester in the U.S. or
    in a more authoritarian regime. All of a sudden they know everything
    about you, and you can face repercussions for just trying to
    exercise your political opinions. If this app were made publicly
    available, it would be the end of being anonymous in public. You
    would have to assume anyone can know who you are any time they’re
    able to take a photo of your face.

  - annie brown  
    And so that technology is what this company is pitching these police
    departments?

  - kashmir hill  
    Exactly.

  - annie brown  
    And what do you know about this company at this point?

  - kashmir hill  
    So at this point, all I really know is that the company is called
    Clearview AI. And so the first thing I do is Google it. And I find
    their website, which is clearview.ai. And the website is pretty
    bare, but there’s also an office address listed there, 145 West 41st
    Street, which happens to be just a couple of blocks from The New
    York Times office.

  - annie brown  
    Right.

  - kashmir hill  
    So I decided to walk over there, and there just is no 145 West 41st
    Street. So that was weird. So now I have this company that’s
    offering this radical new tool —

  - annie brown  
    It’s got a fake address.

  - kashmir hill  
    It’s got a fake address, which is a huge red flag.

  - annie brown  
    So what you do next?

  - kashmir hill  
    I found the company on LinkedIn. It only had one employee listed, a
    sales manager named John Good, which —

  - annie brown  
    John Good.

  - kashmir hill  
    John Good. It seemed like it could also be fake. And I sent that
    person a LinkedIn message and never heard back. So one of the things
    I find online is a website called PitchBook that lists investments
    in start-ups. And so it says that this Clearview AI has received $7
    million from a venture capital firm and from Peter Thiel — you know,
    a big name in Silicon Valley, invested in Facebook and Palantir. So
    I reach out to his spokesperson, and he says I’ll get back to you. I
    never hear from him again. And then one day, I open up Facebook, and
    I have a message from a friend whose name I don’t recognize. And he
    says, hey, I hear you’re looking into Clearview AI. I know them.
    They’re a great company. How can I help?

  - annie brown  
    And you don’t know who this guy is?

  - kashmir hill  
    I don’t. I mean, it’s a guy I met once 10 years ago. And somehow he
    knows that I’m looking into this company. But I’ll take it. You
    know, finally —

  - annie brown  
    Right\!

  - kashmir hill  
    — somebody wants to talk to me about Clearview AI. And so I say,
    hey, can I give you a call? And then he doesn’t respond, which I’m
    getting used to.

  - annie brown  
    You just can’t catch a break.

  - kashmir hill  
    I know. I’m like, I cannot believe this is another dead end.
    
    So phone and email are not working for me. So I just need to figure
    out another door to knock on to try to talk to a real human being.
    And one of the investors in the company is this venture capital firm
    that has an office in Bronxville, New York. So on a cold, rainy
    Tuesday, I got on the train and headed to Bronxville. I get to the
    company’s address. It’s just like in a retail space. And go inside.
    There’s this long, quiet hallway of office suites, and this venture
    capital firm is at the very end. And I knock on the door, and
    there’s no one there. So I start trying to talk to their
    neighbors, and a woman who works next door says, oh yeah, they’re
    never here. So I’m walking down the stairs to go back out of the
    building, and two guys walk through the door. They’re both in dark
    suits with lavender and pink shirts underneath, and they just kind
    of look like V.C.s to me. So I say, hey, are you with this venture
    capital firm? And they say, we are. Who are you? And I was like, I’m
    the New York Times reporter who’s been trying to get in touch with
    you. And they said, the company has told us not to talk to you. And
    I said, well I’ve come all the way out to Bronxville. Can we just
    chat for a little bit? And they say, O.K. If probably helps that I’m
    very pregnant, and they offered me water. And they just start
    telling me everything.

  - \[music\]

  - annie brown  
    And what do they tell you?

  - kashmir hill  
    They confirm that they’ve invested in Clearview AI and that Peter
    Thiel has also invested. They identified the genius coder behind the
    company, this guy named Hoan Ton-That. And they say he’s Vietnamese
    royalty but he’s from Australia. And they also tell me that Hoan is
    the one that was using the fake name John Good on LinkedIn.

  - annie brown  
    He’s John Good.

  - kashmir hill  
    He’s John Good.
    
    And they confirm that law enforcement is already using the app. And
    that law enforcement loves it and that it’s spreading like wildfire.

  - annie brown  
    Wow.

  - kashmir hill  
    So I’ve learned some stuff from these two investors, but no one from
    the company is talking to me still. So in the meantime, I am also
    reaching out to law enforcement, because I want to know if this app
    really works as well as the company claims. By this point, I had
    learned that over 600 law enforcement agencies had tried the app,
    including the Department of Homeland Security and the F.B.I.

  - annie brown  
    Wow. It’s not just local police departments. This is being used by
    the federal government already.

  - kashmir hill  
    Yeah, I mean, I was just shocked to discover how easily government
    agencies can just try a new technology without apparently knowing
    much about the company that provides it. So I talked to a retired
    police chief from Indiana, who was actually one of the first
    departments to use the app. And they solved a case within 20
    seconds, he said.

  - annie brown  
    A case they hadn’t been able to solve?

  - kashmir hill  
    That they hadn’t been able to solve. One of the officers told me
    that he went back through like 30 dead-end cases that hadn’t had any
    hits on the government database, and he got a bunch of hits using
    the app. So they were really excited about it.

  - annie brown  
    This is way more effective than what they were using before.

  - kashmir hill  
    Exactly. With the government databases they were previously using,
    they had to have a photo that was just a direct full-face photo of a
    suspect — like mug shots and driver’s license photos. But with
    Clearview, it could be a person wearing glasses, or a hat, or part
    of their face was covered, or they were in profile, and officers
    were still getting results on these photos.

  - annie brown  
    Wow.

  - kashmir hill  
    But the most astounding story I was told was that investigators had
    this child exploitation video, and there was an adult who was
    visible in the video just for a few seconds in the background. So
    they had this person’s face. They had run it through their usual
    databases and not gotten anything back. But then they ran his face
    through Clearview’s app, and he turned up in the background of
    someone else’s gym selfie. You could see his face in the mirror. And
    so they figured out what gym this photo was taken out. They went to
    the gym. They asked the employees, do you know who this is? And the
    employee said, we can’t tell you. We have to protect our members’
    privacy. But then later, the detectives got a text from somebody who
    worked there identifying the person. And that — I mean, that’s just
    something that would not have been possible without Clearview’s app.
    
    So because officers were telling me the tool works so well, I wanted
    to see it for myself, on myself. And I asked them if they would run
    my photo through the app. But every time I did this, things would
    get weird. The officers would tell me that they ran my photo and
    there were no results.

  - annie brown  
    No pictures of you?

  - kashmir hill  
    There were no pictures of me, which was really weird, because I have
    a lot of photos of myself online. And then officers would just stop
    responding to me or talking to me. And I had no idea what was going
    on until one officer was kind enough to explain to me.

  - \[phone ringing\]

  - officer  
    Hello, how are you.

  - kashmir hill  
    Hey. It’s Kashmir.

  - officer  
    Yes, hi. Mm-hmm.

kashmir hill

I’m keeping this officer anonymous because he could get in serious
trouble for talking to me so openly about Clearview.

  - kashmir hill  
    If you could just describe yourself, to the extent that you can
    describe yourself.

  - officer  
    I’m a police officer at a large metropolitan police department.

kashmir hill

So he’s a cop who was doing a 30-day free trial of the app. And he was
really impressed with it. So I asked him if he wouldn’t mind running my
photo.

annie brown

And what did he tell you happened when he sent your picture through?

  - officer  
    Yeah, nothing. I didn’t get a response at all.

  - kashmir hill  
    No results?

  - officer  
    No results. And within a couple of minutes of me putting your photo
    up there — maybe five, less than 10 — I got a phone call from the
    Clearview company. They wanted to know why I was uploading a New
    York Times reporter’s photo.

  - kashmir hill  
    That is so wild. I don’t know. \[LAUGHS\] It creeps me out as a
    reporter. I mean yeah, it just —

  - officer  
    It kind of creeped me out as a user.

kashmir hill

So this implied that Clearview flagged my face in their system such that
they got an alert when a police officer ran my face. Which I found —

annie brown

Wow.

kashmir hill

— very alarming, because this is telling me for the first time that this
company is able to monitor who law enforcement is looking for, and not
just know who they’re looking for, but manipulate the results. And so
then that made me go back to the earlier officers who had run my photo.
And they all confirmed, yes, I got a call from the company, and they
said, we’re not supposed to be talking to the media.

\[music\]

  - kashmir hill  
    So were you able to keep using the app after that?

  - officer  
    My account was deactivated.

  - kashmir hill  
    Did you ever get access back?

  - officer  
    I never did. But I have colleagues that have access. So if I were to
    need a picture searched, I could just email it to them and they can
    email me the results.

  - kashmir hill  
    And you think the trade-offs are worth it, in terms of what the
    company has access to?

  - officer  
    Do I think it’s worth it? So from a law enforcement perspective,
    it’s worth it. We get a lot of cases, and we don’t usually have a
    lot of leads. And so anything that can — honestly, anything that can
    help us solve a crime is a win for us. From a privacy perspective,
    it’s rather frightening the amount of information that they were
    able to get and provide. As long as they’re doing it for the right
    reasons, then everything will work out. Let’s put it that way.

\[music\]

kashmir hill

But the problem is we don’t know anything about the company at this
point. We don’t know if there’s any kind of oversight. We don’t know who
the people are that are operating this and what their intentions are
with their product. The person in charge of the company won’t talk to
me. But then, it’s the end of December when I get a call from the
company’s spokeswoman. And she says that the founder, Hoan Ton-That, is
ready to talk.

michael barbaro

We’ll be right back.

  - kashmir hill  
    Do you have a hard stop?

  - hoan ton-that  
    No I don’t actually. 12:30.

  - lisa linden  
    12:00 noon.

  - hoan ton-that  
    Oh, 12:00 noon.

  - kashmir hill  
    I have no hard stop.

  - lisa linden  
    Oh.

  - kashmir hill  
    And I have lots of questions, so I’ll take as much time as you can
    give me.

annie brown

So Kashmir, you finally got an interview with the founder of Clearview,
this man named Hoan Ton-That. Where do you meet him?

kashmir hill

So we met in a WeWork in Chelsea. He came down to the lobby.

  - kashmir hill  
    You like New York, you’re going to stay here?

  - hoan ton-that  
    Oh, yeah.

kashmir hill

And his appearance surprised me, because I had Googled him online and
there are a lot of photos of him. And he’s usually pretty eccentric —
like a lot of paisley shirts, he’s at Burning Man.

  - hoan ton-that  
    Let’s go to the back room.

kashmir hill

But in person he was very conservative. He was in this dark blue navy
suit with a white button-up and leather shoes. So he looked very much
like the security start-up entrepreneur.

annie brown

He was looking the part.

kashmir hill

He was looking the part.

  - kashmir hill  
    When were you born? How old are you?

  - hoan ton-that  
    ‘88, so I’m 31.

  - kashmir hill  
    O.K.

annie brown

And what do you learn about him?

kashmir hill

So he is 31. He grew up in Australia, but you can’t hear that in his
voice.

  - hoan ton-that  
    I love computers, obviously.

  - kashmir hill  
    Yeah, so how did you get interested in technology?

  - hoan ton-that  
    We had a computer, of course, when I was four or five years old.

kashmir hill

So his family got a computer when he was three or four, and he was
always tinkering with computers growing up.

  - hoan ton-that  
    We got the internet when I was 10, I think. And then you could
    discover all these things online. But Linux, I was like I have to
    get this thing. It’s the nerdiest thing ever. I convinced my dad. We
    installed it, and I would spend the whole summer reinstalling and
    learning Linux stuff, staying home from high school and learning
    programming for fun. So that’s — I just really liked it.

kashmir hill

He enrolled in college, decided to drop out like many technologists do,
and moved to San Francisco when he was 19.

  - hoan ton-that  
    — 2007, before it was a big thing, right? It was kind of getting
    there, but it wasn’t huge.

kashmir hill

This is 2007, and this is kind of a boom time. The iPhone has just come
out.

  - hoan ton-that  
    That’s the Facebook app era. Remember that?

  - kashmir hill  
    Yeah.

kashmir hill

People are becoming millionaires by making Facebook games. And he wants
to be the next big app guy.

  - hoan ton-that  
    Being there is a lot different from reading about it online. You
    absorb a lot more of how people get things done. And you learn a lot
    more secrets.

annie brown

What did he built?

kashmir hill

So the Facebook apps were like “would you rather” apps and kind of like
romantic GIFs.

  - hoan ton-that  
    Did Some of the first iPhone games as well.

kashmir hill

One of his most recent apps was called Trump Hair, and it was an app for
adding Trump’s hair to your photos.

annie brown

That’s it?

kashmir hill

That’s it. The tagline was, “It’s gonna be yuge\!”

annie brown

O.K. \[LAUGHS\] So how do you move from a Donald Trump hair app to
something that seems like it could revolutionize police work?

kashmir hill

Well, he moved to New York. And that seemed to be a big change for him.
And he started meeting very different people. And one of the most
important people he met was Richard Schwartz.

  - hoan ton-that  
    I ended up meeting Richard at a party.

kashmir hill

This 61-year-old guy who worked for Mayor Rudy Giuliani in the 1990s. He
was just very politically connected.

  - hoan ton-that  
    I really loved that. He had a lot of stories. And then we talked for
    an hour about different ideas. Because I was like, this is what I do
    — technology. I can make anything. And it went from there.

kashmir hill

And the two of them decided, with Hoan Ton-That’s tech know-how and
Richard’s Rolodex, that they want to try to start a facial recognition
company together.

annie brown

And why facial recognition? Why did the two of them choose that?

kashmir hill

I think it was because Hoan had started reading a lot of papers about
facial recognition and machine learning.

  - hoan ton-that  
    I had never really studied AI stuff before, but I could pick up a
    lot of it.

kashmir hill

And I think they realized they could make money doing it.

  - kashmir hill  
    What would you say, in terms of the range of ideas at first, what
    were you thinking?

  - hoan ton-that  
    A lot. I could go on, really crazy, but —

kashmir hill

There’s a lot of face recognition algorithms out there, and a lot that
work pretty well. What was different about what Hoan Ton-That and
Richard Schwartz were doing is they had been willing to scrape all of
these photos from the internet. So they just had a huge database of
photos.

annie brown

Right, the billions of photos.

kashmir hill

Exactly.

  - hoan ton-that  
    And then we had this point where we got to 99 percent accuracy. I
    remember that, it was just in the office. And he was like, wow, it
    works. Try that one again. Try that one again. And just every time,
    it would pick the right person out. And that’s when we knew, this is
    crazy. This actually works.

annie brown

Is that legal? Can you just take photographs from anywhere on the
internet and use them for this kind of thing?

kashmir hill

There was a ruling in a federal court this fall that said, yeah, this
kind of public scraping seems to be legal.

annie brown

And what are they hoping to do with this software at this point?

kashmir hill

I mean, they’re just trying to figure out how they can make money off of
the app. And so they eventually end up settling on law enforcement.

  - hoan ton-that  
    And they start solving cases from grainy A.T.M. photos, cases they
    would’ve never solved. So this spread to different departments, and
    then from one agency to other agencies.

annie brown

And do you ask him about that thing that happened with the officer who
couldn’t find your photos?

kashmir hill

Yeah, so that was one of my questions, and I wasn’t entirely satisfied
by his answer.

  - hoan ton-that  
    So —

  - kashmir hill  
    One thing that surprised me — some of the officers I talked to tried
    to run my photo through it, and they got no hits. And I tons of
    photos online.

  - hoan ton-that  
    \[LAUGHS\] It must have been a bug.

  - kashmir hill  
    Did you guys block me from like getting results?

  - hoan ton-that  
    I don’t know about that.

  - kashmir hill  
    Because I was like, this doesn’t make any sense.

kashmir hill

He said, oh yeah, that was a software bug. But he laughed.

  - kashmir hill  
    I was like, I have 1,000 photos online. This can’t work as well as
    they say it works.

  - hoan ton-that  
    Yeah, well, it must have been a bug in the software or something.

  - kashmir hill  
    \[LAUGHS\] Why did you do that? It totally made me think that —

  - hoan ton-that  
    Hey, maybe it doesn’t work. You never know, right? This could be the
    long con.

  - kashmir hill  
    Ah, O.K.

  - hoan ton-that  
    I’m kidding, I’m kidding. It works.

annie brown

What do you think that was about?

kashmir hill

\[LAUGHS\] I don’t think it was a software bug.

  - hoan ton-that  
    It’s a bug. I don’t know. I —

  - kashmir hill  
    You have no idea, huh?

annie brown

Huh.

kashmir hill

Yeah. So he said the software bug is now fixed.

  - hoan ton-that  
    Oh yes, so I’ll show you. This is the iPhone version.

kashmir hill

And he took a photo of me.

  - hoan ton-that  
    Oh, it does work.

  - kashmir hill  
    Oh, that’s so surprising.

  - hoan ton-that  
    I know.

kashmir hill

And there, the results included a bunch of photos of me online.

  - kashmir hill  
    Oh my god, I totally forgot.

  - hoan ton-that  
    Well, we can take —

  - kashmir hill  
    That’s 10 years ago.

kashmir hill

Including some I had never seen before.

  - kashmir hill  
    Some of these photos I didn’t know were online.

annie brown

So he’s just brushing off this weird thing that happened to you. But do
you get the sense that he’s thinking at all about privacy?

kashmir hill

So I asked him, you know, this is a very powerful app. And I asked him
what restrictions is he thinking about for it. And he said, one, that
they were only selling it to law enforcement right now, though it does
turn out that they’re also selling it to a few private companies for
security purposes. But he said they wouldn’t sell it to bad actors or
bad governments.

  - hoan ton-that  
    — and our philosophy is basically, if it’s a U.S. based — or like a
    democracy or an ally of the U.S. — we will consider it. But like, no
    China, no Russia or anything that wouldn’t be good. So if it’s a
    country where it’s just governed terribly or whatever, I don’t know
    if we’d feel comfortable selling to certain countries.

annie brown

So it doesn’t sound like he has much of a rubric for deciding who to
sell to. And it sounds like there’s no one really overseeing how he’s
making these decisions.

kashmir hill

At this point, it’s just up to Clearview to decide who they want to sell
the app to.

  - hoan ton-that  
    No pressure, but when we talk to some venture capitalists, they’re
    like, “Why don’t you make this consumer? Law enforcement is such a
    small market. You won’t make that much money.” And we’ve considered
    it, and we’re just like, what’s the use case here? And right now, we
    catch, help catch pedophiles. What if a pedophile got access to
    this, goes around the street, runs —

kashmir hill

But when I was talking to one of their investors, he says, we want to
dominate the law enforcement market, and then we want to move into other
markets like hospitality, like real estate. And he predicted that one
day, all consumers will have access to this app.

  - hoan ton-that  
    Um, and —

  - kashmir hill  
    I can tell you that one of your investors hopes that you guys are
    going to go into the consumer market.

  - hoan ton-that  
    Well, yeah. He talks too much. But like, we’re not — we’re not going
    to do that. I just don’t —

annie brown

Hoan seems to be saying, yeah, there’s pressure on us to sell to private
consumers, but we’re not going to do that. And how reasonable is it to
think that he has control or the company has control at this point over
where this technology goes?

kashmir hill

I mean, one point that I made when I was talking to him is that
oftentimes, the tools that law enforcement use end up in the hands of
the public.

  - kashmir hill  
    I just — I personally feel like you guys have opened the door to now
    this becoming more normalized, just because a lot of tools that law
    enforcement have eventually make their way into public hands.

  - hoan ton-that  
    Not always. Not everyone has a gun. \[LAUGHS\] Right? That would be
    —

  - kashmir hill  
    Anyone who wants one can get one in the U.S. basically, but —

kashmir hill

His response was strange. He said, well, look at guns. Law enforcement
has guns, but not everybody has a gun. And I don’t know if that’s
because he’s from Australia?

annie brown

Yeah, he’s proving your point, in a way.

kashmir hill

\[LAUGHS\] It did seem like he was proving my point, rather than
rebutting it.

\[music\]

We’ve been building the technology to make this possible for years now.
Facebook building this huge database of our photos with our names
attached to it, advances in image recognition and search technologies,
it all led us here. But there’s been no accompanying regulation or rules
around how the technology should be used. There’s no real law or
regulation that makes this illegal. The scraping seems to be O.K. We
don’t have a big ban on facial recognition. We don’t need to give
consent for people to process our faces. And so in terms of holding this
tool back, we’re just relying on the moral compasses of the companies
that are making this technology and on the thoughtfulness of people like
Hoan Tan-That.

  - kashmir hill  
    But yeah, what do you think about that? Do you think that this is
    too dangerous a tool for everybody to have?

  - hoan ton-that  
    I have to think about that and really get back to you on an answer,
    because it’s a good question.

  - kashmir hill  
    Yeah.

  - hoan ton-that  
    I’ve thought about it a little bit.

  - kashmir hill  
    You haven’t thought about it? You have?

  - hoan ton-that  
    I have, I have. But I need to really come up with a good answer for
    that. Honestly like, yeah.

\[music\]

annie brown

Thanks, Kashmir.

kashmir hill

Thank you.

michael barbaro

Since Kashmir began reporting on Clearview AI, several major social
media companies including Facebook, Twitter and Venmo have demanded that
the company stop using photos scraped from their websites. But it’s
unclear what, if any, power those social media companies have to force
Clearview to comply. A few weeks ago, the state of New Jersey barred law
enforcement from using Clearview’s technology, but police remain free to
do so in 49 other states.

We’ll be right back.

Here’s what else you need to know today. President Trump has begun a
campaign of retribution against witnesses in the impeachment inquiry,
firing Gordon Sondland, his ambassador to the European Union, who called
the president’s actions toward Ukraine a quid pro quo. And Lieutenant
Colonel Alexander Vindman, a member of the National Security Council,
who expressed alarm over the president’s phone call with the leader of
Ukraine. The Times reports that several Republican senators urged Trump
not to fire the witnesses, fearing it would send a dangerous message,
but that the president ignored their advice. And the global death toll
from the coronavirus has reached more than 800, surpassing that of the
SARS epidemic, which killed 774 in 2003. The number of confirmed
infections from the coronavirus now stands at more than 37,000. Finally,
new polling in New Hampshire, which will hold its primary tomorrow,
shows Mayor Pete Buttigieg neck-and-neck with Senator Bernie Sanders and
former Vice President Joe Biden slipping into fourth place.

  - archived recording (george stephanopoulos)  
    Vice President Biden, the first question is for you. In the last few
    days, you’ve been saying that Democrats will be taking too big a
    risk if they nominate Senator Sanders or Mayor Buttigieg, but they
    came out on top in Iowa. What risks did the Iowa Democrats miss?

michael barbaro

The poll, conducted by The Boston Globe, WBZ and Suffolk University
suggest Buttigieg is benefiting from a strong performance in the Iowa
caucuses and that Biden may perform poorly for the second time in a row,
a prediction Biden confirmed during Friday night’s debate on ABC.

  - archived recording (joe biden)  
    Oh, they didn’t miss anything. This is a long race. I took a hit in
    Iowa, and I’ll probably take it here.

michael barbaro

That’s it for “The Daily.” I’m Michael Barbaro. See you tomorrow.

</div>

</div>

</div>

</div>

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

There are legal risks associated with handling this type of imagery. It
would be against the law for the company to receive images of abuse
without immediately informing the authorities and deleting the material
from its servers. Mr. Ton-That said Clearview’s app transmitted only
faces, not entire images.

The Times verified this behavior by analyzing a version of Clearview’s
Android app, but was not able to examine the company’s iOS offering or a
web-based version.

None of the law enforcement agencies The Times spoke with would say
whether they had performed a technical audit of Clearview before using
the software. Nor would any respond to questions regarding the specific
use of the application, saying they did not comment on investigative
techniques.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Britney Walker, a spokeswoman for the Department of Homeland Security’s
Child Exploitation Investigations Unit, said that it collaborated with
external agencies to assist in investigations, but that the unit’s
“victim-centered” approach forbade any sharing of illegal imagery.

“Under no circumstances would the agency share child sexual abuse
materials to private companies,” Ms. Walker said.

Other companies already work closely with law enforcement officials
investigating child sexual abuse. Johann Hofmann, the chief executive of
Griffeye, said the company’s imagery analysis software was installed
inside law enforcement networks and was designed to avoid sending images
to third parties, including Griffeye itself.

Another company providing analysis tools to investigators of child
sexual abuse, CameraForensics, also said its systems were designed to
never receive any imagery, including faces, from law enforcement. The
company’s founder, Matt Burns, said his company had considered
incorporating facial recognition technology into its software, but had
decided not to for “ethical reasons.”

“We thought it was too controversial of a feature because it was too
easy to use that functionality for abuse,” he said. “And also it’s just
a legal nightmare.”

Still, Mr. Burns said, he understood why investigators would want to use
facial recognition software. “They are faced with a very grim task, and
if there’s a tool that gives them an opportunity to safeguard victims, I
don’t blame them for trying to grab it with both hands,” he said.

Since Clearview’s practices have come to light, Facebook, LinkedIn,
Twitter, Venmo and YouTube have
[sent](https://www.nytimes.com/2020/01/22/technology/clearview-ai-twitter-letter.html)
the company cease-and-desist letters, asking it to stop scraping photos
from their sites and delete existing images in its database. The
attorney general of New Jersey [banned the use of
Clearview](https://www.nytimes.com/2020/01/24/technology/clearview-ai-new-jersey.html)
by officers in the state and called for an investigation into how it and
similar technologies were being used by law enforcement. A lawsuit
seeking class-action certification was filed in Illinois, where a strong
biometric privacy law prohibits the use of residents’ faceprints without
their consent, and another was filed in Virginia on Monday.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Bills that would ban the use of facial recognition by the police have
recently been introduced in New York and Washington. And Clearview
received a letter from Senator Edward Markey, Democrat of Massachusetts,
asking for a list of law enforcement agencies that have used the app and
whether biometric information has been collected for children under 13
years old.

“While this type of technology has existed for quite some time, we
believe we have created something that enables law enforcement to solve
previously unsolvable crimes and, most importantly, protect vulnerable
children,” Mr. Ton-That said in his email. “At the same time, we are
responding to requests for information from government and other
interested parties as appropriate, and look forward to engaging in
constructive discussions with them as we work to make our communities
safer.”

In October, law enforcement groups [sent a
letter](https://www.ascia.org/pdf/news/le_group_letter_to_congress__facial_recogniton_technology__october_2019.pdf)
to members of Congress, urging them to not ban the use of facial
recognition for their investigations. “We understand the public’s
concern about protection of their privacy and civil rights,” they wrote.
“With clear, publicly available policies we believe those concerns can
be addressed.”

Many agencies had already been using Clearview for months, but the
letter made no mention of that.

Michael H. Keller and Aaron Krolik contributed reporting.

</div>

</div>

<div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
