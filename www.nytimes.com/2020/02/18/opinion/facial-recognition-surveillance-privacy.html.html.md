<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Opinion](/section/opinion)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">All
This Dystopia, and for
What?</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/38GEE2G</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div class="css-v5btjw etb61u70">

<div class="css-v05ibm etb61u71">

[Opinion](/section/opinion)

</div>

</div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# All This Dystopia, and for What?

</div>

When privacy-eroding technology doesn’t deliver on its promises.

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1p10dcb ey68jwv0" data-aria-hidden="true">

[![Charlie
Warzel](https://static01.nyt.com/images/2019/03/15/opinion/charlie-warzel/charlie-warzel-thumbLarge-v3.png
"Charlie Warzel")](https://www.nytimes.com/by/charlie-warzel)

</div>

<div class="css-1baulvz">

By [<span class="css-1baulvz last-byline" itemprop="name">Charlie
Warzel</span>](https://www.nytimes.com/by/charlie-warzel)

<div class="css-8atqhb">

Mr. Warzel is an Opinion writer at large.

</div>

</div>

</div>

  - Feb. 18,
    2020

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Money
Sharma/Agence France-Presse — Getty
Images</span></span></span>](https://static01.nyt.com/images/2020/02/18/opinion/18warzelWeb/18warzelWeb-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

When you signed up for this newsletter you may have noticed the language
indicated it would be a “limited run.” And like all limited runs, ours
is coming to an end next week.

We’re winding down next Tuesday and taking a brief hiatus. Next month,
The Privacy Project newsletter will evolve into The New York Times’s
tech newsletter, written by my colleague Shira Ovide. Every weekday,
it’ll help you understand how technology is changing all aspects of
our lives.

If you no longer wish to receive the email, simply unsubscribe at the
bottom of this newsletter before March 1. We’re eager to hear your
thoughts on what you want more or less of so we can make the newsletter
even better for you. Please share your thoughts [on this
form](https://www.nytimes.com/2020/02/18/reader-center/technology-newsletter-feedback.html).
A reporter or editor may follow up with you to learn more.

I’ll save the goodbyes and lessons for next week’s edition but I just
wanted to say that I so appreciate your readership and thoughtful emails
and comments over this period.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

**A correction:** Last week’s column misidentified the developer of
Apache Struts. Apache Struts is an open source project of the Apache
Software Foundation; Adobe was not the
developer.

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006451534" data-slug="privacy-mid-nav-module" style="max-width:1050px">

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## It invades our privacy. But does it work?

In the year I’ve been writing this column, and voraciously reading
articles about digital privacy, an unsettling theme has emerged. A
report introduces a piece of technology with terrifying, privacy-eroding
implications. The technology — facial recognition, digital ad tracking,
spyware, you name it — is being rapidly deployed by companies that
aren’t considering the potential societal harms. The report produces
understandable frustration and concern. Then, upon further examination,
the claims regarding the technology break down. That groundbreaking
piece of technology, it turns out, is deeply flawed. Instead of a
perfect panopticon, you have a surveillance-state equivalent of a lemon,
or worse yet, total snake oil.

The trend is most common when it comes to facial recognition. Clearview
AI, the facial recognition company that scrapes billions of images from
websites and social media platforms, claimed 100 percent accuracy, when
pitching its product to police departments and suggested it employed
testing methodology “used by the American Civil Liberties Union.” The
A.C.L.U. vehemently disagreed, [telling BuzzFeed
News](https://www.buzzfeednews.com/article/carolinehaskins1/clearview-ai-facial-recognition-accurate-aclu-absurd)
that Clearview’s accuracy claim “is absurd on many levels and further
demonstrates that Clearview simply does not understand the harms of its
technology in law enforcement hands.”

NEC, another facial recognition giant, is facing similar scrutiny. A
recent profile of the [company on the website
OneZero](https://onezero.medium.com/nec-is-the-most-important-facial-recognition-company-youve-never-heard-of-12381d530510)
cites a 2018 [analysis](http://gendershades.org/overview.html) of
commercial facial recognition systems that shows “the algorithms were
more than 30 percent less accurate when attempting to identify women of
color compared to white men, making systems little more accurate than a
coin toss.”

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

Facial recognition testing in general is still new and privacy experts
are concerned about their rigor. Independent audits of facial
recognition are few and far between and not reassuring. “In trials of
the NEC technology in London, one of the only independent
[analyses](https://news.sky.com/story/met-polices-facial-recognition-tech-has-81-error-rate-independent-report-says-11755941)
of NEC’s algorithm found that 81 percent of 42 people flagged by the
facial recognition algorithm were not actually on a watch list,” the
OneZero report said.

An [NBC News
investigation](https://www.nbcnews.com/news/all/cute-videos-little-evidence-police-say-amazon-ring-isn-t-n1136026)
into Amazon’s Ring doorbell cameras suggested that their
porch-surveillance technology hasn’t proved all that effective in
catching criminals. Thirteen of the 40 jurisdictions NBC News reached
“said they had made zero arrests as a result of Ring footage,” while
around a dozen others “said that they don’t know how many arrests had
been made as a result of their relationship with Ring — and therefore
could not evaluate its effectiveness.”

The examples are everywhere. Software intended to scan social media
posts of job candidates for background checks sounds like a creepy way
to judge candidates — but, as examples show, the software seems unable
to recognize and appropriately categorize common human traits like
sarcasm or humor, rendering the software mostly useless.

</div>

</div>

<div class="css-cfo9c3">

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

The online advertising industry, which lays the groundwork for most of
the everyday tracking and data collection we face, is equally
unreliable. Though apps, platforms and data brokers are following our
every click, keystroke and physical movements via our phones, the
profiles they assemble can still be full of errors. Take Equifax, the
data broker hacked by the Chinese in 2017. As Aaron Klein of the
Brookings Institution [wrote in the wake of the
hack](https://www.cnbc.com/2017/09/27/the-real-problem-with-credit-reports-is-the-astounding-number-of-errors-equifax-commentary.html),
“More than one in five consumers have a ‘[potentially material
error](https://www.ftc.gov/sites/default/files/documents/reports/section-319-fair-and-accurate-credit-transactions-act-2003-fifth-interim-federal-trade-commission/130211factareport.pdf "https://www.ftc.gov/sites/default/files/documents/reports/section-319-fair-and-accurate-credit-transactions-act-2003-fifth-interim-federal-trade-commission/130211factareport.pdf")’
in their credit file that makes them look riskier than they are” to
lenders.

And while digital marketers are keen to play up the customer insights
from the metadata they collect via our browsing, our understanding of
the effectiveness of data to influence user behavior is still quite new.
For example, despite the (justifiable) shock and outrage over the
Cambridge Analytica scandal, it’s still hard to quantify exactly what
role psychographic profiling played in influencing votes during Brexit
or the 2016 election. Some skeptics suggest there’s not enough empirical
evidence to reach a scientifically sound conclusion about Big Data’s
ability to influence complex behavior like voting.

The same may be true for the entire digital ad industry. A fantastic
deep dive into the ad world by [The
Correspondent](https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising/13228924500-22d5fd24)
illustrated that despite the assumptions of many marketers, there’s a
great deal that’s unknown about the efficacy of digital ads.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“When these experiments showed that ads were utterly pointless,
advertisers were not bothered in the slightest. They charged gaily
ahead, buying ad after ad,” the article said. “Even when they knew, or
could have known, that their ad campaigns were not very profitable, it
had no impact on how they behaved.” Hundreds of billions of dollars are
spent globally in the industry, but as the report concluded, “Is online
advertising working? We simply don’t know.”

The above examples all represent a different, equally troubling brand of
dystopia — one full of false positives, confusion and waste. In these
examples the technology is no less invasive. Your face is still scanned
in public, your online information is still leveraged against you to
manipulate your behavior and your financial data is collected to compile
a score that may determine if you can own a home or a car. Your privacy
is still invaded, only now you’re left to wonder if the insights were
accurate.

As lawmakers ponder facial recognition bans and comprehensive privacy
laws, they’d do well to consider this fundamental question: Setting
aside even the ethical concerns, are the technologies that are slowly
eroding our ability to live a private life actually delivering on their
promises? Companies like NEC and others argue that outright bans on
technology like facial recognition “[stifle
innovation](https://onezero.medium.com/nec-is-the-most-important-facial-recognition-company-youve-never-heard-of-12381d530510).”
Though I’m personally not convinced, there may be kernels of truth to
that. But before giving these companies the benefit of the doubt, we
should look deeper at the so-called innovation to see what we’re really
gaining as a result of our larger privacy sacrifice.

Right now, the trade-off doesn’t look so great. Perhaps the only thing
worse than living in a perfect surveillance state is living in a deeply
flawed one.

</div>

</div>

<div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

## What I’m Reading:

[L.A.P.D. automatic license plate readers pose a massive privacy risk,
audit
says.](https://www.latimes.com/california/story/2020-02-13/privacy-risks-automatic-license-plate-readers-lapd)

[The myth of the privacy
paradox](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3536265).

[I got a Ring doorbell camera. It scared the hell out of
me.](https://nymag.com/intelligencer/2020/02/what-its-like-to-own-an-amazon-ring-doorbell-camera.html?utm_campaign=nym&utm_medium=s1&utm_source=tw)

*Like other media companies, The Times collects data on its visitors
when they read stories like this one. For more detail please see* [*our
privacy
policy*](https://help.nytimes.com/hc/en-us/articles/115014892108-Privacy-policy?module=inline)
*and* [*our publisher's
description*](https://www.nytimes.com/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection%2Fspotlightcollection%2Fprivacy-project-does-privacy-matter&action=click&contentCollection=opinion&region=stream&module=stream_unit&version=latest&contentPlacement=8&pgtype=collection)
*of The Times's practices and continued steps to increase transparency
and protections.*

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

*Follow* [*@privacyproject*](https://twitter.com/privacyproject) *on
Twitter and The New York Times Opinion Section on*
[*Facebook*](https://www.facebook.com/nytopinion)
*and*[*Instagram*](https://www.instagram.com/nytopinion/)*.*

</div>

</div>

<div style="max-width:100%;margin:0 auto">

<div class="css-17dprlf" data-id="100000006450604" data-slug="privacy-collection" style="max-width:2000px">

</div>

</div>

<div id="privacy-glossary-embed" class="section interactive-content interactive-size-scoop css-bvtwvj" data-id="100000006427375">

## glossary replacer

<div class="css-17ih8de interactive-body" data-sourceid="100000006427375">

</div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
