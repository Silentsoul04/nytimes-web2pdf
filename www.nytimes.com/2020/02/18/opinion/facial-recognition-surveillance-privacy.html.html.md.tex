Sections

SEARCH

\protect\hyperlink{site-content}{Skip to
content}\protect\hyperlink{site-index}{Skip to site index}

\href{https://myaccount.nytimes.com/auth/login?response_type=cookie\&client_id=vi}{}

\href{https://www.nytimes.com/section/todayspaper}{Today's Paper}

\href{/section/opinion}{Opinion}\textbar{}All This Dystopia, and for
What?

\url{https://nyti.ms/38GEE2G}

\begin{itemize}
\item
\item
\item
\item
\item
\end{itemize}

Advertisement

\protect\hyperlink{after-top}{Continue reading the main story}

\href{/section/opinion}{Opinion}

Supported by

\protect\hyperlink{after-sponsor}{Continue reading the main story}

\hypertarget{all-this-dystopia-and-for-what}{%
\section{All This Dystopia, and for
What?}\label{all-this-dystopia-and-for-what}}

When privacy-eroding technology doesn't deliver on its promises.

\href{https://www.nytimes.com/by/charlie-warzel}{\includegraphics{https://static01.nyt.com/images/2019/03/15/opinion/charlie-warzel/charlie-warzel-thumbLarge-v3.png}}

By \href{https://www.nytimes.com/by/charlie-warzel}{Charlie Warzel}

Mr. Warzel is an Opinion writer at large.

\begin{itemize}
\item
  Feb. 18, 2020
\item
  \begin{itemize}
  \item
  \item
  \item
  \item
  \item
  \end{itemize}
\end{itemize}

\includegraphics{https://static01.nyt.com/images/2020/02/18/opinion/18warzelWeb/18warzelWeb-articleLarge.jpg?quality=75\&auto=webp\&disable=upscale}

When you signed up for this newsletter you may have noticed the language
indicated it would be a ``limited run.'' And like all limited runs, ours
is coming to an end next week.

We're winding down next Tuesday and taking a brief hiatus. Next month,
The Privacy Project newsletter will evolve into The New York Times's
tech newsletter, written by my colleague Shira Ovide. Every weekday,
it'll help you understand how technology is changing all aspects of our
lives.

If you no longer wish to receive the email, simply unsubscribe at the
bottom of this newsletter before March 1. We're eager to hear your
thoughts on what you want more or less of so we can make the newsletter
even better for you. Please share your thoughts
\href{https://www.nytimes.com/2020/02/18/reader-center/technology-newsletter-feedback.html}{on
this form}. A reporter or editor may follow up with you to learn more.

I'll save the goodbyes and lessons for next week's edition but I just
wanted to say that I so appreciate your readership and thoughtful emails
and comments over this period.

\textbf{A correction:} Last week's column misidentified the developer of
Apache Struts. Apache Struts is an open source project of the Apache
Software Foundation; Adobe was not the developer.

\hypertarget{it-invades-our-privacy-but-does-it-work}{%
\subsection{It invades our privacy. But does it
work?}\label{it-invades-our-privacy-but-does-it-work}}

In the year I've been writing this column, and voraciously reading
articles about digital privacy, an unsettling theme has emerged. A
report introduces a piece of technology with terrifying, privacy-eroding
implications. The technology --- facial recognition, digital ad
tracking, spyware, you name it --- is being rapidly deployed by
companies that aren't considering the potential societal harms. The
report produces understandable frustration and concern. Then, upon
further examination, the claims regarding the technology break down.
That groundbreaking piece of technology, it turns out, is deeply flawed.
Instead of a perfect panopticon, you have a surveillance-state
equivalent of a lemon, or worse yet, total snake oil.

The trend is most common when it comes to facial recognition. Clearview
AI, the facial recognition company that scrapes billions of images from
websites and social media platforms, claimed 100 percent accuracy, when
pitching its product to police departments and suggested it employed
testing methodology ``used by the American Civil Liberties Union.'' The
A.C.L.U. vehemently disagreed,
\href{https://www.buzzfeednews.com/article/carolinehaskins1/clearview-ai-facial-recognition-accurate-aclu-absurd}{telling
BuzzFeed News} that Clearview's accuracy claim ``is absurd on many
levels and further demonstrates that Clearview simply does not
understand the harms of its technology in law enforcement hands.''

NEC, another facial recognition giant, is facing similar scrutiny. A
recent profile of the
\href{https://onezero.medium.com/nec-is-the-most-important-facial-recognition-company-youve-never-heard-of-12381d530510}{company
on the website OneZero} cites a 2018
\href{http://gendershades.org/overview.html}{analysis} of commercial
facial recognition systems that shows ``the algorithms were more than 30
percent less accurate when attempting to identify women of color
compared to white men, making systems little more accurate than a coin
toss.''

Facial recognition testing in general is still new and privacy experts
are concerned about their rigor. Independent audits of facial
recognition are few and far between and not reassuring. ``In trials of
the NEC technology in London, one of the only independent
\href{https://news.sky.com/story/met-polices-facial-recognition-tech-has-81-error-rate-independent-report-says-11755941}{analyses}
of NEC's algorithm found that 81 percent of 42 people flagged by the
facial recognition algorithm were not actually on a watch list,'' the
OneZero report said.

An
\href{https://www.nbcnews.com/news/all/cute-videos-little-evidence-police-say-amazon-ring-isn-t-n1136026}{NBC
News investigation} into Amazon's Ring doorbell cameras suggested that
their porch-surveillance technology hasn't proved all that effective in
catching criminals. Thirteen of the 40 jurisdictions NBC News reached
``said they had made zero arrests as a result of Ring footage,'' while
around a dozen others ``said that they don't know how many arrests had
been made as a result of their relationship with Ring --- and therefore
could not evaluate its effectiveness.''

The examples are everywhere. Software intended to scan social media
posts of job candidates for background checks sounds like a creepy way
to judge candidates --- but, as examples show, the software seems unable
to recognize and appropriately categorize common human traits like
sarcasm or humor, rendering the software mostly useless.

The online advertising industry, which lays the groundwork for most of
the everyday tracking and data collection we face, is equally
unreliable. Though apps, platforms and data brokers are following our
every click, keystroke and physical movements via our phones, the
profiles they assemble can still be full of errors. Take Equifax, the
data broker hacked by the Chinese in 2017. As Aaron Klein of the
Brookings Institution
\href{https://www.cnbc.com/2017/09/27/the-real-problem-with-credit-reports-is-the-astounding-number-of-errors-equifax-commentary.html}{wrote
in the wake of the hack}, ``More than one in five consumers have a
`\href{https://www.ftc.gov/sites/default/files/documents/reports/section-319-fair-and-accurate-credit-transactions-act-2003-fifth-interim-federal-trade-commission/130211factareport.pdf}{potentially
material error}' in their credit file that makes them look riskier than
they are'' to lenders.

And while digital marketers are keen to play up the customer insights
from the metadata they collect via our browsing, our understanding of
the effectiveness of data to influence user behavior is still quite new.
For example, despite the (justifiable) shock and outrage over the
Cambridge Analytica scandal, it's still hard to quantify exactly what
role psychographic profiling played in influencing votes during Brexit
or the 2016 election. Some skeptics suggest there's not enough empirical
evidence to reach a scientifically sound conclusion about Big Data's
ability to influence complex behavior like voting.

The same may be true for the entire digital ad industry. A fantastic
deep dive into the ad world by
\href{https://thecorrespondent.com/100/the-new-dot-com-bubble-is-here-its-called-online-advertising/13228924500-22d5fd24}{The
Correspondent} illustrated that despite the assumptions of many
marketers, there's a great deal that's unknown about the efficacy of
digital ads.

``When these experiments showed that ads were utterly pointless,
advertisers were not bothered in the slightest. They charged gaily
ahead, buying ad after ad,'' the article said. ``Even when they knew, or
could have known, that their ad campaigns were not very profitable, it
had no impact on how they behaved.'' Hundreds of billions of dollars are
spent globally in the industry, but as the report concluded, ``Is online
advertising working? We simply don't know.''

The above examples all represent a different, equally troubling brand of
dystopia --- one full of false positives, confusion and waste. In these
examples the technology is no less invasive. Your face is still scanned
in public, your online information is still leveraged against you to
manipulate your behavior and your financial data is collected to compile
a score that may determine if you can own a home or a car. Your privacy
is still invaded, only now you're left to wonder if the insights were
accurate.

As lawmakers ponder facial recognition bans and comprehensive privacy
laws, they'd do well to consider this fundamental question: Setting
aside even the ethical concerns, are the technologies that are slowly
eroding our ability to live a private life actually delivering on their
promises? Companies like NEC and others argue that outright bans on
technology like facial recognition
``\href{https://onezero.medium.com/nec-is-the-most-important-facial-recognition-company-youve-never-heard-of-12381d530510}{stifle
innovation}.'' Though I'm personally not convinced, there may be kernels
of truth to that. But before giving these companies the benefit of the
doubt, we should look deeper at the so-called innovation to see what
we're really gaining as a result of our larger privacy sacrifice.

Right now, the trade-off doesn't look so great. Perhaps the only thing
worse than living in a perfect surveillance state is living in a deeply
flawed one.

\hypertarget{what-im-reading}{%
\subsection{What I'm Reading:}\label{what-im-reading}}

\href{https://www.latimes.com/california/story/2020-02-13/privacy-risks-automatic-license-plate-readers-lapd}{L.A.P.D.
automatic license plate readers pose a massive privacy risk, audit
says.}

\href{https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3536265}{The
myth of the privacy paradox}.

\href{https://nymag.com/intelligencer/2020/02/what-its-like-to-own-an-amazon-ring-doorbell-camera.html?utm_campaign=nym\&utm_medium=s1\&utm_source=tw}{I
got a Ring doorbell camera. It scared the hell out of me.}

\emph{Like other media companies, The Times collects data on its
visitors when they read stories like this one. For more detail please
see}
\href{https://help.nytimes.com/hc/en-us/articles/115014892108-Privacy-policy?module=inline}{\emph{our
privacy policy}} \emph{and}
\href{https://www.nytimes.com/2019/04/10/opinion/sulzberger-new-york-times-privacy.html?rref=collection\%2Fspotlightcollection\%2Fprivacy-project-does-privacy-matter\&action=click\&contentCollection=opinion\&region=stream\&module=stream_unit\&version=latest\&contentPlacement=8\&pgtype=collection}{\emph{our
publisher's description}} \emph{of The Times's practices and continued
steps to increase transparency and protections.}

\emph{Follow}
\href{https://twitter.com/privacyproject}{\emph{@privacyproject}}
\emph{on Twitter and The New York Times Opinion Section on}
\href{https://www.facebook.com/nytopinion}{\emph{Facebook}}
\emph{and}\href{https://www.instagram.com/nytopinion/}{\emph{Instagram}}\emph{.}

\hypertarget{glossary-replacer}{%
\subsection{glossary replacer}\label{glossary-replacer}}

Advertisement

\protect\hyperlink{after-bottom}{Continue reading the main story}

\hypertarget{site-index}{%
\subsection{Site Index}\label{site-index}}

\hypertarget{site-information-navigation}{%
\subsection{Site Information
Navigation}\label{site-information-navigation}}

\begin{itemize}
\tightlist
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice}{©~2020~The
  New York Times Company}
\end{itemize}

\begin{itemize}
\tightlist
\item
  \href{https://www.nytco.com/}{NYTCo}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us}{Contact
  Us}
\item
  \href{https://www.nytco.com/careers/}{Work with us}
\item
  \href{https://nytmediakit.com/}{Advertise}
\item
  \href{http://www.tbrandstudio.com/}{T Brand Studio}
\item
  \href{https://www.nytimes.com/privacy/cookie-policy\#how-do-i-manage-trackers}{Your
  Ad Choices}
\item
  \href{https://www.nytimes.com/privacy}{Privacy}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service}{Terms
  of Service}
\item
  \href{https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale}{Terms
  of Sale}
\item
  \href{https://spiderbites.nytimes.com}{Site Map}
\item
  \href{https://help.nytimes.com/hc/en-us}{Help}
\item
  \href{https://www.nytimes.com/subscription?campaignId=37WXW}{Subscriptions}
\end{itemize}
