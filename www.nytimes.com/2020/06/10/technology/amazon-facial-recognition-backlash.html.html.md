<div id="app">

<div>

<div>

<div>

<div class="NYTAppHideMasthead css-1q2w90k e1suatyy0">

<div class="section css-ui9rw0 e1suatyy2">

<div class="css-eph4ug er09x8g0">

<div class="css-6n7j50">

</div>

<span class="css-1dv1kvn">Sections</span>

<div class="css-10488qs">

<span class="css-1dv1kvn">SEARCH</span>

</div>

[Skip to content](#site-content)[Skip to site
index](#site-index)

</div>

<div id="masthead-section-label" class="css-1wr3we4 eaxe0e00">

[Technology](https://www.nytimes.com/section/technology)

</div>

<div class="css-10698na e1huz5gh0">

</div>

</div>

<div id="masthead-bar-one" class="section hasLinks css-15hmgas e1csuq9d3">

<div class="css-uqyvli e1csuq9d0">

</div>

<div class="css-1uqjmks e1csuq9d1">

</div>

<div class="css-9e9ivx">

[](https://myaccount.nytimes.com/auth/login?response_type=cookie&client_id=vi)

</div>

<div class="css-1bvtpon e1csuq9d2">

[Today’s
Paper](https://www.nytimes.com/section/todayspaper)

</div>

</div>

</div>

</div>

<div data-aria-hidden="false">

<div id="site-content" data-role="main">

<div>

<div class="css-1aor85t" style="opacity:0.000000001;z-index:-1;visibility:hidden">

<div class="css-1hqnpie">

<div class="css-epjblv">

<span class="css-17xtcya">[Technology](/section/technology)</span><span class="css-x15j1o">|</span><span class="css-fwqvlz">Amazon
Pauses Police Use of Its Facial Recognition
Software</span>

</div>

<div class="css-k008qs">

<div class="css-1iwv8en">

<span class="css-18z7m18"></span>

<div>

</div>

</div>

<span class="css-1n6z4y">https://nyti.ms/30wnILc</span>

<div class="css-1705lsu">

<div class="css-4xjgmj">

<div class="css-4skfbu" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">

  - 
  - 
  - 
  - 
    
    <div class="css-6n7j50">
    
    </div>

  - 

</div>

</div>

</div>

</div>

</div>

</div>

<div id="NYT_TOP_BANNER_REGION" class="css-13pd83m">

</div>

<div id="top-wrapper" class="css-1sy8kpn">

<div id="top-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-top)

<div class="ad top-wrapper" style="text-align:center;height:100%;display:block;min-height:250px">

<div id="top" class="place-ad" data-position="top" data-size-key="top">

</div>

</div>

<div id="after-top">

</div>

</div>

<div>

<div id="sponsor-wrapper" class="css-1hyfx7x">

<div id="sponsor-slug" class="css-19vbshk">

Supported by

</div>

[Continue reading the main
story](#after-sponsor)

<div id="sponsor" class="ad sponsor-wrapper" style="text-align:center;height:100%;display:block">

</div>

<div id="after-sponsor">

</div>

</div>

<div class="css-186x18t">

</div>

<div class="css-1vkm6nb ehdk2mb0">

# Amazon Pauses Police Use of Its Facial Recognition Software

</div>

The company said it hoped the moratorium “might give Congress enough
time to put in place appropriate rules” for the technology.

<div class="css-79elbk" data-testid="photoviewer-wrapper">

<div class="css-z3e15g" data-testid="photoviewer-wrapper-hidden">

</div>

<div class="css-1a48zt4 ehw59r15" data-testid="photoviewer-children">

![<span class="css-16f3y1r e13ogyst0" data-aria-hidden="true">Civil
liberties advocates began calling for a ban on the use of facial
recognition by law enforcement in
2018.</span><span class="css-cnj6d5 e1z0qqy90" itemprop="copyrightHolder"><span class="css-1ly73wi e1tej78p0">Credit...</span><span><span>Elaine
Thompson/Associated
Press</span></span></span>](https://static01.nyt.com/images/2020/06/10/business/10UNREST-AMAZON-sub/merlin_146147871_e6de7acc-ca13-4a75-85c9-bcaa6c869a18-articleLarge.jpg?quality=75&auto=webp&disable=upscale)

</div>

</div>

<div class="css-18e8msd">

<div class="css-vp77d3 epjyd6m0">

<div class="css-1baulvz">

By [<span class="css-1baulvz" itemprop="name">Karen
Weise</span>](https://www.nytimes.com/by/karen-weise) and
[<span class="css-1baulvz last-byline" itemprop="name">Natasha
Singer</span>](https://www.nytimes.com/by/natasha-singer)

</div>

</div>

  - 
    
    <div class="css-ld3wwf e16638kd2">
    
    June 10,
    2020
    
    </div>

  - 
    
    <div class="css-4xjgmj">
    
    <div class="css-d8bdto" data-role="toolbar" data-aria-label="Social Media Share buttons, Save button, and Comments Panel with current comment count" data-testid="share-tools">
    
      - 
      - 
      - 
      - 
        
        <div class="css-6n7j50">
        
        </div>
    
      - 
    
    </div>
    
    </div>

</div>

</div>

<div class="section meteredContent css-1r7ky0e" name="articleBody" itemprop="articleBody">

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

SEATTLE — Amazon said on Wednesday that it was putting a one-year pause
on letting the police use its [facial
recognition](https://www.nytimes.com/2019/05/20/technology/amazon-facial-recognition.html)
tool, in a major sign of the growing concerns that the technology may
lead to [unfair
treatment](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)
of African-Americans.

The technology giant did not explain its reasoning in its brief blog
post about the change, but the move came amid the nationwide protests
over racism and biased policing. Amazon’s technology had been criticized
in the past for misidentifying people of color.

In its [blog
post](https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition),
the company
[said](https://blog.aboutamazon.com/policy/we-are-implementing-a-one-year-moratorium-on-police-use-of-rekognition)
it hoped the moratorium on its service, Rekognition, “might give
Congress enough time to put in place appropriate rules” for the ethical
use of facial recognition.

The announcement was a striking change for Amazon, a prominent supplier
of facial recognition software to law enforcement. More than other big
technology companies, Amazon has resisted calls to slow its deployment.
In the past, Amazon had said its tools were accurate but were improperly
used by researchers.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

On Monday, IBM said it would stop selling facial recognition products,
and last year, the leading maker of police body cameras
[banned](https://www.nytimes.com/2019/06/27/opinion/police-cam-facial-recognition.html)
the use of facial recognition on its products at the recommendation of
its independent ethics board, which said the technology “is not
currently reliable enough to ethically justify its use.” [Google has
advocated](https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html)
a temporary ban on the technology.

The American Civil Liberties Union applauded Amazon in a statement for
“finally recognizing the dangers face recognition poses to Black and
Brown communities and civil rights more broadly.” But it said that the
company should extend the moratorium on law enforcement use of its
system until Congress passed a law regulating the technology.

“Face recognition technology gives governments the unprecedented power
to spy on us wherever we go,” Nicole Ozer, technology and civil
liberties director for the A.C.L.U. of Northern California, said in the
statement. “It fuels police abuse. This surveillance technology must be
stopped.”

Law enforcement agencies use facial recognition technology to
[identify](https://www.nytimes.com/2019/06/09/opinion/facial-recognition-police-new-york-city.html)
suspects and missing children. The systems work by trying to match
facial pattern data extracted from photos or video with those in
databases like driver’s license records. The authorities used the
technology to help identify the suspect [in the mass
shooting](https://www.nytimes.com/2019/04/29/us/capital-gazette-shooting-suspect.html)
at a newspaper last year in Annapolis, Md.

But civil liberties groups have warned that the technology can be used
at a distance to secretly identify individuals — such as protesters
attending demonstrations — potentially chilling Americans’ right to free
speech or simply limiting their ability to go about their business
anonymously in public. Some cities, including San Francisco, and
Cambridge, Mass., have passed bans on the technology.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

This week, Democrats in the House introduced a police reform law that
would ban the use of facial recognition technology with police recording
equipment. Some lawmakers have long worried about the technology,
questioning manufacturers and the public agencies that use their
products on how it affects civil rights and privacy.

Civil liberties advocates began a campaign to ban the use of facial
recognition by law enforcement in 2018, after a report by academic
researchers found racial bias in the systems. The report found that
facial technologies made by IBM and Microsoft were able to correctly
identify the gender of white men in photographs about 100 percent of the
time. But the systems were much less accurate in their ability to
identify the gender of darker-skinned women.

IBM and Microsoft quickly improved their systems. Amazon found itself
under heightened scrutiny.

For the past two years, the A.C.L.U. has led a campaign to push Amazon
to stop selling the technology to law enforcement agencies. The group
obtained documents, using open information laws, from police departments
that showed how Amazon was aggressively marketing its technology to law
enforcement.

The A.C.L.U. also tested Amazon’s technology using the head shots of
members of Congress and comparing them against a database of publicly
available mug shots. The group reported that the Amazon technology
incorrectly matched 28 members of Congress with people who had been
arrested, amounting to a 5 percent error rate among legislators. At the
time, Amazon disputed the findings, saying that the group had used its
system differently than law enforcement customers did.

Rep. Jimmy Gomez, a California Democrat and one of the lawmakers
misidentified in the A.C.L.U. test, said he met with Amazon about the
issue almost a dozen times. He said Amazon was less open to criticism
than its tech peers.

“They were avoiding taking any responsibility for their technology in my
opinion,” Mr. Gomez said on Wednesday after the company’s announcement.
“They always had some excuse.”

Mr. Gomez, who is vice chairman of the House Committee on Oversight and
Reform, said he was glad to see Amazon halt police sales.

</div>

</div>

<div class="css-1fanzo5 StoryBodyCompanionColumn">

<div class="css-53u6y8">

“Amazon can sense that the American people don’t want platitudes when it
comes to dealing with disparities right now,” he said. “They want
concrete action.”

Amazon introduced Rekognition in 2016 as a low-cost, “highly scalable”
way to identify images, including people, in vast databases. Soon after,
it began [pitching the
police](https://www.nytimes.com/2018/05/22/technology/amazon-facial-recognition.html)
on the tool to help investigations, and law enforcement agencies began
adopting the technology.

In an interview on the PBS show “Frontline” earlier this year, Andy
Jassy, the chief executive of Amazon Web Services, said he did not think
the company knew how many police departments were deploying the
technology.

Last fall, Jeff Bezos, Amazon’s chief executive, said the company was
drafting privacy legislation for facial recognition. But he indicated
that Amazon would continue selling the tools in the meantime.

“It’s a perfect example of something that has really positive uses, so
you don’t want to put the brakes on it,” Mr. Bezos said. “At the same
time, there is lots of potential for abuses with that kind of
technology, so you want regulations.”

He said he would welcome “good regulations” on the issue. “That kind of
stability I think would be healthy for the whole industry,” he said.

Mr. Bezos did not provide details for what the company’s proposed
legislation would entail.

Mr. Gomez said he had not seen any model legislation proposed by Amazon,
adding, “That would have been news to me.”

Karen Weise reported from Seattle, and Natasha Singer from New York.
David McCabe contributed reporting from Washington.

</div>

</div>

<div>

</div>

</div>

<div>

</div>

<div>

</div>

<div>

</div>

<div>

<div id="bottom-wrapper" class="css-1ede5it">

<div id="bottom-slug" class="css-l9onyx">

Advertisement

</div>

[Continue reading the main
story](#after-bottom)

<div id="bottom" class="ad bottom-wrapper" style="text-align:center;height:100%;display:block;min-height:90px">

</div>

<div id="after-bottom">

</div>

</div>

</div>

</div>

</div>

## Site Index

<div>

</div>

## Site Information Navigation

  - [© <span>2020</span> <span>The New York Times
    Company</span>](https://help.nytimes.com/hc/en-us/articles/115014792127-Copyright-notice)

<!-- end list -->

  - [NYTCo](https://www.nytco.com/)
  - [Contact
    Us](https://help.nytimes.com/hc/en-us/articles/115015385887-Contact-Us)
  - [Work with us](https://www.nytco.com/careers/)
  - [Advertise](https://nytmediakit.com/)
  - [T Brand Studio](http://www.tbrandstudio.com/)
  - [Your Ad
    Choices](https://www.nytimes.com/privacy/cookie-policy#how-do-i-manage-trackers)
  - [Privacy](https://www.nytimes.com/privacy)
  - [Terms of
    Service](https://help.nytimes.com/hc/en-us/articles/115014893428-Terms-of-service)
  - [Terms of
    Sale](https://help.nytimes.com/hc/en-us/articles/115014893968-Terms-of-sale)
  - [Site
    Map](https://spiderbites.nytimes.com)
  - [Help](https://help.nytimes.com/hc/en-us)
  - [Subscriptions](https://www.nytimes.com/subscription?campaignId=37WXW)

</div>

</div>

</div>

</div>
